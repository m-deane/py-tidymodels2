{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py-recipes Demo: Feature Engineering Pipelines\n",
    "\n",
    "This notebook demonstrates the **py-recipes** package for creating reproducible feature engineering pipelines.\n",
    "\n",
    "## What is py-recipes?\n",
    "\n",
    "**py-recipes** provides a consistent interface for:\n",
    "- **Preprocessing**: Normalization, imputation, encoding\n",
    "- **Feature engineering**: Custom transformations\n",
    "- **Pipeline composition**: Chain multiple steps\n",
    "- **Train/test consistency**: No data leakage\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Recipe**: Specification of preprocessing steps (immutable)\n",
    "2. **prep()**: Fit recipe to training data\n",
    "3. **bake()**: Apply fitted recipe to new data\n",
    "4. **PreparedRecipe**: Fitted recipe ready to transform\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [Basic Recipe Usage](#basic-recipe)\n",
    "3. [Normalization](#normalization)\n",
    "4. [Dummy Variables (One-Hot Encoding)](#dummy)\n",
    "5. [Missing Value Imputation](#imputation)\n",
    "6. [Custom Transformations](#mutate)\n",
    "7. [Multi-Step Pipelines](#pipelines)\n",
    "8. [Integration with Workflows](#workflows)\n",
    "9. [Complete Example](#complete)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup <a id=\"setup\"></a>\n",
    "\n",
    "First, let's import the necessary packages and create sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from py_recipes import recipe\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (200, 6)\n",
      "\n",
      "Missing values:\n",
      "sales           0\n",
      "price           0\n",
      "advertising    20\n",
      "temperature     0\n",
      "store_type      0\n",
      "region          0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>price</th>\n",
       "      <th>advertising</th>\n",
       "      <th>temperature</th>\n",
       "      <th>store_type</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5496.714153</td>\n",
       "      <td>53.577874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.354829</td>\n",
       "      <td>Street</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4861.735699</td>\n",
       "      <td>55.607845</td>\n",
       "      <td>700.312489</td>\n",
       "      <td>6.167520</td>\n",
       "      <td>Online</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5647.688538</td>\n",
       "      <td>60.830512</td>\n",
       "      <td>1002.621850</td>\n",
       "      <td>33.044089</td>\n",
       "      <td>Street</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6523.029856</td>\n",
       "      <td>60.538021</td>\n",
       "      <td>1023.490297</td>\n",
       "      <td>40.334568</td>\n",
       "      <td>Online</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4765.846625</td>\n",
       "      <td>36.223306</td>\n",
       "      <td>774.967264</td>\n",
       "      <td>26.201524</td>\n",
       "      <td>Mall</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sales      price  advertising  temperature store_type region\n",
       "0  5496.714153  53.577874          NaN    31.354829     Street  North\n",
       "1  4861.735699  55.607845   700.312489     6.167520     Online  South\n",
       "2  5647.688538  60.830512  1002.621850    33.044089     Street  North\n",
       "3  6523.029856  60.538021  1023.490297    40.334568     Online   East\n",
       "4  4765.846625  36.223306   774.967264    26.201524       Mall   East"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample data with various issues\n",
    "n = 200\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"sales\": np.random.randn(n) * 1000 + 5000,\n",
    "    \"price\": np.random.randn(n) * 10 + 50,\n",
    "    \"advertising\": np.random.randn(n) * 500 + 1000,\n",
    "    \"temperature\": np.random.randn(n) * 15 + 20,\n",
    "    \"store_type\": np.random.choice([\"Mall\", \"Street\", \"Online\"], n),\n",
    "    \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], n)\n",
    "})\n",
    "\n",
    "# Add some missing values\n",
    "missing_idx = np.random.choice(n, size=20, replace=False)\n",
    "data.loc[missing_idx, \"advertising\"] = np.nan\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"\\nMissing values:\\n{data.isna().sum()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 160 | Test: 40\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "train_idx = int(0.8 * n)\n",
    "train = data[:train_idx].copy()\n",
    "test = data[train_idx:].copy()\n",
    "\n",
    "print(f\"Train: {len(train)} | Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Basic Recipe Usage <a id=\"basic-recipe\"></a>\n",
    "\n",
    "A recipe follows the **prep/bake** pattern:\n",
    "1. **Create** a recipe specification\n",
    "2. **prep()** fits the recipe to training data\n",
    "3. **bake()** applies the fitted recipe to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe: Recipe(steps=[], template=None, roles={})\n",
      "Steps: []\n"
     ]
    }
   ],
   "source": [
    "# Create a simple recipe\n",
    "rec = recipe()\n",
    "print(f\"Recipe: {rec}\")\n",
    "print(f\"Steps: {rec.steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe with 1 step: 1 steps\n"
     ]
    }
   ],
   "source": [
    "# Add a normalization step\n",
    "rec = recipe().step_normalize()\n",
    "print(f\"Recipe with 1 step: {len(rec.steps)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared recipe: PreparedRecipe(recipe=Recipe(steps=[StepNormalize(columns=None, method='zscore')], template=None, roles={}), prepared_steps=[PreparedStepNormalize(columns=['sales', 'price', 'advertising', 'temperature'], scaler=StandardScaler(), method='zscore')], template=           sales      price  advertising  temperature store_type region\n",
      "0    5496.714153  53.577874          NaN    31.354829     Street  North\n",
      "1    4861.735699  55.607845   700.312489     6.167520     Online  South\n",
      "2    5647.688538  60.830512  1002.621850    33.044089     Street  North\n",
      "3    6523.029856  60.538021  1023.490297    40.334568     Online   East\n",
      "4    4765.846625  36.223306   774.967264    26.201524       Mall   East\n",
      "..           ...        ...          ...          ...        ...    ...\n",
      "155  4285.648582  39.974706   794.061517    59.485731     Online   West\n",
      "156  6865.774511  49.814869          NaN    27.399769     Online  South\n",
      "157  5473.832921  47.113414   783.720906    22.772542     Street   East\n",
      "158  3808.696503  53.227186  1197.226071     7.124633     Online   West\n",
      "159  5656.553609  41.727691   789.507760    30.504648     Street   West\n",
      "\n",
      "[160 rows x 6 columns])\n",
      "Prepared steps: 1\n"
     ]
    }
   ],
   "source": [
    "# Fit (prep) the recipe to training data\n",
    "rec_fit = rec.prep(train)\n",
    "print(f\"Prepared recipe: {rec_fit}\")\n",
    "print(f\"Prepared steps: {len(rec_fit.prepared_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original train data (first 3 rows):\n",
      "         sales      price  advertising\n",
      "0  5496.714153  53.577874          NaN\n",
      "1  4861.735699  55.607845   700.312489\n",
      "2  5647.688538  60.830512  1002.621850\n",
      "\n",
      "Transformed train data (first 3 rows):\n",
      "      sales     price  advertising\n",
      "0  0.604468  0.312385          NaN\n",
      "1 -0.075690  0.521598    -0.487344\n",
      "2  0.766184  1.059858     0.114993\n",
      "\n",
      "Means after normalization:\n",
      "sales          1.665335e-16\n",
      "price         -6.938894e-17\n",
      "advertising   -1.973730e-16\n",
      "temperature   -3.330669e-17\n",
      "dtype: float64\n",
      "\n",
      "Std devs after normalization:\n",
      "sales          1.00314\n",
      "price          1.00314\n",
      "advertising    1.00349\n",
      "temperature    1.00314\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply (bake) to new data\n",
    "train_transformed = rec_fit.bake(train)\n",
    "\n",
    "print(\"\\nOriginal train data (first 3 rows):\")\n",
    "print(train[[\"sales\", \"price\", \"advertising\"]].head(3))\n",
    "\n",
    "print(\"\\nTransformed train data (first 3 rows):\")\n",
    "print(train_transformed[[\"sales\", \"price\", \"advertising\"]].head(3))\n",
    "\n",
    "print(\"\\nMeans after normalization:\")\n",
    "print(train_transformed[[\"sales\", \"price\", \"advertising\", \"temperature\"]].mean())\n",
    "\n",
    "print(\"\\nStd devs after normalization:\")\n",
    "print(train_transformed[[\"sales\", \"price\", \"advertising\", \"temperature\"]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Point**: The recipe learns from **training data** and applies the same transformation to **test data**.\n",
    "\n",
    "This prevents **data leakage**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data means (NOT zero because fitted on train):\n",
      "sales          0.143699\n",
      "price          0.160695\n",
      "advertising    0.165710\n",
      "temperature    0.202324\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply the SAME fitted recipe to test data\n",
    "test_transformed = rec_fit.bake(test)\n",
    "\n",
    "print(\"Test data means (NOT zero because fitted on train):\")\n",
    "print(test_transformed[[\"sales\", \"price\", \"advertising\", \"temperature\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Normalization (step_normalize) <a id=\"normalization\"></a>\n",
    "\n",
    "Normalize numeric columns using:\n",
    "- **zscore** (default): standardization (mean=0, std=1)\n",
    "- **minmax**: scaling to [0, 1] range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score normalized columns:\n",
      "              price   advertising\n",
      "count  1.600000e+02  1.440000e+02\n",
      "mean  -6.938894e-17 -1.973730e-16\n",
      "std    1.003140e+00  1.003490e+00\n",
      "min   -3.396881e+00 -2.352548e+00\n",
      "25%   -7.055730e-01 -6.926009e-01\n",
      "50%    1.273539e-02  3.246156e-02\n",
      "75%    6.305484e-01  6.796979e-01\n",
      "max    3.914352e+00  3.177030e+00\n"
     ]
    }
   ],
   "source": [
    "# Normalize specific columns\n",
    "rec_zscore = (\n",
    "    recipe()\n",
    "    .step_normalize(columns=[\"price\", \"advertising\"], method=\"zscore\")\n",
    ")\n",
    "\n",
    "rec_zscore_fit = rec_zscore.prep(train)\n",
    "train_zscore = rec_zscore_fit.bake(train)\n",
    "\n",
    "print(\"Z-score normalized columns:\")\n",
    "print(train_zscore[[\"price\", \"advertising\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax normalized columns:\n",
      "            price  advertising\n",
      "count  160.000000   144.000000\n",
      "mean     0.464611     0.425448\n",
      "std      0.137205     0.181477\n",
      "min      0.000000     0.000000\n",
      "25%      0.368106     0.300194\n",
      "50%      0.466353     0.431319\n",
      "75%      0.550855     0.548368\n",
      "max      1.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# MinMax scaling [0, 1]\n",
    "rec_minmax = (\n",
    "    recipe()\n",
    "    .step_normalize(columns=[\"price\", \"advertising\"], method=\"minmax\")\n",
    ")\n",
    "\n",
    "rec_minmax_fit = rec_minmax.prep(train)\n",
    "train_minmax = rec_minmax_fit.bake(train)\n",
    "\n",
    "print(\"MinMax normalized columns:\")\n",
    "print(train_minmax[[\"price\", \"advertising\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Dummy Variables (step_dummy) <a id=\"dummy\"></a>\n",
    "\n",
    "Convert categorical variables to one-hot encoded dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "  store_type region\n",
      "0     Street  North\n",
      "1     Online  South\n",
      "2     Street  North\n",
      "3     Online   East\n",
      "4       Mall   East\n",
      "\n",
      "Unique store types: ['Street' 'Online' 'Mall']\n",
      "Unique regions: ['North' 'South' 'East' 'West']\n"
     ]
    }
   ],
   "source": [
    "# Original categorical columns\n",
    "print(\"Original data:\")\n",
    "print(train[[\"store_type\", \"region\"]].head())\n",
    "print(f\"\\nUnique store types: {train['store_type'].unique()}\")\n",
    "print(f\"Unique regions: {train['region'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dummy encoding:\n",
      "\n",
      "New columns:\n",
      "['store_type_Mall', 'store_type_Online', 'store_type_Street', 'region_East', 'region_North', 'region_South', 'region_West']\n",
      "\n",
      "First few rows of dummy variables:\n",
      "   store_type_Mall  store_type_Online  store_type_Street  region_East  \\\n",
      "0              0.0                0.0                1.0          0.0   \n",
      "1              0.0                1.0                0.0          0.0   \n",
      "2              0.0                0.0                1.0          0.0   \n",
      "3              0.0                1.0                0.0          1.0   \n",
      "4              1.0                0.0                0.0          1.0   \n",
      "\n",
      "   region_North  region_South  region_West  \n",
      "0           1.0           0.0          0.0  \n",
      "1           0.0           1.0          0.0  \n",
      "2           1.0           0.0          0.0  \n",
      "3           0.0           0.0          0.0  \n",
      "4           0.0           0.0          0.0  \n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns\n",
    "rec_dummy = (\n",
    "    recipe()\n",
    "    .step_dummy([\"store_type\", \"region\"])\n",
    ")\n",
    "\n",
    "rec_dummy_fit = rec_dummy.prep(train)\n",
    "train_dummy = rec_dummy_fit.bake(train)\n",
    "\n",
    "print(\"After dummy encoding:\")\n",
    "print(\"\\nNew columns:\")\n",
    "dummy_cols = [col for col in train_dummy.columns if \"store_type\" in col or \"region\" in col]\n",
    "print(dummy_cols)\n",
    "\n",
    "print(\"\\nFirst few rows of dummy variables:\")\n",
    "print(train_dummy[dummy_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Original categorical columns are removed after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'store_type' in columns: False\n",
      "'region' in columns: False\n"
     ]
    }
   ],
   "source": [
    "# Check that original columns are gone\n",
    "print(\"'store_type' in columns:\", \"store_type\" in train_dummy.columns)\n",
    "print(\"'region' in columns:\", \"region\" in train_dummy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Missing Value Imputation <a id=\"imputation\"></a>\n",
    "\n",
    "Handle missing values with:\n",
    "- **step_impute_mean()**: Replace NA with column mean\n",
    "- **step_impute_median()**: Replace NA with column median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "sales           0\n",
      "price           0\n",
      "advertising    16\n",
      "temperature     0\n",
      "store_type      0\n",
      "region          0\n",
      "dtype: int64\n",
      "\n",
      "Missing in 'advertising': 16 out of 160\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(train.isna().sum())\n",
    "\n",
    "print(f\"\\nMissing in 'advertising': {train['advertising'].isna().sum()} out of {len(train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mean imputation:\n",
      "Missing values: 0\n",
      "\n",
      "Original mean: 944.91\n",
      "After imputation mean: 944.91\n"
     ]
    }
   ],
   "source": [
    "# Impute with mean\n",
    "rec_impute_mean = (\n",
    "    recipe()\n",
    "    .step_impute_mean(columns=[\"advertising\"])\n",
    ")\n",
    "\n",
    "rec_impute_mean_fit = rec_impute_mean.prep(train)\n",
    "train_imputed = rec_impute_mean_fit.bake(train)\n",
    "\n",
    "print(\"After mean imputation:\")\n",
    "print(f\"Missing values: {train_imputed['advertising'].isna().sum()}\")\n",
    "\n",
    "print(f\"\\nOriginal mean: {train['advertising'].mean():.2f}\")\n",
    "print(f\"After imputation mean: {train_imputed['advertising'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After median imputation:\n",
      "Missing values: 0\n",
      "\n",
      "Original median: 961.20\n",
      "After imputation median: 961.20\n"
     ]
    }
   ],
   "source": [
    "# Impute with median\n",
    "rec_impute_median = (\n",
    "    recipe()\n",
    "    .step_impute_median(columns=[\"advertising\"])\n",
    ")\n",
    "\n",
    "rec_impute_median_fit = rec_impute_median.prep(train)\n",
    "train_imputed_median = rec_impute_median_fit.bake(train)\n",
    "\n",
    "print(\"After median imputation:\")\n",
    "print(f\"Missing values: {train_imputed_median['advertising'].isna().sum()}\")\n",
    "\n",
    "print(f\"\\nOriginal median: {train['advertising'].median():.2f}\")\n",
    "print(f\"After imputation median: {train_imputed_median['advertising'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Custom Transformations (step_mutate) <a id=\"mutate\"></a>\n",
    "\n",
    "Create new features using custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns created:\n",
      "   price_squared  price_x_advertising  log_sales\n",
      "0    2870.588540                  NaN   8.611906\n",
      "1    3092.232455         38942.868498   8.489151\n",
      "2    3700.351243         60990.000902   8.639002\n",
      "3    3664.851929         61960.076595   8.783094\n",
      "4    1312.127921         28071.876602   8.469230\n",
      "\n",
      "Original columns preserved:\n",
      "       price  advertising        sales\n",
      "0  53.577874          NaN  5496.714153\n",
      "1  55.607845   700.312489  4861.735699\n",
      "2  60.830512  1002.621850  5647.688538\n",
      "3  60.538021  1023.490297  6523.029856\n",
      "4  36.223306   774.967264  4765.846625\n"
     ]
    }
   ],
   "source": [
    "# Create engineered features\n",
    "rec_mutate = (\n",
    "    recipe()\n",
    "    .step_mutate({\n",
    "        \"price_squared\": lambda df: df[\"price\"] ** 2,\n",
    "        \"price_x_advertising\": lambda df: df[\"price\"] * df[\"advertising\"],\n",
    "        \"log_sales\": lambda df: np.log(df[\"sales\"])\n",
    "    })\n",
    ")\n",
    "\n",
    "rec_mutate_fit = rec_mutate.prep(train)\n",
    "train_mutated = rec_mutate_fit.bake(train)\n",
    "\n",
    "print(\"New columns created:\")\n",
    "new_cols = [\"price_squared\", \"price_x_advertising\", \"log_sales\"]\n",
    "print(train_mutated[new_cols].head())\n",
    "\n",
    "print(\"\\nOriginal columns preserved:\")\n",
    "print(train_mutated[[\"price\", \"advertising\", \"sales\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Multi-Step Pipelines <a id=\"pipelines\"></a>\n",
    "\n",
    "Chain multiple preprocessing steps together.\n",
    "\n",
    "**Order matters!** Steps are applied sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline has 4 steps:\n",
      "  1. StepImputeMean\n",
      "  2. StepMutate\n",
      "  3. StepNormalize\n",
      "  4. StepDummy\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive preprocessing pipeline\n",
    "rec_pipeline = (\n",
    "    recipe()\n",
    "    # 1. Handle missing values first\n",
    "    .step_impute_mean()\n",
    "    # 2. Create new features\n",
    "    .step_mutate({\n",
    "        \"price_squared\": lambda df: df[\"price\"] ** 2,\n",
    "        \"log_advertising\": lambda df: np.log(df[\"advertising\"] + 1)\n",
    "    })\n",
    "    # 3. Normalize numeric columns\n",
    "    .step_normalize()\n",
    "    # 4. Encode categorical variables\n",
    "    .step_dummy([\"store_type\", \"region\"])\n",
    ")\n",
    "\n",
    "print(f\"Pipeline has {len(rec_pipeline.steps)} steps:\")\n",
    "for i, step in enumerate(rec_pipeline.steps, 1):\n",
    "    print(f\"  {i}. {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train shape: (160, 6)\n",
      "Final train shape: (160, 13)\n",
      "\n",
      "Final columns: ['sales', 'price', 'advertising', 'temperature', 'price_squared', 'log_advertising', 'store_type_Mall', 'store_type_Online', 'store_type_Street', 'region_East', 'region_North', 'region_South', 'region_West']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewdeane/Documents/Data Science/python/_projects/py-tidymodels/py-tidymodels2/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/matthewdeane/Documents/Data Science/python/_projects/py-tidymodels/py-tidymodels2/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/matthewdeane/Documents/Data Science/python/_projects/py-tidymodels/py-tidymodels2/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Fit the entire pipeline\n",
    "rec_pipeline_fit = rec_pipeline.prep(train)\n",
    "\n",
    "# Apply to train\n",
    "train_final = rec_pipeline_fit.bake(train)\n",
    "\n",
    "# Apply to test\n",
    "test_final = rec_pipeline_fit.bake(test)\n",
    "\n",
    "print(f\"Original train shape: {train.shape}\")\n",
    "print(f\"Final train shape: {train_final.shape}\")\n",
    "print(f\"\\nFinal columns: {list(train_final.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after pipeline:\n",
      "4\n",
      "\n",
      "Numeric column statistics:\n",
      "             sales         price   advertising   temperature  price_squared  \\\n",
      "mean  1.665335e-16 -6.938894e-17 -4.218847e-16 -3.330669e-17  -3.719247e-16   \n",
      "std   1.003140e+00  1.003140e+00  1.003140e+00  1.003140e+00   1.003140e+00   \n",
      "\n",
      "      log_advertising  \n",
      "mean     9.792736e-16  \n",
      "std      1.003221e+00  \n"
     ]
    }
   ],
   "source": [
    "# Verify no missing values and standardization\n",
    "print(\"Missing values after pipeline:\")\n",
    "print(train_final.isna().sum().sum())\n",
    "\n",
    "print(\"\\nNumeric column statistics:\")\n",
    "numeric_cols = [\"sales\", \"price\", \"advertising\", \"temperature\", \"price_squared\", \"log_advertising\"]\n",
    "print(train_final[numeric_cols].describe().loc[[\"mean\", \"std\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Integration with Workflows <a id=\"workflows\"></a>\n",
    "\n",
    "Recipes integrate seamlessly with **py-workflows** for complete modeling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow created with recipe preprocessing\n",
      "Preprocessor: Recipe\n",
      "Model: linear_reg\n"
     ]
    }
   ],
   "source": [
    "# Create recipe\n",
    "rec_for_model = (\n",
    "    recipe()\n",
    "    .step_impute_mean()\n",
    "    .step_normalize(columns=[\"price\", \"advertising\", \"temperature\"])\n",
    "    .step_dummy([\"store_type\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create workflow\n",
    "wf = (\n",
    "    workflow()\n",
    "    .add_recipe(rec_for_model)\n",
    "    .add_model(linear_reg().set_engine(\"sklearn\"))\n",
    ")\n",
    "\n",
    "print(\"Workflow created with recipe preprocessing\")\n",
    "print(f\"Preprocessor: {type(wf.preprocessor).__name__}\")\n",
    "print(f\"Model: {wf.spec.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow fitted successfully\n",
      "Preprocessor type: PreparedRecipe\n"
     ]
    }
   ],
   "source": [
    "# Fit workflow (recipe is automatically prepped)\n",
    "wf_fit = wf.fit(train)\n",
    "\n",
    "print(\"Workflow fitted successfully\")\n",
    "print(f\"Preprocessor type: {type(wf_fit.pre).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "         .pred\n",
      "0  5097.223413\n",
      "1  4473.059352\n",
      "2  4710.019172\n",
      "3  5189.366138\n",
      "4  4753.120466\n",
      "\n",
      "Prediction shape: (40, 1)\n",
      "Test data shape: (40, 6)\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data (recipe is automatically applied)\n",
    "predictions = wf_fit.predict(test)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(predictions.head())\n",
    "\n",
    "print(f\"\\nPrediction shape: {predictions.shape}\")\n",
    "print(f\"Test data shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs DataFrame (observation-level):\n",
      "       actuals       fitted     forecast    residuals  split       model  \\\n",
      "0  5496.714153  4925.901109  5496.714153  5496.714153  train  linear_reg   \n",
      "1  4861.735699  5250.933675  4861.735699  4861.735699  train  linear_reg   \n",
      "2  5647.688538  4977.788992  5647.688538  5647.688538  train  linear_reg   \n",
      "3  6523.029856  5191.706343  6523.029856  6523.029856  train  linear_reg   \n",
      "4  4765.846625  4828.566105  4765.846625  4765.846625  train  linear_reg   \n",
      "\n",
      "  model_group_name   group  \n",
      "0                   global  \n",
      "1                   global  \n",
      "2                   global  \n",
      "3                   global  \n",
      "4                   global  \n",
      "\n",
      "Coefficients DataFrame (variable-level):\n",
      "          variable  coefficient\n",
      "0        Intercept     0.000000\n",
      "1            price    93.253177\n",
      "2      advertising  -149.401651\n",
      "3      temperature     2.705815\n",
      "4  store_type_Mall  -134.808164\n",
      "\n",
      "Stats DataFrame (model-level):\n",
      "      metric       value  split       model model_group_name   group\n",
      "0       rmse  901.032857  train  linear_reg                   global\n",
      "1        mae  727.845329  train  linear_reg                   global\n",
      "4  r_squared      0.0685  train  linear_reg                   global\n"
     ]
    }
   ],
   "source": [
    "# Extract comprehensive outputs\n",
    "outputs, coefficients, stats = wf_fit.extract_outputs()\n",
    "\n",
    "print(\"Outputs DataFrame (observation-level):\")\n",
    "print(outputs.head())\n",
    "\n",
    "print(\"\\nCoefficients DataFrame (variable-level):\")\n",
    "print(coefficients[[\"variable\", \"coefficient\"]].head())\n",
    "\n",
    "print(\"\\nStats DataFrame (model-level):\")\n",
    "print(stats[stats[\"metric\"].isin([\"rmse\", \"mae\", \"r_squared\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Complete Example: Train/Test Evaluation <a id=\"complete\"></a>\n",
    "\n",
    "A full example showing recipe → workflow → evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete workflow fitted and evaluated!\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive recipe\n",
    "final_recipe = (\n",
    "    recipe()\n",
    "    # 1. Impute missing values\n",
    "    .step_impute_mean()\n",
    "    # 2. Engineer features\n",
    "    .step_mutate({\n",
    "        \"price_squared\": lambda df: df[\"price\"] ** 2,\n",
    "        \"temp_x_price\": lambda df: df[\"temperature\"] * df[\"price\"]\n",
    "    })\n",
    "    # 3. Normalize all numeric columns\n",
    "    .step_normalize()\n",
    "    # 4. Encode categories\n",
    "    .step_dummy([\"store_type\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create workflow\n",
    "final_wf = (\n",
    "    workflow()\n",
    "    .add_recipe(final_recipe)\n",
    "    .add_model(linear_reg().set_engine(\"sklearn\"))\n",
    ")\n",
    "\n",
    "# Fit on train\n",
    "final_wf_fit = final_wf.fit(train)\n",
    "\n",
    "# Evaluate on test\n",
    "final_wf_fit = final_wf_fit.evaluate(test)\n",
    "\n",
    "print(\"Complete workflow fitted and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OUTPUTS DATAFRAME (observation-level)\n",
      "============================================================\n",
      "Total observations: 200\n",
      "Train: 160\n",
      "Test: 40\n",
      "\n",
      "First few rows:\n",
      "    actuals  forecast  residuals  split\n",
      "0  0.604468  0.604468   0.604468  train\n",
      "1 -0.075690 -0.075690  -0.075690  train\n",
      "2  0.766184  0.766184   0.766184  train\n",
      "3  1.703807  1.703807   1.703807  train\n",
      "4 -0.178402 -0.178402  -0.178402  train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewdeane/Documents/Data Science/python/_projects/py-tidymodels/py_parsnip/engines/sklearn_linear_reg.py:325: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std_errors = np.sqrt(var_coef)\n"
     ]
    }
   ],
   "source": [
    "# Extract all outputs\n",
    "outputs, coefficients, stats = final_wf_fit.extract_outputs()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OUTPUTS DATAFRAME (observation-level)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total observations: {len(outputs)}\")\n",
    "print(f\"Train: {len(outputs[outputs['split']=='train'])}\")\n",
    "print(f\"Test: {len(outputs[outputs['split']=='test'])}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(outputs[[\"actuals\", \"forecast\", \"residuals\", \"split\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COEFFICIENTS DATAFRAME (variable-level)\n",
      "============================================================\n",
      "             variable  coefficient\n",
      "0           Intercept     0.000000\n",
      "1               price     0.074952\n",
      "2         advertising    -0.167890\n",
      "3         temperature     0.296053\n",
      "4       price_squared     0.107954\n",
      "5        temp_x_price    -0.302534\n",
      "6     store_type_Mall    -0.139166\n",
      "7   store_type_Online     0.076976\n",
      "8   store_type_Street     0.062190\n",
      "9         region_East     0.130784\n",
      "10       region_North    -0.108576\n",
      "11       region_South     0.132182\n",
      "12        region_West    -0.154390\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COEFFICIENTS DATAFRAME (variable-level)\")\n",
    "print(\"=\"*60)\n",
    "print(coefficients[[\"variable\", \"coefficient\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STATS DATAFRAME (model-level metrics)\n",
      "============================================================\n",
      "\n",
      "Performance Metrics:\n",
      "\n",
      "TRAIN:\n",
      "  rmse: 0.9635\n",
      "  mae: 0.7816\n",
      "  r_squared: 0.0716\n",
      "\n",
      "TEST:\n",
      "  rmse: 1.1116\n",
      "  mae: 0.8833\n",
      "  r_squared: -0.3272\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STATS DATAFRAME (model-level metrics)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Performance metrics\n",
    "perf_metrics = stats[stats[\"metric\"].isin([\"rmse\", \"mae\", \"r_squared\"])]\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "for split in [\"train\", \"test\"]:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    split_metrics = perf_metrics[perf_metrics[\"split\"] == split]\n",
    "    for _, row in split_metrics.iterrows():\n",
    "        print(f\"  {row['metric']}: {row['value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Recipe:\n",
      "Type: PreparedRecipe\n",
      "Number of prepared steps: 4\n",
      "\n",
      "Transformed shape: (40, 13)\n"
     ]
    }
   ],
   "source": [
    "# Extract the fitted recipe for inspection\n",
    "fitted_recipe = final_wf_fit.extract_preprocessor()\n",
    "\n",
    "print(\"Fitted Recipe:\")\n",
    "print(f\"Type: {type(fitted_recipe).__name__}\")\n",
    "print(f\"Number of prepared steps: {len(fitted_recipe.prepared_steps)}\")\n",
    "\n",
    "# Can use the fitted recipe independently\n",
    "new_data_transformed = fitted_recipe.bake(test)\n",
    "print(f\"\\nTransformed shape: {new_data_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**py-recipes** provides a powerful, composable system for feature engineering:\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **No Data Leakage**: Preprocessing fitted on train, applied to test\n",
    "2. **Reproducible**: Same transformations applied consistently\n",
    "3. **Composable**: Chain multiple steps together\n",
    "4. **Integrated**: Works seamlessly with py-workflows\n",
    "5. **Method Chaining**: Clean, readable syntax\n",
    "\n",
    "### Available Steps\n",
    "\n",
    "- `step_normalize()`: zscore or minmax normalization\n",
    "- `step_dummy()`: one-hot encoding\n",
    "- `step_impute_mean()`: mean imputation\n",
    "- `step_impute_median()`: median imputation\n",
    "- `step_mutate()`: custom transformations\n",
    "\n",
    "### Pattern\n",
    "\n",
    "```python\n",
    "# 1. Create recipe\n",
    "rec = recipe().step_normalize().step_dummy([\"category\"])\n",
    "\n",
    "# 2. Fit to training data\n",
    "rec_fit = rec.prep(train)\n",
    "\n",
    "# 3. Apply to any data\n",
    "train_transformed = rec_fit.bake(train)\n",
    "test_transformed = rec_fit.bake(test)\n",
    "```\n",
    "\n",
    "### Integration with Workflows\n",
    "\n",
    "```python\n",
    "wf = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg().set_engine(\"sklearn\"))\n",
    ")\n",
    "wf_fit = wf.fit(train).evaluate(test)\n",
    "outputs, coefficients, stats = wf_fit.extract_outputs()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore `08_workflows_demo.ipynb` for more workflow examples\n",
    "- Check `02_parsnip_demo.ipynb` for model specifications\n",
    "- See `07_rsample_demo.ipynb` for time series cross-validation\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
