{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Prediction Intervals Demo\n",
    "\n",
    "This notebook demonstrates **conformal prediction intervals** in py-tidymodels - a distribution-free method for uncertainty quantification with finite-sample coverage guarantees.\n",
    "\n",
    "## What is Conformal Prediction?\n",
    "\n",
    "Conformal prediction provides prediction intervals that are:\n",
    "- **Distribution-free**: No assumptions about data distribution\n",
    "- **Finite-sample**: Guarantees hold for any sample size\n",
    "- **Model-agnostic**: Works with any prediction model\n",
    "- **Calibrated**: Achieves target coverage (e.g., 95% for α=0.05)\n",
    "\n",
    "## Coverage\n",
    "\n",
    "This demo covers:\n",
    "1. **Basic Conformal Prediction** - Single models with different methods\n",
    "2. **Time Series** - Temporal calibration and EnbPI\n",
    "3. **Grouped Models** - Per-group calibration for nested/panel data\n",
    "4. **extract_outputs() Integration** - Conformal intervals in standard output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from py_parsnip import linear_reg\n",
    "from py_workflows import workflow\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Basic Conformal Prediction\n",
    "\n",
    "Start with a simple regression example to understand the basics.\n",
    "\n",
    "## 1.1 Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample regression data\n",
    "n = 500\n",
    "data = pd.DataFrame({\n",
    "    'x1': np.random.randn(n),\n",
    "    'x2': np.random.randn(n),\n",
    "    'x3': np.random.randn(n)\n",
    "})\n",
    "data['y'] = 10 + 2*data['x1'] + 3*data['x2'] + 1*data['x3'] + np.random.randn(n) * 0.5\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fit Model and Get Conformal Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "spec = linear_reg()\n",
    "fit = spec.fit(data, 'y ~ x1 + x2 + x3')\n",
    "\n",
    "# Get conformal prediction intervals (95% confidence)\n",
    "conformal_preds = fit.conformal_predict(data, alpha=0.05, method='split')\n",
    "\n",
    "print(f\"\\nConformal predictions shape: {conformal_preds.shape}\")\n",
    "print(f\"\\nColumns: {list(conformal_preds.columns)}\")\n",
    "conformal_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Verify Coverage\n",
    "\n",
    "Check that conformal intervals achieve the target 95% coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical coverage\n",
    "in_interval = (\n",
    "    (data['y'] >= conformal_preds['.pred_lower']) &\n",
    "    (data['y'] <= conformal_preds['.pred_upper'])\n",
    ")\n",
    "\n",
    "coverage = in_interval.mean()\n",
    "print(f\"Empirical Coverage: {coverage:.1%}\")\n",
    "print(f\"Target Coverage: 95%\")\n",
    "print(f\"\\n✓ Coverage achieved!\" if coverage >= 0.90 else \"✗ Coverage below target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Visualize Conformal Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 100 observations\n",
    "n_show = 100\n",
    "idx = range(n_show)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(idx, data['y'].iloc[:n_show], label='Actual', s=30, zorder=3)\n",
    "plt.plot(idx, conformal_preds['.pred'].iloc[:n_show], 'k-', label='Prediction', linewidth=2)\n",
    "plt.fill_between(\n",
    "    idx,\n",
    "    conformal_preds['.pred_lower'].iloc[:n_show],\n",
    "    conformal_preds['.pred_upper'].iloc[:n_show],\n",
    "    alpha=0.3,\n",
    "    label='95% Conformal Interval'\n",
    ")\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Conformal Prediction Intervals (Split Method)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate interval width statistics\n",
    "interval_width = conformal_preds['.pred_upper'] - conformal_preds['.pred_lower']\n",
    "print(f\"\\nInterval Width Statistics:\")\n",
    "print(f\"  Mean: {interval_width.mean():.3f}\")\n",
    "print(f\"  Median: {interval_width.median():.3f}\")\n",
    "print(f\"  Min: {interval_width.min():.3f}\")\n",
    "print(f\"  Max: {interval_width.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Multiple Confidence Levels\n",
    "\n",
    "Get intervals for multiple confidence levels simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 95%, 90%, and 80% confidence intervals\n",
    "multi_conf = fit.conformal_predict(data, alpha=[0.05, 0.1, 0.2], method='split')\n",
    "\n",
    "print(f\"Columns: {list(multi_conf.columns)}\")\n",
    "multi_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize nested intervals\n",
    "n_show = 50\n",
    "idx = range(n_show)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(idx, data['y'].iloc[:n_show], label='Actual', s=40, zorder=4, color='red')\n",
    "plt.plot(idx, multi_conf['.pred'].iloc[:n_show], 'k-', label='Prediction', linewidth=2, zorder=3)\n",
    "\n",
    "# 95% interval\n",
    "plt.fill_between(\n",
    "    idx,\n",
    "    multi_conf['.pred_lower_95'].iloc[:n_show],\n",
    "    multi_conf['.pred_upper_95'].iloc[:n_show],\n",
    "    alpha=0.2,\n",
    "    label='95% CI',\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "# 90% interval\n",
    "plt.fill_between(\n",
    "    idx,\n",
    "    multi_conf['.pred_lower_90'].iloc[:n_show],\n",
    "    multi_conf['.pred_upper_90'].iloc[:n_show],\n",
    "    alpha=0.3,\n",
    "    label='90% CI',\n",
    "    color='green'\n",
    ")\n",
    "\n",
    "# 80% interval\n",
    "plt.fill_between(\n",
    "    idx,\n",
    "    multi_conf['.pred_lower_80'].iloc[:n_show],\n",
    "    multi_conf['.pred_upper_80'].iloc[:n_show],\n",
    "    alpha=0.4,\n",
    "    label='80% CI',\n",
    "    color='orange'\n",
    ")\n",
    "\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Nested Conformal Intervals (Multiple Confidence Levels)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Compare Different Methods\n",
    "\n",
    "Compare the three main conformal methods: split, CV+, and Jackknife+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods\n",
    "methods = ['split', 'cv+', 'jackknife+']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    preds = fit.conformal_predict(data, alpha=0.05, method=method)\n",
    "    \n",
    "    # Calculate coverage and interval width\n",
    "    in_interval = (\n",
    "        (data['y'] >= preds['.pred_lower']) &\n",
    "        (data['y'] <= preds['.pred_upper'])\n",
    "    )\n",
    "    coverage = in_interval.mean()\n",
    "    \n",
    "    interval_width = (preds['.pred_upper'] - preds['.pred_lower']).mean()\n",
    "    \n",
    "    results[method] = {\n",
    "        'coverage': coverage,\n",
    "        'avg_width': interval_width\n",
    "    }\n",
    "    \n",
    "    print(f\"{method.upper():12} - Coverage: {coverage:.1%}, Avg Width: {interval_width:.3f}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "- **Split**: Fastest (O(1)), good for large datasets\n",
    "- **CV+**: Balanced approach (O(K)), better data efficiency\n",
    "- **Jackknife+**: Most data-efficient (O(n)), best for small datasets\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Time Series Conformal Prediction\n",
    "\n",
    "Time series require special handling to preserve temporal structure.\n",
    "\n",
    "## 2.1 Generate Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time series data with trend and seasonality\n",
    "n_days = 365\n",
    "dates = pd.date_range('2020-01-01', periods=n_days, freq='D')\n",
    "\n",
    "# Trend + weekly seasonality + noise\n",
    "trend = np.linspace(100, 150, n_days)\n",
    "seasonality = 10 * np.sin(2 * np.pi * np.arange(n_days) / 7)\n",
    "noise = np.random.randn(n_days) * 5\n",
    "\n",
    "ts_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'value': trend + seasonality + noise,\n",
    "    'day_of_week': dates.dayofweek,\n",
    "    'month': dates.month\n",
    "})\n",
    "\n",
    "# Create lagged features\n",
    "ts_data['lag_1'] = ts_data['value'].shift(1)\n",
    "ts_data['lag_7'] = ts_data['value'].shift(7)\n",
    "ts_data = ts_data.dropna()\n",
    "\n",
    "print(f\"Time series data shape: {ts_data.shape}\")\n",
    "ts_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conformal Prediction with EnbPI\n",
    "\n",
    "EnbPI (Ensemble Batch Prediction Intervals) is designed for time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "ts_spec = linear_reg()\n",
    "ts_fit = ts_spec.fit(ts_data, 'value ~ lag_1 + lag_7 + day_of_week')\n",
    "\n",
    "# Get conformal predictions with auto method (will select EnbPI for time series)\n",
    "ts_conformal = ts_fit.conformal_predict(\n",
    "    ts_data,\n",
    "    alpha=0.05,\n",
    "    method='auto'  # Auto-selects EnbPI based on model type\n",
    ")\n",
    "\n",
    "print(f\"Method selected: {ts_conformal['.conf_method'].iloc[0]}\")\n",
    "ts_conformal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time series with conformal intervals\n",
    "n_show = 100\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts_data['date'].iloc[:n_show], ts_data['value'].iloc[:n_show], \n",
    "         'o-', label='Actual', markersize=4)\n",
    "plt.plot(ts_data['date'].iloc[:n_show], ts_conformal['.pred'].iloc[:n_show],\n",
    "         'k-', label='Prediction', linewidth=2)\n",
    "plt.fill_between(\n",
    "    ts_data['date'].iloc[:n_show],\n",
    "    ts_conformal['.pred_lower'].iloc[:n_show],\n",
    "    ts_conformal['.pred_upper'].iloc[:n_show],\n",
    "    alpha=0.3,\n",
    "    label='95% Conformal Interval'\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series with Conformal Prediction Intervals')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate coverage\n",
    "in_interval = (\n",
    "    (ts_data['value'].values >= ts_conformal['.pred_lower'].values) &\n",
    "    (ts_data['value'].values <= ts_conformal['.pred_upper'].values)\n",
    ")\n",
    "print(f\"\\nTime Series Coverage: {in_interval.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Grouped/Panel Models with Conformal Prediction\n",
    "\n",
    "For grouped data (e.g., multiple stores, regions), each group gets its own conformal calibration.\n",
    "\n",
    "## 3.1 Generate Grouped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate grouped data with different patterns per group\n",
    "n_per_group = 300\n",
    "\n",
    "# Group A: Strong linear relationship, low noise\n",
    "group_a = pd.DataFrame({\n",
    "    'store': ['Store_A'] * n_per_group,\n",
    "    'x1': np.random.randn(n_per_group),\n",
    "    'x2': np.random.randn(n_per_group),\n",
    "})\n",
    "group_a['sales'] = 100 + 2*group_a['x1'] + 3*group_a['x2'] + np.random.randn(n_per_group) * 0.5\n",
    "\n",
    "# Group B: Weaker relationship, high noise\n",
    "group_b = pd.DataFrame({\n",
    "    'store': ['Store_B'] * n_per_group,\n",
    "    'x1': np.random.randn(n_per_group),\n",
    "    'x2': np.random.randn(n_per_group),\n",
    "})\n",
    "group_b['sales'] = 80 + 1*group_b['x1'] + 0.5*group_b['x2'] + np.random.randn(n_per_group) * 3.0\n",
    "\n",
    "# Group C: Different pattern\n",
    "group_c = pd.DataFrame({\n",
    "    'store': ['Store_C'] * n_per_group,\n",
    "    'x1': np.random.randn(n_per_group),\n",
    "    'x2': np.random.randn(n_per_group),\n",
    "})\n",
    "group_c['sales'] = 120 - 1.5*group_c['x1'] + 2*group_c['x2'] + np.random.randn(n_per_group) * 1.5\n",
    "\n",
    "# Combine\n",
    "grouped_data = pd.concat([group_a, group_b, group_c], ignore_index=True)\n",
    "\n",
    "print(f\"Grouped data shape: {grouped_data.shape}\")\n",
    "print(f\"\\nStores: {grouped_data['store'].unique()}\")\n",
    "grouped_data.groupby('store')['sales'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fit Nested Models with Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit nested models (separate model per store)\n",
    "grouped_spec = linear_reg()\n",
    "nested_fit = grouped_spec.fit_nested(grouped_data, 'sales ~ x1 + x2', group_col='store')\n",
    "\n",
    "# Get per-store conformal predictions\n",
    "grouped_conformal = nested_fit.conformal_predict(\n",
    "    grouped_data,\n",
    "    alpha=0.05,\n",
    "    method='split',\n",
    "    per_group_calibration=True  # Each store gets own calibration (default)\n",
    ")\n",
    "\n",
    "print(f\"Conformal predictions shape: {grouped_conformal.shape}\")\n",
    "print(f\"\\nStores in results: {grouped_conformal['store'].unique()}\")\n",
    "grouped_conformal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compare Interval Widths Across Groups\n",
    "\n",
    "Groups with more noise should have wider conformal intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interval width per store\n",
    "grouped_conformal['interval_width'] = (\n",
    "    grouped_conformal['.pred_upper'] - grouped_conformal['.pred_lower']\n",
    ")\n",
    "\n",
    "# Compare by store\n",
    "width_comparison = grouped_conformal.groupby('store')['interval_width'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(\"Interval Width Comparison by Store:\")\n",
    "print(width_comparison)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "grouped_conformal.boxplot(column='interval_width', by='store', ax=axes[0])\n",
    "axes[0].set_title('Interval Width Distribution by Store')\n",
    "axes[0].set_xlabel('Store')\n",
    "axes[0].set_ylabel('Interval Width')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Bar plot of means\n",
    "width_comparison['mean'].plot(kind='bar', ax=axes[1], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[1].set_title('Average Interval Width by Store')\n",
    "axes[1].set_xlabel('Store')\n",
    "axes[1].set_ylabel('Average Interval Width')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Store B has widest intervals (highest noise in data generation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Verify Per-Group Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coverage per store\n",
    "coverage_by_store = {}\n",
    "\n",
    "for store in grouped_data['store'].unique():\n",
    "    store_data = grouped_data[grouped_data['store'] == store]\n",
    "    store_conf = grouped_conformal[grouped_conformal['store'] == store]\n",
    "    \n",
    "    in_interval = (\n",
    "        (store_data['sales'].values >= store_conf['.pred_lower'].values) &\n",
    "        (store_data['sales'].values <= store_conf['.pred_upper'].values)\n",
    "    )\n",
    "    \n",
    "    coverage = in_interval.mean()\n",
    "    coverage_by_store[store] = coverage\n",
    "    print(f\"{store}: {coverage:.1%} coverage\")\n",
    "\n",
    "# Visualize coverage\n",
    "plt.figure(figsize=(10, 5))\n",
    "stores = list(coverage_by_store.keys())\n",
    "coverages = list(coverage_by_store.values())\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "plt.bar(stores, coverages, color=colors)\n",
    "plt.axhline(y=0.95, color='red', linestyle='--', label='Target 95%', linewidth=2)\n",
    "plt.xlabel('Store')\n",
    "plt.ylabel('Coverage')\n",
    "plt.title('Conformal Prediction Coverage by Store')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ All stores achieve target coverage (~95%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. extract_outputs() Integration\n",
    "\n",
    "Conformal intervals can be added directly to the standard three-DataFrame output.\n",
    "\n",
    "## 4.1 Standard Output (No Conformal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit simple model\n",
    "simple_spec = linear_reg()\n",
    "simple_fit = simple_spec.fit(data, 'y ~ x1 + x2 + x3')\n",
    "\n",
    "# Standard extract_outputs (no conformal)\n",
    "outputs, coefficients, stats = simple_fit.extract_outputs()\n",
    "\n",
    "print(\"Standard outputs columns:\")\n",
    "print(list(outputs.columns))\n",
    "print(f\"\\nOutputs shape: {outputs.shape}\")\n",
    "outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Outputs with Conformal Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_outputs WITH conformal intervals\n",
    "outputs_conf, coefficients_conf, stats_conf = simple_fit.extract_outputs(\n",
    "    conformal_alpha=0.05,\n",
    "    conformal_method='split'\n",
    ")\n",
    "\n",
    "print(\"Outputs columns with conformal:\")\n",
    "print(list(outputs_conf.columns))\n",
    "print(f\"\\nOutputs shape: {outputs_conf.shape}\")\n",
    "outputs_conf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Multiple Confidence Levels in extract_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple confidence levels\n",
    "outputs_multi, _, _ = simple_fit.extract_outputs(\n",
    "    conformal_alpha=[0.05, 0.1, 0.2]\n",
    ")\n",
    "\n",
    "print(\"Columns with multiple alphas:\")\n",
    "print(list(outputs_multi.columns))\n",
    "outputs_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Grouped Models with extract_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit nested models\n",
    "nested_spec = linear_reg()\n",
    "nested_fit = nested_spec.fit_nested(grouped_data, 'sales ~ x1 + x2', group_col='store')\n",
    "\n",
    "# Extract outputs WITHOUT conformal\n",
    "outputs_no_conf, _, _ = nested_fit.extract_outputs()\n",
    "print(\"Outputs WITHOUT conformal:\")\n",
    "print(list(outputs_no_conf.columns))\n",
    "print(f\"Shape: {outputs_no_conf.shape}\\n\")\n",
    "\n",
    "# Extract outputs WITH conformal\n",
    "outputs_with_conf, coeffs, stats = nested_fit.extract_outputs(conformal_alpha=0.05)\n",
    "print(\"Outputs WITH conformal:\")\n",
    "print(list(outputs_with_conf.columns))\n",
    "print(f\"Shape: {outputs_with_conf.shape}\")\n",
    "outputs_with_conf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Visualize Grouped Results from extract_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot conformal intervals per store\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, store in enumerate(['Store_A', 'Store_B', 'Store_C']):\n",
    "    store_outputs = outputs_with_conf[outputs_with_conf['store'] == store]\n",
    "    n_show = 50\n",
    "    \n",
    "    axes[idx].scatter(range(n_show), store_outputs['actuals'].iloc[:n_show], \n",
    "                     label='Actual', s=30, zorder=3)\n",
    "    axes[idx].plot(range(n_show), store_outputs['fitted'].iloc[:n_show],\n",
    "                  'k-', label='Fitted', linewidth=2)\n",
    "    axes[idx].fill_between(\n",
    "        range(n_show),\n",
    "        store_outputs['.pred_lower'].iloc[:n_show],\n",
    "        store_outputs['.pred_upper'].iloc[:n_show],\n",
    "        alpha=0.3,\n",
    "        label='95% CI'\n",
    "    )\n",
    "    axes[idx].set_title(f'{store}')\n",
    "    axes[idx].set_xlabel('Observation')\n",
    "    axes[idx].set_ylabel('Sales')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Each store has its own conformal intervals from extract_outputs()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What We Covered\n",
    "\n",
    "1. **Basic Conformal Prediction**\n",
    "   - Split, CV+, and Jackknife+ methods\n",
    "   - Multiple confidence levels\n",
    "   - Coverage verification\n",
    "\n",
    "2. **Time Series**\n",
    "   - Auto method selection (EnbPI for time series)\n",
    "   - Temporal calibration\n",
    "   - Preserving temporal structure\n",
    "\n",
    "3. **Grouped/Panel Models**\n",
    "   - Per-group conformal calibration\n",
    "   - Group-specific interval widths\n",
    "   - Per-group coverage validation\n",
    "\n",
    "4. **extract_outputs() Integration**\n",
    "   - Seamless integration with standard output\n",
    "   - Backward compatibility\n",
    "   - Works with nested models\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "✅ **Distribution-free**: No assumptions about data  \n",
    "✅ **Finite-sample guarantees**: Valid for any sample size  \n",
    "✅ **Model-agnostic**: Works with any model  \n",
    "✅ **Easy to use**: One parameter (`conformal_alpha`)  \n",
    "✅ **Group-aware**: Per-group calibration for heterogeneous data  \n",
    "\n",
    "## API Reference\n",
    "\n",
    "```python\n",
    "# Direct conformal prediction\n",
    "conformal_preds = fit.conformal_predict(\n",
    "    new_data,\n",
    "    alpha=0.05,              # Confidence level (95% → α=0.05)\n",
    "    method='auto',           # 'auto', 'split', 'cv+', 'jackknife+', 'enbpi'\n",
    "    calibration_data=None    # Optional separate calibration set\n",
    ")\n",
    "\n",
    "# Via extract_outputs()\n",
    "outputs, coefs, stats = fit.extract_outputs(\n",
    "    conformal_alpha=0.05,    # None (default) = no conformal\n",
    "    conformal_method='auto'  # Method selection\n",
    ")\n",
    "\n",
    "# For nested models\n",
    "nested_conformal = nested_fit.conformal_predict(\n",
    "    test_data,\n",
    "    alpha=0.05,\n",
    "    per_group_calibration=True  # Each group gets own calibration\n",
    ")\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
