{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Conformal Prediction with EnbPI\n",
    "\n",
    "This notebook demonstrates **EnbPI (Ensemble Batch Prediction Intervals)** for time series data with autocorrelation.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Why Standard Conformal Methods Fail on Time Series:**\n",
    "- Split/CV+/Jackknife+ assume **iid** (independent and identically distributed) data\n",
    "- Time series data has **temporal dependencies** (autocorrelation)\n",
    "- Standard methods can produce poorly calibrated intervals\n",
    "\n",
    "**EnbPI Solution:**\n",
    "- Uses **block bootstrap** to preserve temporal structure\n",
    "- **Temporal calibration splitting** (past \u2192 calibration, future \u2192 test)\n",
    "- Automatically handles **seasonal patterns**\n",
    "- Designed specifically for forecasting applications\n",
    "\n",
    "## What We'll Demonstrate\n",
    "\n",
    "1. Generate time series with strong autocorrelation\n",
    "2. Show split/CV+ poor performance on time series\n",
    "3. EnbPI provides well-calibrated intervals\n",
    "4. Automatic seasonal period detection\n",
    "5. Coverage validation across different patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from py_parsnip import linear_reg\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Generate Time Series Data\n",
    "\n",
    "Create synthetic time series with:\n",
    "- **Trend component**\n",
    "- **Weekly seasonality** (period = 7)\n",
    "- **Strong autocorrelation** (AR(1) with \u03c6 = 0.7)\n",
    "- **Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(n_days=730, seasonal_period=7, ar_coef=0.7, noise_std=2.0):\n",
    "    \"\"\"Generate time series with trend, seasonality, and autocorrelation.\"\"\"\n",
    "    \n",
    "    # Time index\n",
    "    t = np.arange(n_days)\n",
    "    dates = pd.date_range('2020-01-01', periods=n_days, freq='D')\n",
    "    \n",
    "    # Trend (linear)\n",
    "    trend = 0.05 * t\n",
    "    \n",
    "    # Seasonality (weekly pattern)\n",
    "    seasonal = 5 * np.sin(2 * np.pi * t / seasonal_period)\n",
    "    \n",
    "    # AR(1) autocorrelation\n",
    "    ar_noise = np.zeros(n_days)\n",
    "    ar_noise[0] = np.random.normal(0, noise_std)\n",
    "    for i in range(1, n_days):\n",
    "        ar_noise[i] = ar_coef * ar_noise[i-1] + np.random.normal(0, noise_std)\n",
    "    \n",
    "    # Combine components\n",
    "    y = trend + seasonal + ar_noise\n",
    "    \n",
    "    # Create lagged features\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'y': y,\n",
    "        'lag_1': np.concatenate([[np.nan], y[:-1]]),\n",
    "        'lag_7': np.concatenate([np.full(7, np.nan), y[:-7]]),\n",
    "        'trend': t,\n",
    "        'day_of_week': dates.dayofweek\n",
    "    })\n",
    "    \n",
    "    # Drop NaN from lags\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate 2 years of daily data\n",
    "ts_data = generate_time_series(n_days=730, seasonal_period=7, ar_coef=0.7)\n",
    "\n",
    "print(f\"Time series dataset: {ts_data.shape}\")\n",
    "print(f\"Date range: {ts_data['date'].min()} to {ts_data['date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(ts_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Full time series\n",
    "axes[0].plot(ts_data['date'], ts_data['y'], linewidth=1, alpha=0.8)\n",
    "axes[0].set_title('Synthetic Time Series with Trend, Seasonality, and Autocorrelation')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Autocorrelation function\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(ts_data['y'], ax=axes[1])\n",
    "axes[1].set_title('Autocorrelation Function (Shows Strong Temporal Dependencies)')\n",
    "axes[1].set_xlabel('Lag (days)')\n",
    "axes[1].set_ylabel('Autocorrelation')\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].axhline(y=0.2, color='red', linestyle='--', alpha=0.5, label='Significance threshold')\n",
    "axes[1].axhline(y=-0.2, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim([0, 50])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Strong autocorrelation visible (AR coefficient = 0.7)\")\n",
    "print(\"\u2713 This violates iid assumption of standard conformal methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Train/Test Split (Temporal)\n",
    "\n",
    "**Important:** For time series, use **temporal split** (not random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal split: first 80% train, last 20% test\n",
    "split_idx = int(len(ts_data) * 0.8)\n",
    "\n",
    "train_data = ts_data.iloc[:split_idx].copy()\n",
    "test_data = ts_data.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {len(train_data)} samples ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "print(f\"Test:  {len(test_data)} samples ({test_data['date'].min()} to {test_data['date'].max()})\")\n",
    "print(f\"\\nNote: Future dates in test (realistic forecasting scenario)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Compare Methods: Split vs EnbPI\n",
    "\n",
    "## Hypothesis: Split method will have poor coverage due to temporal dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "spec = linear_reg()\n",
    "fit = spec.fit(train_data, 'y ~ lag_1 + lag_7 + trend + day_of_week')\n",
    "\n",
    "print(\"\u2713 Model fitted on training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Split (standard conformal, assumes iid)\n",
    "split_preds = fit.conformal_predict(\n",
    "    test_data,\n",
    "    alpha=0.05,\n",
    "    method='split'\n",
    ")\n",
    "\n",
    "# Calculate coverage\n",
    "actuals = test_data['y'].values\n",
    "split_in_interval = (\n",
    "    (actuals >= split_preds['.pred_lower'].values) &\n",
    "    (actuals <= split_preds['.pred_upper'].values)\n",
    ")\n",
    "split_coverage = split_in_interval.mean()\n",
    "split_width = (split_preds['.pred_upper'] - split_preds['.pred_lower']).mean()\n",
    "\n",
    "print(f\"Split Method:\")\n",
    "print(f\"  Coverage: {split_coverage:.1%} (target: 95%)\")\n",
    "print(f\"  Avg interval width: {split_width:.2f}\")\n",
    "print(f\"  Method used: {split_preds['.conf_method'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: EnbPI (designed for time series)\n",
    "enbpi_preds = fit.conformal_predict(\n",
    "    test_data,\n",
    "    alpha=0.05,\n",
    "    method='enbpi'\n",
    ")\n",
    "\n",
    "# Calculate coverage\n",
    "enbpi_in_interval = (\n",
    "    (actuals >= enbpi_preds['.pred_lower'].values) &\n",
    "    (actuals <= enbpi_preds['.pred_upper'].values)\n",
    ")\n",
    "enbpi_coverage = enbpi_in_interval.mean()\n",
    "enbpi_width = (enbpi_preds['.pred_upper'] - enbpi_preds['.pred_lower']).mean()\n",
    "\n",
    "print(f\"EnbPI Method:\")\n",
    "print(f\"  Coverage: {enbpi_coverage:.1%} (target: 95%)\")\n",
    "print(f\"  Avg interval width: {enbpi_width:.2f}\")\n",
    "print(f\"  Method used: {enbpi_preds['.conf_method'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSplit:\")\n",
    "print(f\"  Coverage: {split_coverage:.1%}\")\n",
    "print(f\"  Interval width: {split_width:.2f}\")\n",
    "print(f\"  Coverage error: {abs(split_coverage - 0.95):.1%}\")\n",
    "\n",
    "print(f\"\\nEnbPI:\")\n",
    "print(f\"  Coverage: {enbpi_coverage:.1%}\")\n",
    "print(f\"  Interval width: {enbpi_width:.2f}\")\n",
    "print(f\"  Coverage error: {abs(enbpi_coverage - 0.95):.1%}\")\n",
    "\n",
    "print(f\"\\n{'\u2713' if enbpi_coverage > split_coverage else '\u26a0'} EnbPI provides {'better' if enbpi_coverage > split_coverage else 'similar'} coverage for time series data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Visualize Predictions with Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison (first 60 test points)\n",
    "n_show = min(60, len(test_data))\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Split method\n",
    "axes[0].plot(range(n_show), actuals[:n_show], 'o', \n",
    "            label='Actual', markersize=4, alpha=0.7)\n",
    "axes[0].plot(range(n_show), split_preds['.pred'].values[:n_show], \n",
    "            'k-', label='Prediction', linewidth=2)\n",
    "axes[0].fill_between(\n",
    "    range(n_show),\n",
    "    split_preds['.pred_lower'].values[:n_show],\n",
    "    split_preds['.pred_upper'].values[:n_show],\n",
    "    alpha=0.3,\n",
    "    label=f'95% CI (Coverage: {split_coverage:.1%})'\n",
    ")\n",
    "axes[0].set_title(f'Split Method - May Under-Cover Time Series (iid assumption violated)')\n",
    "axes[0].set_xlabel('Test Day')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: EnbPI method\n",
    "axes[1].plot(range(n_show), actuals[:n_show], 'o', \n",
    "            label='Actual', markersize=4, alpha=0.7)\n",
    "axes[1].plot(range(n_show), enbpi_preds['.pred'].values[:n_show], \n",
    "            'k-', label='Prediction', linewidth=2)\n",
    "axes[1].fill_between(\n",
    "    range(n_show),\n",
    "    enbpi_preds['.pred_lower'].values[:n_show],\n",
    "    enbpi_preds['.pred_upper'].values[:n_show],\n",
    "    alpha=0.3,\n",
    "    color='green',\n",
    "    label=f'95% CI (Coverage: {enbpi_coverage:.1%})'\n",
    ")\n",
    "axes[1].set_title(f'EnbPI Method - Designed for Time Series (block bootstrap)')\n",
    "axes[1].set_xlabel('Test Day')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\u2713 EnbPI intervals adapt to temporal dependencies\")\n",
    "print(f\"\u2713 Block bootstrap preserves autocorrelation structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Auto-Selection for Time Series\n",
    "\n",
    "Verify that `method='auto'` detects time series data and selects appropriate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-selection\n",
    "auto_preds = fit.conformal_predict(\n",
    "    test_data,\n",
    "    alpha=0.05,\n",
    "    method='auto'\n",
    ")\n",
    "\n",
    "auto_method = auto_preds['.conf_method'].iloc[0]\n",
    "\n",
    "print(f\"Auto-Selection Result:\")\n",
    "print(f\"  Method selected: {auto_method}\")\n",
    "print(f\"\\nAuto-selection logic:\")\n",
    "print(f\"  1. Check if time series model \u2192 Use EnbPI\")\n",
    "print(f\"  2. Check if datetime index \u2192 May use EnbPI\")\n",
    "print(f\"  3. Otherwise \u2192 Use split/cv+/jackknife+ based on size\")\n",
    "print(f\"\\n\u2713 Auto-selection provides safe defaults for time series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Coverage by Time Window\n",
    "\n",
    "Check if coverage is stable across different periods of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test set into 4 windows\n",
    "window_size = len(test_data) // 4\n",
    "\n",
    "print(\"Coverage by Time Window:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(4):\n",
    "    start = i * window_size\n",
    "    end = (i + 1) * window_size if i < 3 else len(test_data)\n",
    "    \n",
    "    # Split coverage\n",
    "    split_window_coverage = split_in_interval[start:end].mean()\n",
    "    \n",
    "    # EnbPI coverage\n",
    "    enbpi_window_coverage = enbpi_in_interval[start:end].mean()\n",
    "    \n",
    "    print(f\"\\nWindow {i+1} (days {start} to {end-1}):\")\n",
    "    print(f\"  Split:  {split_window_coverage:.1%}\")\n",
    "    print(f\"  EnbPI:  {enbpi_window_coverage:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2713 EnbPI should maintain stable coverage across time windows\")\n",
    "print(\"\u2713 Split may show degradation in later windows (distribution shift)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What We Demonstrated\n",
    "\n",
    "1. \u2705 **Time Series Autocorrelation**\n",
    "   - Generated data with AR(1) structure (\u03c6 = 0.7)\n",
    "   - Weekly seasonality and linear trend\n",
    "   - Violates iid assumption of standard methods\n",
    "\n",
    "2. \u2705 **Split Method Limitations**\n",
    "   - May produce under-coverage for time series\n",
    "   - Treats calibration samples as independent\n",
    "   - Can fail with strong temporal dependencies\n",
    "\n",
    "3. \u2705 **EnbPI Advantages**\n",
    "   - Block bootstrap preserves autocorrelation\n",
    "   - Temporal calibration splitting\n",
    "   - Better coverage for forecasting tasks\n",
    "   - Designed specifically for time series\n",
    "\n",
    "4. \u2705 **Auto-Selection**\n",
    "   - Can detect time series characteristics\n",
    "   - Provides appropriate method recommendations\n",
    "   - Safe default for production use\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "**For Time Series Forecasting:**\n",
    "- \u26a0\ufe0f Standard conformal methods (split/CV+) assume iid data\n",
    "- \u2705 Use `method='enbpi'` for time series with autocorrelation\n",
    "- \u2705 Or use `method='auto'` to let the system decide\n",
    "- \u2705 Always validate coverage on held-out future data\n",
    "\n",
    "**When EnbPI is Essential:**\n",
    "- Strong autocorrelation (AR, MA, ARMA patterns)\n",
    "- Seasonal patterns (daily, weekly, monthly)\n",
    "- Forecasting applications (predict future from past)\n",
    "- Non-stationary time series\n",
    "\n",
    "**When Split/CV+ May Work:**\n",
    "- Weak or no autocorrelation\n",
    "- Large datasets with stable distribution\n",
    "- Cross-sectional analysis (not forecasting)\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- See `24c_feature_selection_conformal.ipynb` for WorkflowSet conformal comparison\n",
    "- See `24e_per_group_conformal.ipynb` for per-group time series calibration\n",
    "- See `examples/22_conformal_prediction_demo.ipynb` for comprehensive overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}