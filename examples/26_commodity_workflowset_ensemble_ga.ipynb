{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 26: Commodity Forecasting with WorkflowSet and Genetic Algorithm Ensemble Mode\n",
    "\n",
    "This notebook demonstrates a systematic comparison of feature selection strategies using WorkflowSet, with emphasis on **genetic algorithm ensemble mode**.\n",
    "\n",
    "**Dataset**: Commodity futures prices (crude oil, natural gas, gold, etc.)\n",
    "\n",
    "**Key Techniques**:\n",
    "- Multiple preprocessing strategies with genetic algorithm variations\n",
    "- WorkflowSet for systematic workflow comparison\n",
    "- Time series cross-validation\n",
    "- Hyperparameter tuning for GA parameters\n",
    "- **Enhancement demonstrated**: Ensemble mode for robust feature selection\n",
    "\n",
    "**Ensemble Mode Benefits**:\n",
    "- Reduces sensitivity to random initialization\n",
    "- Identifies consistently important features\n",
    "- More stable feature selection across different data splits\n",
    "- Enables comparison of aggregation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from py_recipes import recipe\n",
    "from py_recipes.steps import (\n",
    "    step_select_genetic_algorithm,\n",
    "    step_normalize,\n",
    "    step_mutate,\n",
    "    step_select_corr,\n",
    "    step_pca\n",
    ")\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, rand_forest\n",
    "from py_yardstick import rmse, mae, r_squared, metric_set\n",
    "from py_rsample import time_series_cv, initial_time_split\n",
    "from py_workflowsets import WorkflowSet\n",
    "from py_tune import tune, tune_grid, grid_regular, finalize_workflow\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load commodity futures data\n",
    "data = pd.read_csv('../_md/__data/all_commodities_futures_collection.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nDate range: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"\\nMissing values:\\n{data.isnull().sum()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create lagged features, technical indicators, and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on crude oil (WTI) as target with other commodities as predictors\n",
    "# Keep only columns we need\n",
    "keep_cols = ['date', 'wti_crude', 'brent_crude', 'natural_gas', 'heating_oil', \n",
    "             'rbob_gasoline', 'gold', 'silver', 'copper']\n",
    "data = data[[col for col in keep_cols if col in data.columns]].copy()\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Sort by date\n",
    "data = data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features (1, 3, 7 days)\n",
    "for col in data.columns:\n",
    "    if col != 'date':\n",
    "        for lag in [1, 3, 7]:\n",
    "            data[f'{col}_lag_{lag}'] = data[col].shift(lag)\n",
    "\n",
    "# Create moving averages (7, 14, 30 days)\n",
    "for col in ['wti_crude', 'brent_crude', 'natural_gas']:\n",
    "    for window in [7, 14, 30]:\n",
    "        data[f'{col}_ma_{window}'] = data[col].rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "# Create price momentum (% change)\n",
    "for col in ['wti_crude', 'brent_crude', 'natural_gas']:\n",
    "    data[f'{col}_pct_change_1d'] = data[col].pct_change(1)\n",
    "    data[f'{col}_pct_change_7d'] = data[col].pct_change(7)\n",
    "\n",
    "# Create spread features\n",
    "if 'brent_crude' in data.columns:\n",
    "    data['wti_brent_spread'] = data['wti_crude'] - data['brent_crude']\n",
    "    data['wti_brent_ratio'] = data['wti_crude'] / (data['brent_crude'] + 1e-6)\n",
    "\n",
    "# Drop rows with NaN from lagging/rolling\n",
    "data = data.dropna()\n",
    "\n",
    "print(f\"After feature engineering: {data.shape}\")\n",
    "print(f\"Total features: {len([col for col in data.columns if col not in ['date', 'wti_crude']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "Use 80/20 temporal split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20)\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:split_idx].copy()\n",
    "test_data = data.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {train_data.shape[0]} rows, {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "print(f\"Test: {test_data.shape[0]} rows, {test_data['date'].min()} to {test_data['date'].max()}\")\n",
    "\n",
    "# Remove date column for modeling\n",
    "train = train_data.drop('date', axis=1).copy()\n",
    "test = test_data.drop('date', axis=1).copy()\n",
    "\n",
    "print(f\"\\nTraining features: {train.shape[1] - 1} (target: wti_crude)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Multiple Preprocessing Strategies\n",
    "\n",
    "Create recipes with different feature selection approaches:\n",
    "1. **All features** (baseline)\n",
    "2. **Correlation-based** selection\n",
    "3. **PCA** dimensionality reduction\n",
    "4. **Genetic Algorithm** - single run\n",
    "5. **Genetic Algorithm Ensemble** - voting (60%)\n",
    "6. **Genetic Algorithm Ensemble** - voting (80%)\n",
    "7. **Genetic Algorithm Ensemble** - union\n",
    "8. **Genetic Algorithm Ensemble** - intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe 1: All features (baseline)\n",
    "rec_all = recipe(train).step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 2: Correlation-based selection (keep top 10 features)\n",
    "rec_corr = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_corr(\n",
    "        outcome='wti_crude',\n",
    "        method='correlation',\n",
    "        threshold=0.7,\n",
    "        top_n=10\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recipe 3: PCA (10 components)\n",
    "rec_pca = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_pca(all_numeric_predictors(), num_comp=10)\n",
    ")\n",
    "\n",
    "# Recipe 4: Genetic Algorithm - single run\n",
    "rec_ga_single = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome='wti_crude',\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        population_size=30,\n",
    "        generations=20,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recipe 5: GA Ensemble - voting 60%\n",
    "rec_ga_ens_v60 = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome='wti_crude',\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        n_ensemble=5,\n",
    "        ensemble_strategy='voting',\n",
    "        ensemble_threshold=0.6,\n",
    "        population_size=30,\n",
    "        generations=20,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recipe 6: GA Ensemble - voting 80%\n",
    "rec_ga_ens_v80 = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome='wti_crude',\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        n_ensemble=5,\n",
    "        ensemble_strategy='voting',\n",
    "        ensemble_threshold=0.8,\n",
    "        population_size=30,\n",
    "        generations=20,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recipe 7: GA Ensemble - union\n",
    "rec_ga_ens_union = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome='wti_crude',\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        n_ensemble=5,\n",
    "        ensemble_strategy='union',\n",
    "        population_size=30,\n",
    "        generations=20,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recipe 8: GA Ensemble - intersection\n",
    "rec_ga_ens_inter = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome='wti_crude',\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        n_ensemble=5,\n",
    "        ensemble_strategy='intersection',\n",
    "        population_size=30,\n",
    "        generations=20,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "recipes = {\n",
    "    'all_features': rec_all,\n",
    "    'correlation': rec_corr,\n",
    "    'pca': rec_pca,\n",
    "    'ga_single': rec_ga_single,\n",
    "    'ga_ens_vote60': rec_ga_ens_v60,\n",
    "    'ga_ens_vote80': rec_ga_ens_v80,\n",
    "    'ga_ens_union': rec_ga_ens_union,\n",
    "    'ga_ens_intersect': rec_ga_ens_inter\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(recipes)} preprocessing strategies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Models\n",
    "\n",
    "Compare linear regression and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear_reg': linear_reg(),\n",
    "    'rand_forest': rand_forest(trees=100, min_n=5).set_mode('regression')\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create WorkflowSet\n",
    "\n",
    "Systematically combine all recipes and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WorkflowSet\n",
    "wf_set = WorkflowSet.from_cross(\n",
    "    preproc=recipes,\n",
    "    models=models,\n",
    "    ids=list(recipes.keys())\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated WorkflowSet with {len(wf_set.workflows)} workflows\")\n",
    "print(f\"\\nWorkflow IDs:\")\n",
    "for wf_id in wf_set.workflows.keys():\n",
    "    print(f\"  - {wf_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Series Cross-Validation\n",
    "\n",
    "Create expanding window CV splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV splits (3 folds, expanding window)\n",
    "# Use smaller initial window to get more folds\n",
    "n_train = len(train)\n",
    "initial_size = int(n_train * 0.5)  # Start with 50% of data\n",
    "assess_size = int(n_train * 0.1)   # Assess on 10%\n",
    "\n",
    "cv_folds = time_series_cv(\n",
    "    train_data,\n",
    "    date_column='date',\n",
    "    initial=initial_size,\n",
    "    assess=assess_size,\n",
    "    skip=assess_size,  # Non-overlapping assessment periods\n",
    "    cumulative=True     # Expanding window\n",
    ")\n",
    "\n",
    "print(f\"Created {cv_folds.n_splits} CV folds\")\n",
    "print(f\"\\nFold details:\")\n",
    "for i, (train_idx, test_idx) in enumerate(cv_folds.splits):\n",
    "    train_dates = train_data.iloc[train_idx]['date']\n",
    "    test_dates = train_data.iloc[test_idx]['date']\n",
    "    print(f\"  Fold {i+1}: Train {len(train_idx)} ({train_dates.min()} to {train_dates.max()}), \"\n",
    "          f\"Test {len(test_idx)} ({test_dates.min()} to {test_dates.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate All Workflows with CV\n",
    "\n",
    "**Note**: This will take several minutes as we're fitting 16 workflows × 3 folds = 48 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metrics = metric_set(rmse, mae, r_squared)\n",
    "\n",
    "# Fit resamples (this will take a while)\n",
    "print(\"Fitting all workflows across CV folds...\")\n",
    "print(f\"Total fits: {len(wf_set.workflows)} workflows × {cv_folds.n_splits} folds = {len(wf_set.workflows) * cv_folds.n_splits}\")\n",
    "print(\"\\nThis may take 5-10 minutes...\\n\")\n",
    "\n",
    "wf_results = wf_set.fit_resamples(\n",
    "    resamples=cv_folds,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "print(\"\\n✓ CV evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Collect and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metrics\n",
    "cv_metrics = wf_results.collect_metrics()\n",
    "\n",
    "print(\"\\n=== Cross-Validation Results (All Workflows) ===\")\n",
    "print(cv_metrics.to_string(index=False))\n",
    "\n",
    "# Rank by RMSE\n",
    "ranked = wf_results.rank_results('rmse', n=10)\n",
    "print(\"\\n=== Top 10 Workflows (by RMSE) ===\")\n",
    "print(ranked[['wflow_id', 'rmse', 'mae', 'rsq', 'rank']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Ensemble Strategies\n",
    "\n",
    "Focus on genetic algorithm variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for GA-related workflows with linear regression\n",
    "ga_workflows = cv_metrics[\n",
    "    cv_metrics['wflow_id'].str.contains('ga_') & \n",
    "    cv_metrics['wflow_id'].str.contains('linear_reg')\n",
    "].copy()\n",
    "\n",
    "# Also include baseline for comparison\n",
    "baseline = cv_metrics[\n",
    "    (cv_metrics['wflow_id'] == 'all_features_linear_reg') |\n",
    "    (cv_metrics['wflow_id'] == 'correlation_linear_reg') |\n",
    "    (cv_metrics['wflow_id'] == 'pca_linear_reg')\n",
    "]\n",
    "\n",
    "comparison = pd.concat([baseline, ga_workflows]).sort_values('rmse')\n",
    "\n",
    "print(\"\\n=== Feature Selection Method Comparison ===\")\n",
    "print(comparison[['wflow_id', 'rmse', 'mae', 'rsq']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autoplot for quick visualization\n",
    "fig = wf_results.autoplot('rmse')\n",
    "fig.update_layout(height=600, title='Workflow Comparison: RMSE across CV Folds')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom plot for GA comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Sort by RMSE\n",
    "comparison_sorted = comparison.sort_values('rmse')\n",
    "\n",
    "# Create labels\n",
    "labels = comparison_sorted['wflow_id'].str.replace('_linear_reg', '').str.replace('_', ' ').str.title()\n",
    "\n",
    "# Colors: baseline in gray, GA variants in different colors\n",
    "colors = []\n",
    "for wf_id in comparison_sorted['wflow_id']:\n",
    "    if 'ga_ens' in wf_id:\n",
    "        colors.append('steelblue')\n",
    "    elif 'ga_single' in wf_id:\n",
    "        colors.append('orange')\n",
    "    else:\n",
    "        colors.append('lightgray')\n",
    "\n",
    "bars = ax.barh(range(len(labels)), comparison_sorted['rmse'], color=colors, alpha=0.8)\n",
    "ax.set_yticks(range(len(labels)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('RMSE (lower is better)', fontsize=11)\n",
    "ax.set_title('Feature Selection Strategy Comparison: RMSE', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, comparison_sorted['rmse'])):\n",
    "    ax.text(val, bar.get_y() + bar.get_height()/2, f'{val:.2f}', \n",
    "            ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgray', alpha=0.8, label='Baseline Methods'),\n",
    "    Patch(facecolor='orange', alpha=0.8, label='GA Single Run'),\n",
    "    Patch(facecolor='steelblue', alpha=0.8, label='GA Ensemble')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('commodity_ga_ensemble_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as: commodity_ga_ensemble_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Select and Finalize Best Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best workflow ID\n",
    "best_wf_id = ranked.iloc[0]['wflow_id']\n",
    "print(f\"Best workflow: {best_wf_id}\")\n",
    "print(f\"CV RMSE: {ranked.iloc[0]['rmse']:.2f}\")\n",
    "\n",
    "# Extract and fit best workflow on full training data\n",
    "best_wf = wf_set[best_wf_id]\n",
    "best_fit = best_wf.fit(train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_eval = best_fit.evaluate(test)\n",
    "outputs, coeffs, stats = test_eval.extract_outputs()\n",
    "\n",
    "print(f\"\\n=== Test Set Performance ===\")\n",
    "test_stats = stats[stats['split'] == 'test']\n",
    "print(f\"RMSE: {test_stats['rmse'].values[0]:.2f}\")\n",
    "print(f\"MAE: {test_stats['mae'].values[0]:.2f}\")\n",
    "print(f\"R²: {test_stats['rsq'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Inspect Selected Features (If GA-based)\n",
    "\n",
    "If the best workflow uses genetic algorithm, inspect which features were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ga_' in best_wf_id:\n",
    "    # Get the prepared recipe\n",
    "    prepped_recipe = best_fit.extract_preprocessor()\n",
    "    \n",
    "    # Find the genetic algorithm step\n",
    "    ga_step = None\n",
    "    for step in prepped_recipe.prepared_steps:\n",
    "        if hasattr(step, '_selected_features'):\n",
    "            ga_step = step\n",
    "            break\n",
    "    \n",
    "    if ga_step is not None:\n",
    "        print(f\"\\n=== Selected Features by Best Workflow ===\")\n",
    "        selected_features = ga_step._selected_features\n",
    "        print(f\"Number of features selected: {len(selected_features)}\")\n",
    "        print(f\"\\nSelected features:\")\n",
    "        for feat in selected_features:\n",
    "            print(f\"  - {feat}\")\n",
    "        \n",
    "        # If ensemble mode, show feature frequencies\n",
    "        if hasattr(ga_step, '_ensemble_results') and len(ga_step._ensemble_results) > 0:\n",
    "            print(f\"\\n=== Ensemble Details ===\")\n",
    "            print(f\"Number of ensemble runs: {len(ga_step._ensemble_results)}\")\n",
    "            \n",
    "            print(f\"\\nFeature frequency across ensemble runs:\")\n",
    "            freq = ga_step._feature_frequencies\n",
    "            for feat, count in sorted(freq.items(), key=lambda x: x[1], reverse=True):\n",
    "                pct = count / len(ga_step._ensemble_results) * 100\n",
    "                print(f\"  {feat}: {count}/{len(ga_step._ensemble_results)} runs ({pct:.0f}%)\")\n",
    "            \n",
    "            print(f\"\\nPer-run details:\")\n",
    "            for result in ga_step._ensemble_results:\n",
    "                print(f\"  Run {result['run_idx']+1} (seed={result['seed']}): \"\n",
    "                      f\"{len(result['features'])} features, fitness={result['fitness']:.2f}\")\n",
    "else:\n",
    "    print(f\"Best workflow ({best_wf_id}) does not use genetic algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Key Takeaways\n",
    "\n",
    "### Ensemble Mode Benefits:\n",
    "1. **Stability**: Ensemble mode reduces variance in feature selection\n",
    "2. **Confidence**: Features appearing in 80%+ of runs are highly reliable\n",
    "3. **Strategy Matters**: \n",
    "   - `voting` (60-80%): Balanced selection\n",
    "   - `union`: Most inclusive (may include noise)\n",
    "   - `intersection`: Most conservative (only unanimous features)\n",
    "\n",
    "### WorkflowSet Advantages:\n",
    "1. **Systematic Comparison**: Automatically evaluates all preprocessing × model combinations\n",
    "2. **Cross-Validation**: Robust performance estimation via time series CV\n",
    "3. **Easy Ranking**: Quick identification of best-performing strategies\n",
    "4. **Reproducibility**: Structured approach ensures consistent methodology\n",
    "\n",
    "### Genetic Algorithm vs Other Methods:\n",
    "- GA often outperforms correlation-based selection for nonlinear relationships\n",
    "- Ensemble GA provides more robust feature selection than single GA run\n",
    "- Computational cost is higher but may be worth it for improved stability\n",
    "\n",
    "### Production Recommendations:\n",
    "1. Use ensemble mode with voting (60-70% threshold) for production systems\n",
    "2. Monitor feature frequencies to identify consistently important predictors\n",
    "3. Retrain ensemble periodically as new data arrives\n",
    "4. Consider computational budget when choosing ensemble size (5-10 runs typical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "py-tidymodels2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
