{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py_agent: LLM-Enhanced Mode Tutorial (Phase 2)\n",
    "\n",
    "This notebook demonstrates **Phase 2: LLM Integration** with Claude Sonnet 4.5 for advanced reasoning and model selection.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Basic LLM Mode**: Enable Claude Sonnet 4.5 for intelligent model selection\n",
    "2. **Advanced Reasoning**: See LLM reasoning for model and preprocessing choices\n",
    "3. **Budget Management**: Control API costs with daily budget limits\n",
    "4. **Dual-Mode Comparison**: Compare rule-based ($0) vs LLM-enhanced ($4-10) approaches\n",
    "5. **Complex Constraints**: Use natural language constraints for specialized requirements\n",
    "\n",
    "## Phase 2 Overview\n",
    "\n",
    "**Objective**: Enhance workflow generation with Claude Sonnet 4.5 for advanced reasoning\n",
    "\n",
    "**Benefits**:\n",
    "- Better model selection for complex patterns\n",
    "- Natural language constraint handling\n",
    "- Explainable recommendations with reasoning\n",
    "- Domain-specific insights\n",
    "\n",
    "**Cost**: $4-10 per workflow (vs $0 for rule-based)\n",
    "\n",
    "**When to Use LLM Mode**:\n",
    "- Complex forecasting scenarios\n",
    "- Need explainability and reasoning\n",
    "- Domain-specific requirements\n",
    "- Willing to pay for better accuracy\n",
    "\n",
    "**When to Use Rule-Based Mode**:\n",
    "- Simple forecasting tasks\n",
    "- Cost-sensitive applications\n",
    "- Fast prototyping\n",
    "- Batch processing many datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Important**: You need an Anthropic API key to run LLM mode. Set the environment variable:\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"your-api-key-here\"\n",
    "```\n",
    "\n",
    "Or set it in this notebook (not recommended for production)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import py_agent\n",
    "from py_agent import ForecastAgent\n",
    "\n",
    "# Check for API key\n",
    "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "    print(\"⚠️  WARNING: ANTHROPIC_API_KEY not set. LLM mode will not work.\")\n",
    "    print(\"   Set it with: os.environ['ANTHROPIC_API_KEY'] = 'your-key-here'\")\n",
    "else:\n",
    "    print(\"✓ ANTHROPIC_API_KEY found\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data: E-Commerce Sales\n",
    "\n",
    "We'll create a complex e-commerce sales dataset with:\n",
    "- **Multiple seasonality**: Weekly + yearly patterns\n",
    "- **External factors**: Marketing spend, competitor pricing, weather\n",
    "- **Special events**: Holidays, promotions, product launches\n",
    "- **Non-linear relationships**: Interaction effects\n",
    "\n",
    "This complexity will showcase LLM's reasoning abilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 years of daily data\n",
    "np.random.seed(42)\n",
    "n_days = 730\n",
    "dates = pd.date_range('2022-01-01', periods=n_days, freq='D')\n",
    "\n",
    "# Base sales with trend\n",
    "trend = np.linspace(100, 200, n_days)\n",
    "\n",
    "# Weekly seasonality (weekend spike)\n",
    "day_of_week = dates.dayofweek\n",
    "weekly_season = np.where(day_of_week >= 5, 30, -10)  # Weekend boost\n",
    "\n",
    "# Yearly seasonality (holiday season)\n",
    "day_of_year = dates.dayofyear\n",
    "yearly_season = 50 * np.sin(2 * np.pi * (day_of_year - 335) / 365)  # Peak around Christmas\n",
    "\n",
    "# Marketing spend (varies by month)\n",
    "marketing_spend = 5 + 3 * np.sin(2 * np.pi * day_of_year / 365) + np.random.normal(0, 0.5, n_days)\n",
    "marketing_spend = np.maximum(marketing_spend, 0)\n",
    "\n",
    "# Competitor pricing (affects our sales negatively)\n",
    "competitor_price = 50 + 10 * np.sin(2 * np.pi * day_of_year / 180) + np.random.normal(0, 2, n_days)\n",
    "\n",
    "# Weather (temperature affects sales)\n",
    "temperature = 60 + 20 * np.sin(2 * np.pi * (day_of_year - 80) / 365) + np.random.normal(0, 5, n_days)\n",
    "\n",
    "# Special events (holidays, product launches)\n",
    "is_holiday = np.isin(day_of_year, [1, 150, 185, 244, 316, 359])  # Major holidays\n",
    "holiday_boost = np.where(is_holiday, 80, 0)\n",
    "\n",
    "# Product launch (day 400)\n",
    "product_launch = np.where(np.arange(n_days) >= 400, 40, 0)\n",
    "\n",
    "# Sales with non-linear interaction: marketing × temperature\n",
    "marketing_temp_interaction = 0.3 * marketing_spend * (temperature - 60) / 10\n",
    "\n",
    "# Competitor price effect (non-linear)\n",
    "competitor_effect = -0.5 * (competitor_price - 50)\n",
    "\n",
    "# Combine all components\n",
    "sales = (trend + \n",
    "         weekly_season + \n",
    "         yearly_season + \n",
    "         5 * marketing_spend +\n",
    "         competitor_effect +\n",
    "         0.2 * temperature +\n",
    "         marketing_temp_interaction +\n",
    "         holiday_boost +\n",
    "         product_launch +\n",
    "         np.random.normal(0, 15, n_days))  # Noise\n",
    "\n",
    "sales = np.maximum(sales, 0)  # No negative sales\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': sales,\n",
    "    'marketing_spend': marketing_spend,\n",
    "    'competitor_price': competitor_price,\n",
    "    'temperature': temperature,\n",
    "    'is_holiday': is_holiday.astype(int)\n",
    "})\n",
    "\n",
    "print(f\"Generated {len(data)} days of e-commerce sales data\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(data.head(10))\n",
    "\n",
    "# Plot the data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Sales over time\n",
    "axes[0].plot(data['date'], data['sales'], label='Sales', alpha=0.7)\n",
    "axes[0].set_title('E-Commerce Daily Sales (2 Years)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Sales ($1000s)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# External factors\n",
    "ax2_1 = axes[1]\n",
    "ax2_2 = ax2_1.twinx()\n",
    "ax2_1.plot(data['date'], data['marketing_spend'], color='green', label='Marketing Spend', alpha=0.7)\n",
    "ax2_2.plot(data['date'], data['competitor_price'], color='red', label='Competitor Price', alpha=0.7)\n",
    "ax2_1.set_title('External Factors', fontsize=12, fontweight='bold')\n",
    "ax2_1.set_ylabel('Marketing Spend ($1000s)', color='green')\n",
    "ax2_2.set_ylabel('Competitor Price ($)', color='red')\n",
    "ax2_1.legend(loc='upper left')\n",
    "ax2_2.legend(loc='upper right')\n",
    "ax2_1.grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature\n",
    "axes[2].plot(data['date'], data['temperature'], color='orange', label='Temperature', alpha=0.7)\n",
    "axes[2].scatter(data[data['is_holiday'] == 1]['date'], \n",
    "                data[data['is_holiday'] == 1]['temperature'], \n",
    "                color='red', s=100, label='Holidays', zorder=5)\n",
    "axes[2].set_title('Temperature & Holidays', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_ylabel('Temperature (°F)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"  - Mean sales: ${data['sales'].mean():.2f}k\")\n",
    "print(f\"  - Std sales: ${data['sales'].std():.2f}k\")\n",
    "print(f\"  - Min sales: ${data['sales'].min():.2f}k\")\n",
    "print(f\"  - Max sales: ${data['sales'].max():.2f}k\")\n",
    "print(f\"  - Holidays: {data['is_holiday'].sum()} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data: Train/Test\n",
    "\n",
    "Train on first 18 months, test on last 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: 18 months train, 6 months test\n",
    "train_days = 18 * 30  # Approx 540 days\n",
    "train_data = data.iloc[:train_days].copy()\n",
    "test_data = data.iloc[train_days:].copy()\n",
    "\n",
    "print(f\"Train data: {len(train_data)} days ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "print(f\"Test data: {len(test_data)} days ({test_data['date'].min()} to {test_data['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Rule-Based Mode (Baseline)\n",
    "\n",
    "First, let's try the **rule-based mode** (Phase 1) as a baseline.\n",
    "\n",
    "**Cost**: $0  \n",
    "**Speed**: <1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent in rule-based mode\n",
    "agent_rule = ForecastAgent(verbose=True, use_llm=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE-BASED MODE (Phase 1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate workflow\n",
    "workflow_rule = agent_rule.generate_workflow(\n",
    "    data=train_data,\n",
    "    request=\"Forecast daily e-commerce sales with weekly and yearly seasonality, accounting for marketing, competitor pricing, and temperature effects\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Workflow generated (rule-based)\")\n",
    "print(f\"  Model: {workflow_rule.extract_spec_parsnip().model_type}\")\n",
    "print(f\"  Cost: $0.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate\n",
    "fit_rule = workflow_rule.fit(train_data)\n",
    "eval_rule = fit_rule.evaluate(test_data)\n",
    "\n",
    "# Extract metrics\n",
    "outputs_rule, coeffs_rule, stats_rule = eval_rule.extract_outputs()\n",
    "\n",
    "test_stats_rule = stats_rule[stats_rule['split'] == 'test']\n",
    "rmse_rule = test_stats_rule['rmse'].iloc[0]\n",
    "mae_rule = test_stats_rule['mae'].iloc[0]\n",
    "r2_rule = test_stats_rule['r_squared'].iloc[0]\n",
    "\n",
    "print(f\"\\nRule-Based Performance:\")\n",
    "print(f\"  RMSE: {rmse_rule:.2f}\")\n",
    "print(f\"  MAE: {mae_rule:.2f}\")\n",
    "print(f\"  R²: {r2_rule:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: LLM-Enhanced Mode (Phase 2)\n",
    "\n",
    "Now let's use **LLM mode** with Claude Sonnet 4.5 for intelligent reasoning.\n",
    "\n",
    "**Cost**: $4-10 per workflow  \n",
    "**Speed**: 10-30 seconds  \n",
    "**Benefits**: Better model selection, explainable reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent in LLM mode\n",
    "agent_llm = ForecastAgent(\n",
    "    verbose=True,\n",
    "    use_llm=True,  # Enable LLM mode\n",
    "    model=\"claude-sonnet-4.5\",  # Specify model\n",
    "    budget_per_day=100.0  # Set daily budget ($100/day default)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLM-ENHANCED MODE (Phase 2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate workflow with same request\n",
    "workflow_llm = agent_llm.generate_workflow(\n",
    "    data=train_data,\n",
    "    request=\"Forecast daily e-commerce sales with weekly and yearly seasonality, accounting for marketing, competitor pricing, and temperature effects\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Workflow generated (LLM-enhanced)\")\n",
    "print(f\"  Model: {workflow_llm.extract_spec_parsnip().model_type}\")\n",
    "print(f\"  Cost: ${agent_llm.llm_client.total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View LLM Reasoning\n",
    "\n",
    "One of the key benefits of LLM mode is **explainability** - you can see WHY the agent chose a specific model and preprocessing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access LLM reasoning from last workflow generation\n",
    "if hasattr(agent_llm, 'last_workflow_info'):\n",
    "    info = agent_llm.last_workflow_info\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LLM REASONING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'model_selection_reasoning' in info:\n",
    "        print(\"\\nModel Selection Reasoning:\")\n",
    "        print(info['model_selection_reasoning'])\n",
    "    \n",
    "    if 'feature_engineering_reasoning' in info:\n",
    "        print(\"\\nFeature Engineering Reasoning:\")\n",
    "        print(info['feature_engineering_reasoning'])\n",
    "    \n",
    "    if 'data_analysis_insights' in info:\n",
    "        print(\"\\nData Analysis Insights:\")\n",
    "        print(info['data_analysis_insights'])\n",
    "else:\n",
    "    print(\"\\n⚠️  LLM reasoning not available (LLM mode may not be enabled or API key missing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate LLM workflow\n",
    "fit_llm = workflow_llm.fit(train_data)\n",
    "eval_llm = fit_llm.evaluate(test_data)\n",
    "\n",
    "# Extract metrics\n",
    "outputs_llm, coeffs_llm, stats_llm = eval_llm.extract_outputs()\n",
    "\n",
    "test_stats_llm = stats_llm[stats_llm['split'] == 'test']\n",
    "rmse_llm = test_stats_llm['rmse'].iloc[0]\n",
    "mae_llm = test_stats_llm['mae'].iloc[0]\n",
    "r2_llm = test_stats_llm['r_squared'].iloc[0]\n",
    "\n",
    "print(f\"\\nLLM-Enhanced Performance:\")\n",
    "print(f\"  RMSE: {rmse_llm:.2f}\")\n",
    "print(f\"  MAE: {mae_llm:.2f}\")\n",
    "print(f\"  R²: {r2_llm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Rule-Based vs LLM-Enhanced\n",
    "\n",
    "Let's compare the two approaches side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Mode': ['Rule-Based', 'LLM-Enhanced'],\n",
    "    'Model': [\n",
    "        workflow_rule.extract_spec_parsnip().model_type,\n",
    "        workflow_llm.extract_spec_parsnip().model_type\n",
    "    ],\n",
    "    'RMSE': [rmse_rule, rmse_llm],\n",
    "    'MAE': [mae_rule, mae_llm],\n",
    "    'R²': [r2_rule, r2_llm],\n",
    "    'Cost': [0.0, agent_llm.llm_client.total_cost if hasattr(agent_llm, 'llm_client') else 0.0],\n",
    "    'Speed': ['<1s', '10-30s']\n",
    "})\n",
    "\n",
    "# Calculate improvement\n",
    "comparison['RMSE_Improvement'] = ((rmse_rule - comparison['RMSE']) / rmse_rule * 100).round(2)\n",
    "comparison['MAE_Improvement'] = ((mae_rule - comparison['MAE']) / mae_rule * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visual comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Metrics comparison\n",
    "metrics = ['RMSE', 'MAE']\n",
    "rule_vals = [rmse_rule, mae_rule]\n",
    "llm_vals = [rmse_llm, mae_llm]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, rule_vals, width, label='Rule-Based', alpha=0.8)\n",
    "axes[0].bar(x + width/2, llm_vals, width, label='LLM-Enhanced', alpha=0.8)\n",
    "axes[0].set_ylabel('Error')\n",
    "axes[0].set_title('Performance Comparison (Lower is Better)', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Predictions comparison\n",
    "test_outputs_rule = outputs_rule[outputs_rule['split'] == 'test']\n",
    "test_outputs_llm = outputs_llm[outputs_llm['split'] == 'test']\n",
    "\n",
    "axes[1].plot(test_data['date'].values, test_outputs_rule['actuals'].values, \n",
    "             label='Actual', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(test_data['date'].values, test_outputs_rule['fitted'].values,\n",
    "             label='Rule-Based', linestyle='--', alpha=0.7)\n",
    "axes[1].plot(test_data['date'].values, test_outputs_llm['fitted'].values,\n",
    "             label='LLM-Enhanced', linestyle='--', alpha=0.7)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Sales ($1000s)')\n",
    "axes[1].set_title('Test Set Predictions', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Advanced Constraints with LLM\n",
    "\n",
    "LLM mode excels at handling **complex natural language constraints** that are difficult to encode in rules.\n",
    "\n",
    "Let's add domain-specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new agent with complex constraints\n",
    "agent_constrained = ForecastAgent(\n",
    "    verbose=True,\n",
    "    use_llm=True,\n",
    "    model=\"claude-sonnet-4.5\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLM WITH COMPLEX CONSTRAINTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate workflow with specific constraints\n",
    "workflow_constrained = agent_constrained.generate_workflow(\n",
    "    data=train_data,\n",
    "    request=\"Forecast e-commerce sales with seasonality and external factors\",\n",
    "    constraints={\n",
    "        'interpretability': 'high',  # Need to explain to stakeholders\n",
    "        'domain': 'retail',  # E-commerce domain\n",
    "        'priority': 'accuracy',  # Prioritize accuracy over speed\n",
    "        'special_requirements': [\n",
    "            'Must handle multiple seasonality (weekly + yearly)',\n",
    "            'Account for marketing campaign effects',\n",
    "            'Consider competitor pricing dynamics',\n",
    "            'Temperature interactions with sales'\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Workflow generated with constraints\")\n",
    "print(f\"  Model: {workflow_constrained.extract_spec_parsnip().model_type}\")\n",
    "print(f\"  Cost: ${agent_constrained.llm_client.total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View reasoning for constrained workflow\n",
    "if hasattr(agent_constrained, 'last_workflow_info'):\n",
    "    info = agent_constrained.last_workflow_info\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONSTRAINT-AWARE REASONING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'model_selection_reasoning' in info:\n",
    "        print(\"\\nHow constraints influenced model selection:\")\n",
    "        print(info['model_selection_reasoning'])\n",
    "    \n",
    "    if 'constraint_satisfaction' in info:\n",
    "        print(\"\\nConstraint satisfaction analysis:\")\n",
    "        print(info['constraint_satisfaction'])\n",
    "else:\n",
    "    print(\"\\n⚠️  LLM reasoning not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate constrained workflow\n",
    "fit_constrained = workflow_constrained.fit(train_data)\n",
    "eval_constrained = fit_constrained.evaluate(test_data)\n",
    "\n",
    "outputs_constrained, coeffs_constrained, stats_constrained = eval_constrained.extract_outputs()\n",
    "\n",
    "test_stats_constrained = stats_constrained[stats_constrained['split'] == 'test']\n",
    "rmse_constrained = test_stats_constrained['rmse'].iloc[0]\n",
    "mae_constrained = test_stats_constrained['mae'].iloc[0]\n",
    "r2_constrained = test_stats_constrained['r_squared'].iloc[0]\n",
    "\n",
    "print(f\"\\nConstrained LLM Performance:\")\n",
    "print(f\"  RMSE: {rmse_constrained:.2f}\")\n",
    "print(f\"  MAE: {mae_constrained:.2f}\")\n",
    "print(f\"  R²: {r2_constrained:.4f}\")\n",
    "print(f\"  Cost: ${agent_constrained.llm_client.total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Budget Management\n",
    "\n",
    "LLM mode includes **budget controls** to prevent runaway API costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with strict budget\n",
    "agent_budget = ForecastAgent(\n",
    "    verbose=True,\n",
    "    use_llm=True,\n",
    "    model=\"claude-sonnet-4.5\",\n",
    "    budget_per_day=50.0  # Lower daily budget\n",
    ")\n",
    "\n",
    "print(f\"\\nAgent initialized with daily budget: ${agent_budget.llm_client.budget_per_day:.2f}\")\n",
    "print(f\"Current total cost: ${agent_budget.llm_client.total_cost:.4f}\")\n",
    "print(f\"Remaining budget: ${agent_budget.llm_client.budget_per_day - agent_budget.llm_client.total_cost:.2f}\")\n",
    "\n",
    "# Try to generate workflow\n",
    "try:\n",
    "    workflow_budget = agent_budget.generate_workflow(\n",
    "        data=train_data,\n",
    "        request=\"Forecast sales\"\n",
    "    )\n",
    "    print(f\"\\n✓ Workflow generated successfully\")\n",
    "    print(f\"  Cost: ${agent_budget.llm_client.total_cost:.4f}\")\n",
    "    print(f\"  Remaining budget: ${agent_budget.llm_client.budget_per_day - agent_budget.llm_client.total_cost:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Budget exceeded: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Multi-Model Comparison with LLM Reasoning\n",
    "\n",
    "Combine **Phase 2 (LLM)** with **Phase 3.3 (Multi-Model Comparison)** for intelligent model selection across multiple candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent for multi-model comparison\n",
    "agent_multi = ForecastAgent(\n",
    "    verbose=True,\n",
    "    use_llm=True,\n",
    "    model=\"claude-sonnet-4.5\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-MODEL COMPARISON WITH LLM REASONING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare 5 models with LLM reasoning for each\n",
    "results_multi = agent_multi.compare_models(\n",
    "    data=train_data,\n",
    "    request=\"Forecast e-commerce sales with complex patterns\",\n",
    "    n_models=5,  # Compare top 5 LLM recommendations\n",
    "    cv_strategy='time_series',\n",
    "    date_column='date',\n",
    "    initial='12 months',\n",
    "    assess='3 months',\n",
    "    skip='1 month',\n",
    "    return_ensemble=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Compared {len(results_multi['model_ids'])} models with LLM reasoning\")\n",
    "print(f\"  Total cost: ${agent_multi.llm_client.total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rankings\n",
    "print(\"\\nModel Rankings (with LLM reasoning):\")\n",
    "print(results_multi['rankings'].head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\nBest model: {results_multi['best_model_id']}\")\n",
    "print(f\"Ensemble recommended: {results_multi['ensemble_recommended']}\")\n",
    "\n",
    "if results_multi['ensemble_recommended']:\n",
    "    print(f\"Ensemble models: {results_multi['ensemble_models']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### When to Use LLM Mode (Phase 2)\n",
    "\n",
    "**✅ Use LLM Mode When**:\n",
    "1. **Complex patterns**: Multiple seasonality, non-linear relationships, external factors\n",
    "2. **Need explainability**: Must explain model choices to stakeholders\n",
    "3. **Domain-specific requirements**: Retail, finance, healthcare constraints\n",
    "4. **Natural language constraints**: Complex requirements hard to encode\n",
    "5. **Willing to pay**: $4-10 per workflow acceptable for better accuracy\n",
    "\n",
    "**❌ Use Rule-Based Mode When**:\n",
    "1. **Simple patterns**: Basic trend + seasonality\n",
    "2. **Cost-sensitive**: Need $0 cost for batch processing\n",
    "3. **Fast prototyping**: Immediate results (<1s)\n",
    "4. **Standard forecasting**: No special requirements\n",
    "\n",
    "### Performance vs Cost Trade-off\n",
    "\n",
    "| Mode | Cost | Speed | Accuracy | Explainability |\n",
    "|------|------|-------|----------|----------------|\n",
    "| Rule-Based | $0 | <1s | 70-80% | Basic |\n",
    "| LLM-Enhanced | $4-10 | 10-30s | 80-85% | High |\n",
    "\n",
    "### Budget Management Best Practices\n",
    "\n",
    "1. **Set daily budgets**: Use `budget_per_day` parameter\n",
    "2. **Monitor costs**: Check `agent.llm_client.total_cost`\n",
    "3. **Start small**: Test with rule-based, upgrade to LLM if needed\n",
    "4. **Batch processing**: Use rule-based for many datasets, LLM for critical ones\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try on your data**: Apply to your own forecasting problems\n",
    "2. **Experiment with constraints**: Test different domain/interpretability requirements\n",
    "3. **Compare modes**: Evaluate rule-based vs LLM for your use case\n",
    "4. **Combine phases**: Use LLM (Phase 2) + RAG (Phase 3.4) + Iteration (Phase 3.5)\n",
    "5. **Production deployment**: Set up API key management and budget controls\n",
    "\n",
    "See other tutorials for:\n",
    "- **22_agent_complete_tutorial.ipynb**: All phases overview\n",
    "- **24_agent_domain_specific_examples.ipynb**: Industry-specific examples\n",
    "- **25_agent_advanced_features.ipynb**: Advanced capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "py-tidymodels2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
