{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 30: Manual Regression - External Forecast Comparison\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **`manual_reg()`**, a NEW feature in py-tidymodels v1.0.0 that allows you to **specify coefficients manually** without fitting.\n",
    "\n",
    "### What is Manual Regression?\n",
    "\n",
    "Instead of learning coefficients from data, you **provide them directly**:\n",
    "\n",
    "```python\n",
    "from py_parsnip import manual_reg\n",
    "\n",
    "# Specify coefficients manually\n",
    "spec = manual_reg(\n",
    "    coefficients={'temperature': -0.5, 'wind_speed': 0.3},\n",
    "    intercept=1000.0\n",
    ")\n",
    "\n",
    "# \"Fit\" (just stores coefficients)\n",
    "fit = spec.fit(data, 'demand ~ temperature + wind_speed')\n",
    "\n",
    "# Predict using manual coefficients\n",
    "predictions = fit.predict(test_data)\n",
    "```\n",
    "\n",
    "**No fitting happens** - the model just uses your coefficients.\n",
    "\n",
    "---\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "### 1. **Compare with External Tools**\n",
    "You have forecasts from:\n",
    "- Excel (LINEST, Solver)\n",
    "- R (lm, forecast)\n",
    "- SAS (PROC REG)\n",
    "- Commercial software\n",
    "- Legacy systems\n",
    "\n",
    "**Goal**: Reproduce those forecasts in py-tidymodels and compare.\n",
    "\n",
    "### 2. **Incorporate Domain Expert Knowledge**\n",
    "Subject matter experts provide coefficient estimates:\n",
    "- \"Temperature affects demand by -0.5 per degree\"\n",
    "- \"Each $1 price increase reduces sales by 100 units\"\n",
    "\n",
    "**Goal**: Test expert intuition against data-driven models.\n",
    "\n",
    "### 3. **Create Baselines**\n",
    "Simple benchmarks for model comparison:\n",
    "- Naive rules: `sales = baseline + 0.5 * price`\n",
    "- Industry standards\n",
    "- Historical coefficients\n",
    "\n",
    "**Goal**: Ensure data-driven models beat simple baselines.\n",
    "\n",
    "### 4. **Reproduce Legacy Forecasts**\n",
    "Old system uses fixed coefficients:\n",
    "- Migration validation\n",
    "- Regulatory compliance\n",
    "- Audit trails\n",
    "\n",
    "**Goal**: Exactly match legacy outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**Refinery Margins** (simple, interpretable)\n",
    "- Small dataset for clear demonstration\n",
    "- Easy to understand relationships\n",
    "- Good for manual coefficient specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Manual regression imports (NEW!)\n",
    "from py_parsnip import manual_reg, linear_reg\n",
    "\n",
    "# Supporting imports\n",
    "from py_rsample import initial_time_split\n",
    "from py_yardstick import rmse, mae, r_squared\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load refinery margins data\n",
    "data = pd.read_csv('../_md/__data/refinery_margins.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Create margin column (brent - dubai)\n",
    "data['margin'] = data['brent'] - data['dubai']\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"Data: {len(data):,} rows\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(f\"\\nData statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "split = initial_time_split(data, prop=0.8)\n",
    "train_data = split.training()\n",
    "test_data = split.testing()\n",
    "\n",
    "print(f\"Train: {len(train_data):,} rows ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "print(f\"Test:  {len(test_data):,} rows ({test_data['date'].min()} to {test_data['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Use Case 1: Compare with External Tool (Excel)\n",
    "\n",
    "**Scenario**: Your team has an Excel model that forecasts refinery margins using:\n",
    "- Brent crude price\n",
    "- Dubai crude price\n",
    "\n",
    "Excel LINEST gave these coefficients:\n",
    "- Brent: 1.2\n",
    "- Dubai: -0.8\n",
    "- Intercept: 50.0\n",
    "\n",
    "**Goal**: Reproduce Excel forecasts and compare with py-tidymodels fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel coefficients (from external tool)\n",
    "excel_coefficients = {\n",
    "    'brent': 1.2,\n",
    "    'dubai': -0.8\n",
    "}\n",
    "excel_intercept = 50.0\n",
    "\n",
    "print(\"üìä Excel Model Coefficients:\")\n",
    "print(f\"  Intercept: {excel_intercept}\")\n",
    "for var, coef in excel_coefficients.items():\n",
    "    print(f\"  {var}: {coef}\")\n",
    "\n",
    "# Create manual regression model\n",
    "excel_model = manual_reg(\n",
    "    coefficients=excel_coefficients,\n",
    "    intercept=excel_intercept\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Manual regression model created with Excel coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Fit\" the manual model (just stores coefficients)\n",
    "fit_excel = excel_model.fit(train_data, 'margin ~ brent + dubai')\n",
    "\n",
    "# Evaluate on test data\n",
    "eval_excel = fit_excel.evaluate(test_data)\n",
    "outputs_excel, coeffs_excel, stats_excel = eval_excel.extract_outputs()\n",
    "\n",
    "# Extract test metrics (LONG format - manual_reg)\n",
    "test_stats = stats_excel[stats_excel['split'] == 'test']\n",
    "test_rmse_excel = test_stats[test_stats['metric'] == 'rmse']['value'].iloc[0]\n",
    "test_mae_excel = test_stats[test_stats['metric'] == 'mae']['value'].iloc[0]\n",
    "test_r2_excel = test_stats[test_stats['metric'] == 'r_squared']['value'].iloc[0]\n",
    "\n",
    "print(\"üìä Excel Model - Test Performance:\")\n",
    "print(f\"RMSE: {test_rmse_excel:.4f}\")\n",
    "print(f\"MAE:  {test_mae_excel:.4f}\")\n",
    "print(f\"R¬≤:   {test_r2_excel:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Successfully reproduced Excel forecasts in py-tidymodels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with py-tidymodels Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit actual linear regression (data-driven)\n",
    "fitted_model = linear_reg().fit(train_data, 'margin ~ brent + dubai')\n",
    "\n",
    "# Evaluate\n",
    "eval_fitted = fitted_model.evaluate(test_data)\n",
    "outputs_fitted, coeffs_fitted, stats_fitted = eval_fitted.extract_outputs()\n",
    "\n",
    "# Extract test metrics (LONG format - linear_reg)\n",
    "test_stats = stats_fitted[stats_fitted['split'] == 'test']\n",
    "test_rmse_fitted = test_stats[test_stats['metric'] == 'rmse']['value'].iloc[0]\n",
    "test_mae_fitted = test_stats[test_stats['metric'] == 'mae']['value'].iloc[0]\n",
    "test_r2_fitted = test_stats[test_stats['metric'] == 'r_squared']['value'].iloc[0]\n",
    "\n",
    "print(\"üìä py-tidymodels Fitted Model - Test Performance:\")\n",
    "print(f\"RMSE: {test_rmse_fitted:.4f}\")\n",
    "print(f\"MAE:  {test_mae_fitted:.4f}\")\n",
    "print(f\"R¬≤:   {test_r2_fitted:.4f}\")\n",
    "\n",
    "# Show learned coefficients\n",
    "print(\"\\nüìä Learned Coefficients:\")\n",
    "print(coeffs_fitted[['variable', 'coefficient']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Excel vs Fitted\n",
    "comparison_excel = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Excel (Manual)',\n",
    "        'Source': 'External tool (LINEST)',\n",
    "        'Test_RMSE': test_rmse_excel,\n",
    "        'Test_MAE': test_mae_excel,\n",
    "        'Test_R¬≤': test_r2_excel\n",
    "    },\n",
    "    {\n",
    "        'Model': 'py-tidymodels (Fitted)',\n",
    "        'Source': 'Learned from data',\n",
    "        'Test_RMSE': test_rmse_fitted,\n",
    "        'Test_MAE': test_mae_fitted,\n",
    "        'Test_R¬≤': test_r2_fitted\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nüìä COMPARISON: Excel vs py-tidymodels\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_excel.to_string(index=False))\n",
    "\n",
    "# Calculate improvement\n",
    "rmse_improvement = (test_rmse_excel - test_rmse_fitted) / test_rmse_excel * 100\n",
    "print(f\"\\nüìà RMSE Improvement: {rmse_improvement:+.2f}%\")\n",
    "\n",
    "if rmse_improvement > 0:\n",
    "    print(\"‚úÖ Data-driven model outperforms Excel\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Excel model is competitive (domain knowledge valuable?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Use Case 2: Domain Expert Knowledge\n",
    "\n",
    "**Scenario**: A refinery expert says:\n",
    "- \"Brent price increase of $1 improves margin by $0.9\"\n",
    "- \"Dubai price increase of $1 reduces margin by $0.7\" (different crude grade)\n",
    "- \"Base margin is around $45\"\n",
    "\n",
    "**Goal**: Test expert intuition against data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert coefficients\n",
    "expert_coefficients = {\n",
    "    'brent': 0.9,   # Expert: \"$1 Brent increase ‚Üí +$0.9 margin\"\n",
    "    'dubai': -0.7   # Expert: \"$1 Dubai increase ‚Üí -$0.7 margin\"\n",
    "}\n",
    "expert_intercept = 45.0  # Expert: \"Base margin is $45\"\n",
    "\n",
    "print(\"üß† Domain Expert Coefficients:\")\n",
    "print(f\"  Intercept: ${expert_intercept}\")\n",
    "print(f\"  Brent: ${expert_coefficients['brent']} per $1 Brent increase\")\n",
    "print(f\"  Dubai: ${expert_coefficients['dubai']} per $1 Dubai increase\")\n",
    "\n",
    "# Create expert model\n",
    "expert_model = manual_reg(\n",
    "    coefficients=expert_coefficients,\n",
    "    intercept=expert_intercept\n",
    ")\n",
    "\n",
    "# Fit and evaluate\n",
    "fit_expert = expert_model.fit(train_data, 'margin ~ brent + dubai')\n",
    "eval_expert = fit_expert.evaluate(test_data)\n",
    "outputs_expert, coeffs_expert, stats_expert = eval_expert.extract_outputs()\n",
    "\n",
    "# Extract test metrics (LONG format - manual_reg)\n",
    "test_stats = stats_expert[stats_expert['split'] == 'test']\n",
    "test_rmse_expert = test_stats[test_stats['metric'] == 'rmse']['value'].iloc[0]\n",
    "test_mae_expert = test_stats[test_stats['metric'] == 'mae']['value'].iloc[0]\n",
    "test_r2_expert = test_stats[test_stats['metric'] == 'r_squared']['value'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä Expert Model - Test Performance:\")\n",
    "print(f\"RMSE: {test_rmse_expert:.4f}\")\n",
    "print(f\"MAE:  {test_mae_expert:.4f}\")\n",
    "print(f\"R¬≤:   {test_r2_expert:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full comparison\n",
    "comparison_all = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Excel (Manual)',\n",
    "        'Brent_Coef': excel_coefficients['brent'],\n",
    "        'Dubai_Coef': excel_coefficients['dubai'],\n",
    "        'Intercept': excel_intercept,\n",
    "        'Test_RMSE': test_rmse_excel,\n",
    "        'Test_R¬≤': test_r2_excel\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Expert Knowledge',\n",
    "        'Brent_Coef': expert_coefficients['brent'],\n",
    "        'Dubai_Coef': expert_coefficients['dubai'],\n",
    "        'Intercept': expert_intercept,\n",
    "        'Test_RMSE': test_rmse_expert,\n",
    "        'Test_R¬≤': test_r2_expert\n",
    "    },\n",
    "    {\n",
    "        'Model': 'py-tidymodels (Data)',\n",
    "        'Brent_Coef': coeffs_fitted[coeffs_fitted['variable'] == 'brent']['coefficient'].iloc[0],\n",
    "        'Dubai_Coef': coeffs_fitted[coeffs_fitted['variable'] == 'dubai']['coefficient'].iloc[0],\n",
    "        'Intercept': coeffs_fitted[coeffs_fitted['variable'] == 'Intercept']['coefficient'].iloc[0],\n",
    "        'Test_RMSE': test_rmse_fitted,\n",
    "        'Test_R¬≤': test_r2_fitted\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nüìä FULL COMPARISON: Manual vs Expert vs Data-Driven\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_all.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_idx = comparison_all['Test_RMSE'].idxmin()\n",
    "best_model = comparison_all.iloc[best_idx]\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model['Model']}\")\n",
    "print(f\"   Test RMSE: {best_model['Test_RMSE']:.4f}\")\n",
    "print(f\"   Test R¬≤: {best_model['Test_R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Coefficient Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of coefficients\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = comparison_all['Model']\n",
    "x_pos = np.arange(len(models))\n",
    "\n",
    "# Brent coefficient\n",
    "axes[0].bar(x_pos, comparison_all['Brent_Coef'], alpha=0.7, color='steelblue')\n",
    "axes[0].set_ylabel('Coefficient Value', fontsize=11)\n",
    "axes[0].set_title('Brent Coefficient Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "# Dubai coefficient\n",
    "axes[1].bar(x_pos, comparison_all['Dubai_Coef'], alpha=0.7, color='coral')\n",
    "axes[1].set_ylabel('Coefficient Value', fontsize=11)\n",
    "axes[1].set_title('Dubai Coefficient Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"- All models agree on direction (Brent +, Dubai -)\")\n",
    "print(\"- Magnitudes differ based on source (external/expert/data)\")\n",
    "print(\"- Data-driven coefficients often close to expert knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Use Case 3: Simple Baseline\n",
    "\n",
    "**Scenario**: Create a naive baseline for benchmarking:\n",
    "- \"Margin = Brent - Dubai\" (crude spread)\n",
    "- Industry rule of thumb\n",
    "\n",
    "**Goal**: Ensure data-driven models beat this simple rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive baseline: Margin = Brent - Dubai (crude spread)\n",
    "# Simple industry rule: margin should equal the price difference\n",
    "baseline_coefficients = {\n",
    "    'brent': 1.0,   # +$1 per Brent\n",
    "    'dubai': -1.0   # -$1 per Dubai\n",
    "}\n",
    "baseline_intercept = 0.0  # No intercept (pure spread)\n",
    "\n",
    "print(\"üìè Naive Baseline Coefficients:\")\n",
    "print(f\"  Intercept: {baseline_intercept}\")\n",
    "print(f\"  Brent: {baseline_coefficients['brent']}\")\n",
    "print(f\"  Dubai: {baseline_coefficients['dubai']}\")\n",
    "print(\"\\nüí° Simple rule: Margin = Brent - Dubai\")\n",
    "\n",
    "# Create baseline model\n",
    "baseline_model = manual_reg(\n",
    "    coefficients=baseline_coefficients,\n",
    "    intercept=baseline_intercept\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate\n",
    "fit_baseline = baseline_model.fit(train_data, 'margin ~ brent + dubai')\n",
    "eval_baseline = fit_baseline.evaluate(test_data)\n",
    "outputs_baseline, coeffs_baseline, stats_baseline = eval_baseline.extract_outputs()\n",
    "\n",
    "# Extract test metrics (LONG format - manual_reg)\n",
    "test_stats = stats_baseline[stats_baseline['split'] == 'test']\n",
    "test_rmse_baseline = test_stats[test_stats['metric'] == 'rmse']['value'].iloc[0]\n",
    "test_mae_baseline = test_stats[test_stats['metric'] == 'mae']['value'].iloc[0]\n",
    "test_r2_baseline = test_stats[test_stats['metric'] == 'r_squared']['value'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä Naive Baseline - Test Performance:\")\n",
    "print(f\"RMSE: {test_rmse_baseline:.4f}\")\n",
    "print(f\"MAE:  {test_mae_baseline:.4f}\")\n",
    "print(f\"R¬≤:   {test_r2_baseline:.4f}\")\n",
    "\n",
    "# Compare with data-driven\n",
    "improvement = (test_rmse_baseline - test_rmse_fitted) / test_rmse_baseline * 100\n",
    "print(f\"\\nüìà Data-driven improvement over baseline: {improvement:+.2f}%\")\n",
    "\n",
    "if improvement > 10:\n",
    "    print(\"‚úÖ Data-driven model significantly beats naive baseline\")\n",
    "elif improvement > 0:\n",
    "    print(\"üü° Marginal improvement - consider if added complexity worth it\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Baseline competitive - may want to stick with simple rule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial specification: Only Brent coefficient known\n",
    "# Dubai coefficient will default to 0.0\n",
    "partial_coefficients = {\n",
    "    'brent': 1.0  # Only specify Brent, Dubai defaults to 0\n",
    "}\n",
    "partial_intercept = 0.0\n",
    "\n",
    "print(\"üìù Partial Model - Brent Only:\")\n",
    "print(f\"  Brent: {partial_coefficients['brent']}\")\n",
    "print(f\"  Dubai: 0.0 (default)\")\n",
    "print(f\"  Intercept: {partial_intercept}\")\n",
    "print(\"\\nüí° Missing coefficients automatically set to 0\")\n",
    "\n",
    "# Create partial model\n",
    "partial_model = manual_reg(\n",
    "    coefficients=partial_coefficients,\n",
    "    intercept=partial_intercept\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Use Case 4: Partial Coefficient Specification\n",
    "\n",
    "**Feature**: You can specify **some** coefficients, others default to 0.\n",
    "\n",
    "**Scenario**: You know Brent coefficient but unsure about Dubai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_partial = partial_model.fit(train_data, 'margin ~ brent + dubai')\n",
    "eval_partial = fit_partial.evaluate(test_data)\n",
    "outputs_partial, coeffs_partial, stats_partial = eval_partial.extract_outputs()\n",
    "\n",
    "# Extract test metrics (LONG format - manual_reg)\n",
    "test_stats = stats_partial[stats_partial['split'] == 'test']\n",
    "test_rmse_partial = test_stats[test_stats['metric'] == 'rmse']['value'].iloc[0]\n",
    "test_mae_partial = test_stats[test_stats['metric'] == 'mae']['value'].iloc[0]\n",
    "test_r2_partial = test_stats[test_stats['metric'] == 'r_squared']['value'].iloc[0]\n",
    "\n",
    "print(\"\\nüìä Partial Model - Test Performance:\")\n",
    "print(f\"RMSE: {test_rmse_partial:.4f}\")\n",
    "print(f\"MAE:  {test_mae_partial:.4f}\")\n",
    "print(f\"R¬≤:   {test_r2_partial:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Partial specification useful when:\")\n",
    "print(\"  - You know some coefficients but not all\")\n",
    "print(\"  - Want to fix certain coefficients while exploring others\")\n",
    "print(\"  - Testing sensitivity to individual coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Final Comparison: All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all models\n",
    "final_comparison = pd.DataFrame([\n",
    "    {'Model': 'Excel (Manual)', 'Source': 'External tool', 'RMSE': test_rmse_excel, 'R¬≤': test_r2_excel},\n",
    "    {'Model': 'Expert Knowledge', 'Source': 'Domain expert', 'RMSE': test_rmse_expert, 'R¬≤': test_r2_expert},\n",
    "    {'Model': 'Naive Baseline', 'Source': 'Simple rule', 'RMSE': test_rmse_baseline, 'R¬≤': test_r2_baseline},\n",
    "    {'Model': 'Partial (Brent only)', 'Source': 'Partial spec', 'RMSE': test_rmse_partial, 'R¬≤': test_r2_partial},\n",
    "    {'Model': 'py-tidymodels (Fitted)', 'Source': 'Data-driven', 'RMSE': test_rmse_fitted, 'R¬≤': test_r2_fitted}\n",
    "]).sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL COMPARISON: All Models (sorted by RMSE)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(final_comparison.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best = final_comparison.iloc[0]\n",
    "print(f\"\\nüèÜ BEST MODEL: {best['Model']}\")\n",
    "print(f\"   Source: {best['Source']}\")\n",
    "print(f\"   Test RMSE: {best['RMSE']:.4f}\")\n",
    "print(f\"   Test R¬≤: {best['R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['green' if 'Data' in m else 'steelblue' if 'Excel' in m or 'Expert' in m else 'gray' \n",
    "          for m in final_comparison['Model']]\n",
    "\n",
    "bars = ax.barh(final_comparison['Model'], final_comparison['RMSE'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Test RMSE (lower is better)', fontsize=11)\n",
    "ax.set_title('Manual vs Data-Driven Models', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height()/2, \n",
    "            f'{width:.4f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "## When to Use Manual Regression\n",
    "\n",
    "### ‚úÖ Use Cases\n",
    "\n",
    "1. **External Tool Comparison**\n",
    "   - Reproduce Excel/R/SAS forecasts\n",
    "   - Validate migration from legacy systems\n",
    "   - Audit trail and compliance\n",
    "\n",
    "2. **Domain Expert Knowledge**\n",
    "   - Incorporate subject matter expertise\n",
    "   - Test expert intuition vs data\n",
    "   - Combine domain knowledge with ML\n",
    "\n",
    "3. **Baseline Creation**\n",
    "   - Simple benchmarks for comparison\n",
    "   - Industry standard coefficients\n",
    "   - Naive rules of thumb\n",
    "\n",
    "4. **Legacy System Reproduction**\n",
    "   - Exact match of old forecasts\n",
    "   - Regulatory compliance\n",
    "   - Business continuity\n",
    "\n",
    "5. **Sensitivity Analysis**\n",
    "   - Test impact of coefficient changes\n",
    "   - \"What if\" scenarios\n",
    "   - Explore coefficient ranges\n",
    "\n",
    "### ‚ùå When NOT to Use\n",
    "\n",
    "- You don't have external coefficients\n",
    "- Data-driven fitting is preferred\n",
    "- No need for external validation\n",
    "- Coefficients are unknown\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### Validation\n",
    "1. **Always compare** manual vs fitted models\n",
    "2. **Check if manual coefficients are reasonable** (sign, magnitude)\n",
    "3. **Evaluate on test set** (don't just trust coefficients)\n",
    "4. **Document source** of manual coefficients\n",
    "\n",
    "### Coefficient Specification\n",
    "```python\n",
    "# Full specification\n",
    "manual_reg(\n",
    "    coefficients={'x1': 1.5, 'x2': -0.3},\n",
    "    intercept=10.0\n",
    ")\n",
    "\n",
    "# Partial specification (others default to 0)\n",
    "manual_reg(\n",
    "    coefficients={'x1': 1.5},  # x2 will be 0\n",
    "    intercept=10.0\n",
    ")\n",
    "\n",
    "# Variable names must match formula\n",
    "fit = spec.fit(data, 'y ~ x1 + x2')  # Matches coefficient names\n",
    "```\n",
    "\n",
    "### Statistical Inference\n",
    "- **No p-values or confidence intervals** (coefficients not estimated)\n",
    "- `coeffs` DataFrame will have NaN for std_error, t_stat, p_value\n",
    "- This is expected - manual coefficients bypass statistical inference\n",
    "\n",
    "### Integration with Workflows\n",
    "```python\n",
    "from py_workflows import Workflow\n",
    "\n",
    "# Manual model in workflow\n",
    "wf = Workflow().add_formula('y ~ x1 + x2').add_model(\n",
    "    manual_reg(coefficients={'x1': 1.5, 'x2': -0.3}, intercept=10.0)\n",
    ")\n",
    "\n",
    "fit = wf.fit(train_data)\n",
    "predictions = fit.predict(test_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "### ‚ùå Mismatched Variable Names\n",
    "```python\n",
    "# Wrong\n",
    "spec = manual_reg(coefficients={'x1': 1.5})\n",
    "fit = spec.fit(data, 'y ~ x_1')  # Variable name mismatch!\n",
    "\n",
    "# Correct\n",
    "spec = manual_reg(coefficients={'x_1': 1.5})\n",
    "fit = spec.fit(data, 'y ~ x_1')  # Names match\n",
    "```\n",
    "\n",
    "### ‚ùå Forgetting Intercept\n",
    "```python\n",
    "# May want intercept=0 sometimes, but usually need it\n",
    "spec = manual_reg(\n",
    "    coefficients={'x1': 1.5},\n",
    "    intercept=10.0  # Don't forget!\n",
    ")\n",
    "```\n",
    "\n",
    "### ‚ùå Unrealistic Coefficients\n",
    "```python\n",
    "# Always sanity check coefficients\n",
    "# - Sign make sense? (temperature ‚Üí heating: negative?)\n",
    "# - Magnitude reasonable? (not 10000 when data range is 0-100)\n",
    "# - Units correct? (per dollar, per degree, etc.)\n",
    "```\n",
    "\n",
    "### ‚ùå Not Comparing with Data-Driven\n",
    "```python\n",
    "# Always fit data-driven model for comparison\n",
    "manual_fit = manual_reg(...).fit(train, formula)\n",
    "fitted_fit = linear_reg().fit(train, formula)  # Compare!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Production Considerations\n",
    "\n",
    "### Documentation\n",
    "- Document source of coefficients (Excel file, expert name, date)\n",
    "- Version control coefficient values\n",
    "- Explain rationale for manual specification\n",
    "\n",
    "### Monitoring\n",
    "- Track manual model performance over time\n",
    "- Alert if performance degrades significantly\n",
    "- Periodically re-evaluate if data-driven would be better\n",
    "\n",
    "### When to Refit\n",
    "- Manual coefficients are fixed (no retraining)\n",
    "- Consider refitting data-driven model periodically\n",
    "- Compare manual vs fitted performance regularly\n",
    "\n",
    "### Audit Trail\n",
    "- Save coefficient values and sources\n",
    "- Track who provided coefficients and when\n",
    "- Document any coefficient updates\n",
    "\n",
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "- **Manual Regression Documentation**: `_md/ISSUE_8_MANUAL_MODEL_SUMMARY.md`\n",
    "- **Linear Regression**: Example 02 (parsnip demo)\n",
    "- **Model Comparison**: Example 11 (WorkflowSet)\n",
    "- **CLAUDE.md**: Complete architecture documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
