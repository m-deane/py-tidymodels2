{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tuning: Bayesian Optimization with Gaussian Processes (tune_bayes)\n",
    "\n",
    "This notebook demonstrates **Bayesian optimization** for hyperparameter tuning using Gaussian Process surrogates.\n",
    "\n",
    "## Key Benefits:\n",
    "- **Most sample-efficient**: Best for expensive model evaluations\n",
    "- **Probabilistic surrogate**: Models uncertainty in performance\n",
    "- **Acquisition functions**: Balances exploration vs exploitation\n",
    "- **Sequential**: Each evaluation informs the next choice\n",
    "\n",
    "## Bayesian Optimization Algorithm:\n",
    "1. **Initial phase**: Random sampling (build surrogate)\n",
    "2. **Fit GP**: Model performance surface with uncertainty\n",
    "3. **Acquisition**: Find point maximizing expected improvement/utility\n",
    "4. **Evaluate**: Test the proposed configuration\n",
    "5. **Update GP**: Incorporate new observation\n",
    "6. **Repeat** until budget exhausted\n",
    "\n",
    "## Acquisition Functions:\n",
    "- **Expected Improvement (EI)**: How much better than current best?\n",
    "- **Probability of Improvement (PI)**: Chance of beating current best?\n",
    "- **Upper Confidence Bound (UCB)**: Optimistic estimate with exploration bonus\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, boost_tree, svm_rbf\n",
    "from py_rsample import vfold_cv\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "from py_tune import (\n",
    "    tune, grid_regular, tune_grid,\n",
    "    tune_bayes, control_bayes\n",
    ")\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../_md/__data/preem.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.drop(columns=['date'])  # Drop date to avoid patsy categorical issues\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "FORMULA = \"target ~ totaltar + mean_med_diesel_crack_input1_trade_month_lag2 + mean_nwe_hsfo_crack_trade_month_lag1 + mean_nwe_lsfo_crack_trade_month\"\n",
    "\n",
    "print(f\"Formula: {FORMULA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Elastic Net with Expected Improvement\n",
    "\n",
    "### 1.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net workflow\n",
    "wf_elasticnet = (\n",
    "    workflow()\n",
    "    .add_formula(FORMULA)\n",
    "    .add_model(\n",
    "        linear_reg(\n",
    "            penalty=tune(),\n",
    "            mixture=tune()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define parameter space\n",
    "param_info = {\n",
    "    'penalty': {'range': (0.001, 10.0), 'trans': 'log'},\n",
    "    'mixture': {'range': (0.0, 1.0)}\n",
    "}\n",
    "\n",
    "print(\"Parameter space:\")\n",
    "for param, info in param_info.items():\n",
    "    trans = info.get('trans', 'none')\n",
    "    print(f\"  {param}: {info['range']} (trans: {trans})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV folds\n",
    "cv_folds = vfold_cv(df, v=5)\n",
    "print(f\"Created {len(cv_folds)} CV folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Baseline: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for comparison\n",
    "grid = grid_regular(param_info, levels=10)  # 100 combinations\n",
    "\n",
    "print(f\"Running grid search with {len(grid)} combinations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "grid_results = tune_grid(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    grid=grid,\n",
    "    metrics=metric_set(rmse, mae)\n",
    ")\n",
    "\n",
    "grid_time = time.time() - start_time\n",
    "grid_best_rmse = grid_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "\n",
    "print(f\"\u2713 Grid search: {grid_time:.1f}s, best RMSE: {grid_best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bayesian Optimization with Expected Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Bayesian optimization\n",
    "bayes_ctrl = control_bayes(\n",
    "    n_initial=5,           # Random initial points to build GP\n",
    "    n_iter=20,             # Bayesian optimization iterations\n",
    "    acquisition='ei',      # Expected Improvement\n",
    "    kappa=2.576,           # Exploration parameter (for UCB)\n",
    "    xi=0.01,               # Exploration parameter (for EI/PI)\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Bayesian Optimization Configuration:\")\n",
    "print(f\"  Initial random points: {bayes_ctrl.n_initial}\")\n",
    "print(f\"  Bayesian iterations: {bayes_ctrl.n_iter}\")\n",
    "print(f\"  Total evaluations: {bayes_ctrl.n_initial + bayes_ctrl.n_iter}\")\n",
    "print(f\"  Acquisition function: {bayes_ctrl.acquisition}\")\n",
    "print(f\"  Exploration (xi): {bayes_ctrl.xi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian optimization\n",
    "print(\"\\nRunning Bayesian optimization with Expected Improvement...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "bayes_results = tune_bayes(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse, mae),\n",
    "    control=bayes_ctrl\n",
    ")\n",
    "\n",
    "bayes_time = time.time() - start_time\n",
    "print(f\"\\n\u2713 Bayesian optimization complete in {bayes_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "bayes_best_rmse = bayes_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "n_bayes_evals = len(bayes_results.grid)\n",
    "n_grid_evals = len(grid)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: Grid Search vs Bayesian Optimization\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nGrid search:\")\n",
    "print(f\"  Evaluations: {n_grid_evals}\")\n",
    "print(f\"  Time: {grid_time:.1f}s\")\n",
    "print(f\"  Best RMSE: {grid_best_rmse:.4f}\")\n",
    "print(f\"\\nBayesian Optimization:\")\n",
    "print(f\"  Evaluations: {n_bayes_evals}\")\n",
    "print(f\"  Time: {bayes_time:.1f}s\")\n",
    "print(f\"  Best RMSE: {bayes_best_rmse:.4f}\")\n",
    "print(f\"\\nEfficiency:\")\n",
    "print(f\"  Speedup: {grid_time / bayes_time:.2f}x\")\n",
    "print(f\"  Evaluation reduction: {(1 - n_bayes_evals/n_grid_evals)*100:.1f}%\")\n",
    "print(f\"  Performance ratio: {bayes_best_rmse / grid_best_rmse:.4f}\")\n",
    "\n",
    "if bayes_best_rmse <= grid_best_rmse * 1.01:\n",
    "    print(\"\\n\u2713 Bayesian optimization found comparable/better solution with 4x fewer evaluations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualize Bayesian Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract search trajectory\n",
    "bayes_metrics = bayes_results.metrics\n",
    "rmse_values = bayes_metrics[bayes_metrics['metric'] == 'rmse'].groupby('.config')['value'].mean()\n",
    "configs = [int(c.split('_')[1]) for c in rmse_values.index]\n",
    "\n",
    "# Separate initial random phase from Bayesian phase\n",
    "n_initial = bayes_ctrl.n_initial\n",
    "initial_idx = configs[:n_initial]\n",
    "bayes_idx = configs[n_initial:]\n",
    "initial_rmse = rmse_values.iloc[:n_initial].values\n",
    "bayes_rmse = rmse_values.iloc[n_initial:].values\n",
    "\n",
    "# Plot convergence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE over iterations (split random vs Bayesian)\n",
    "ax1.scatter(initial_idx, initial_rmse, c='gray', s=80, alpha=0.6, label='Random initial')\n",
    "ax1.scatter(bayes_idx, bayes_rmse, c='blue', s=80, alpha=0.6, label='Bayesian')\n",
    "ax1.plot(configs, np.minimum.accumulate(rmse_values.values), 'r-', linewidth=2, label='Best so far')\n",
    "ax1.axhline(grid_best_rmse, color='green', linestyle='--', label='Grid search best')\n",
    "ax1.axvline(n_initial, color='gray', linestyle=':', alpha=0.5, label='End of random phase')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_title('Bayesian Optimization Convergence')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter space exploration\n",
    "penalty_values = bayes_results.grid['penalty'].values\n",
    "mixture_values = bayes_results.grid['mixture'].values\n",
    "scatter = ax2.scatter(penalty_values[:n_initial], mixture_values[:n_initial], \n",
    "                     c='gray', s=100, alpha=0.6, edgecolors='black', linewidth=0.5, label='Random')\n",
    "scatter = ax2.scatter(penalty_values[n_initial:], mixture_values[n_initial:], \n",
    "                     c=bayes_rmse, cmap='viridis', s=100, edgecolors='black', linewidth=0.5, label='Bayesian')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Penalty (log scale)')\n",
    "ax2.set_ylabel('Mixture')\n",
    "ax2.set_title('Parameter Space Exploration')\n",
    "ax2.legend()\n",
    "plt.colorbar(scatter, ax=ax2, label='RMSE')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Left: Sequential improvement over iterations\")\n",
    "print(\"\u2713 Right: GP guides search to promising regions (dark = better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing Acquisition Functions\n",
    "\n",
    "### 2.1 Probability of Improvement (PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of Improvement\n",
    "pi_ctrl = control_bayes(\n",
    "    n_initial=5,\n",
    "    n_iter=20,\n",
    "    acquisition='pi',  # Probability of Improvement\n",
    "    xi=0.01,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Running Bayesian optimization with Probability of Improvement...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pi_results = tune_bayes(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse),\n",
    "    control=pi_ctrl\n",
    ")\n",
    "\n",
    "pi_time = time.time() - start_time\n",
    "pi_best_rmse = pi_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "\n",
    "print(f\"\u2713 PI: {pi_time:.1f}s, best RMSE: {pi_best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Upper Confidence Bound (UCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper Confidence Bound\n",
    "ucb_ctrl = control_bayes(\n",
    "    n_initial=5,\n",
    "    n_iter=20,\n",
    "    acquisition='ucb',  # Upper Confidence Bound\n",
    "    kappa=2.576,        # 99% confidence interval\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Running Bayesian optimization with Upper Confidence Bound...\")\n",
    "start_time = time.time()\n",
    "\n",
    "ucb_results = tune_bayes(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse),\n",
    "    control=ucb_ctrl\n",
    ")\n",
    "\n",
    "ucb_time = time.time() - start_time\n",
    "ucb_best_rmse = ucb_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "\n",
    "print(f\"\u2713 UCB: {ucb_time:.1f}s, best RMSE: {ucb_best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Compare Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ACQUISITION FUNCTION COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nExpected Improvement (EI):     RMSE = {bayes_best_rmse:.4f}, {bayes_time:.1f}s\")\n",
    "print(f\"Probability of Improvement (PI): RMSE = {pi_best_rmse:.4f}, {pi_time:.1f}s\")\n",
    "print(f\"Upper Confidence Bound (UCB):   RMSE = {ucb_best_rmse:.4f}, {ucb_time:.1f}s\")\n",
    "\n",
    "print(\"\\nCharacteristics:\")\n",
    "print(\"  EI: Balanced exploration/exploitation (default choice)\")\n",
    "print(\"  PI: More exploitative (prefers immediate improvement)\")\n",
    "print(\"  UCB: More exploratory (optimistic exploration bonus)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost with Bayesian Optimization\n",
    "\n",
    "Test on high-dimensional parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost workflow (4D parameter space)\n",
    "wf_xgb = (\n",
    "    workflow()\n",
    "    .add_formula(FORMULA)\n",
    "    .add_model(\n",
    "        boost_tree(\n",
    "            trees=tune(),\n",
    "            tree_depth=tune(),\n",
    "            learn_rate=tune(),\n",
    "            min_n=tune()\n",
    "        ).set_mode(\"regression\").set_engine(\"xgboost\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4D parameter space\n",
    "xgb_param_info = {\n",
    "    'trees': {'range': (50, 300), 'type': 'int'},\n",
    "    'tree_depth': {'range': (3, 10), 'type': 'int'},\n",
    "    'learn_rate': {'range': (0.001, 0.3), 'trans': 'log'},\n",
    "    'min_n': {'range': (2, 40), 'type': 'int'}\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameter space (4D):\")\n",
    "for param, info in xgb_param_info.items():\n",
    "    print(f\"  {param}: {info['range']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian optimization on XGBoost\n",
    "xgb_bayes_ctrl = control_bayes(\n",
    "    n_initial=10,  # More initial points for 4D space\n",
    "    n_iter=30,     # More iterations\n",
    "    acquisition='ei',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nRunning Bayesian optimization on XGBoost (4D)...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_bayes_results = tune_bayes(\n",
    "    wf_xgb,\n",
    "    resamples=cv_folds,\n",
    "    param_info=xgb_param_info,\n",
    "    metrics=metric_set(rmse, mae, r_squared),\n",
    "    control=xgb_bayes_ctrl\n",
    ")\n",
    "\n",
    "xgb_bayes_time = time.time() - start_time\n",
    "print(f\"\\n\u2713 XGBoost Bayesian optimization complete in {xgb_bayes_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best XGBoost configurations\n",
    "print(\"Top 5 XGBoost configurations:\")\n",
    "xgb_bayes_results.show_best(metric=\"rmse\", n=5, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with grid search equivalence\n",
    "n_xgb_evals = len(xgb_bayes_results.grid)\n",
    "equivalent_grid_size = 5 ** 4  # 5 levels for 4 parameters\n",
    "\n",
    "print(f\"\\nXGBoost efficiency:\")\n",
    "print(f\"  Bayesian Optimization: {n_xgb_evals} evaluations\")\n",
    "print(f\"  Equivalent grid (5^4): {equivalent_grid_size} evaluations\")\n",
    "print(f\"  Reduction: {(1 - n_xgb_evals/equivalent_grid_size)*100:.1f}%\")\n",
    "print(f\"\\n\u2713 Bayesian optimization excels in high-dimensional spaces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced: Custom Exploration Parameters\n",
    "\n",
    "### 4.1 Effect of xi (EI exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different xi values\n",
    "xi_values = [0.001, 0.01, 0.1, 0.5]\n",
    "xi_results = {}\n",
    "\n",
    "print(\"Testing different xi values (EI exploration parameter)...\\n\")\n",
    "\n",
    "for xi in xi_values:\n",
    "    print(f\"xi = {xi}...\")\n",
    "    ctrl = control_bayes(n_initial=5, n_iter=15, acquisition='ei', xi=xi, verbose=False)\n",
    "    \n",
    "    results = tune_bayes(\n",
    "        wf_elasticnet,\n",
    "        resamples=cv_folds,\n",
    "        param_info=param_info,\n",
    "        metrics=metric_set(rmse),\n",
    "        control=ctrl\n",
    "    )\n",
    "    \n",
    "    best_rmse = results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "    xi_results[xi] = best_rmse\n",
    "    print(f\"  \u2192 Best RMSE: {best_rmse:.4f}\\n\")\n",
    "\n",
    "print(\"\\nxi comparison:\")\n",
    "print(\"=\" * 50)\n",
    "for xi, rmse in xi_results.items():\n",
    "    print(f\"xi = {xi:6.3f}:  RMSE = {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n\u2713 Lower xi = more exploitation (greedy)\")\n",
    "print(\"\u2713 Higher xi = more exploration (optimistic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Effect of kappa (UCB exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different kappa values\n",
    "kappa_values = [1.0, 2.576, 5.0]  # 68%, 99%, aggressive\n",
    "kappa_results = {}\n",
    "\n",
    "print(\"Testing different kappa values (UCB exploration parameter)...\\n\")\n",
    "\n",
    "for kappa in kappa_values:\n",
    "    print(f\"kappa = {kappa}...\")\n",
    "    ctrl = control_bayes(n_initial=5, n_iter=15, acquisition='ucb', kappa=kappa, verbose=False)\n",
    "    \n",
    "    results = tune_bayes(\n",
    "        wf_elasticnet,\n",
    "        resamples=cv_folds,\n",
    "        param_info=param_info,\n",
    "        metrics=metric_set(rmse),\n",
    "        control=ctrl\n",
    "    )\n",
    "    \n",
    "    best_rmse = results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "    kappa_results[kappa] = best_rmse\n",
    "    print(f\"  \u2192 Best RMSE: {best_rmse:.4f}\\n\")\n",
    "\n",
    "print(\"\\nkappa comparison:\")\n",
    "print(\"=\" * 50)\n",
    "for kappa, rmse in kappa_results.items():\n",
    "    print(f\"kappa = {kappa:5.3f}:  RMSE = {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n\u2713 Lower kappa = more exploitation (mean-focused)\")\n",
    "print(\"\u2713 Higher kappa = more exploration (uncertainty bonus)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Best Practices\n",
    "\n",
    "### When to use Bayesian Optimization:\n",
    "- \u2713 **Expensive models** (slow to train, e.g., deep learning)\n",
    "- \u2713 **Limited budget** (can only afford 20-50 evaluations)\n",
    "- \u2713 **Continuous parameters** (works on continuous spaces)\n",
    "- \u2713 **Black-box optimization** (no gradient information)\n",
    "- \u2713 **Sequential** tuning (can't parallelize evaluations)\n",
    "\n",
    "### Acquisition Function Selection:\n",
    "\n",
    "**Expected Improvement (EI)**:\n",
    "- Default choice for most cases\n",
    "- Balanced exploration/exploitation\n",
    "- Robust across different problems\n",
    "\n",
    "**Probability of Improvement (PI)**:\n",
    "- More exploitative\n",
    "- Good when you have a target performance\n",
    "- Faster convergence, may miss global optimum\n",
    "\n",
    "**Upper Confidence Bound (UCB)**:\n",
    "- More exploratory\n",
    "- Good for exploration-heavy tasks\n",
    "- Principled uncertainty-based exploration\n",
    "\n",
    "### Configuration Guidelines:\n",
    "\n",
    "**n_initial** (random phase):\n",
    "- 2D: 5-10 points\n",
    "- 3-4D: 10-20 points\n",
    "- 5+D: 20-30 points\n",
    "- Rule of thumb: 2-5 \u00d7 number of dimensions\n",
    "\n",
    "**n_iter** (Bayesian phase):\n",
    "- 20-50: Quick search\n",
    "- 50-100: Standard\n",
    "- 100+: Thorough search\n",
    "\n",
    "**xi** (for EI/PI):\n",
    "- 0.001: Greedy (exploitation)\n",
    "- 0.01: Balanced (default)\n",
    "- 0.1-0.5: Exploratory\n",
    "\n",
    "**kappa** (for UCB):\n",
    "- 1.0: Conservative (68% CI)\n",
    "- 2.576: Standard (99% CI)\n",
    "- 5.0+: Aggressive exploration\n",
    "\n",
    "### Expected Performance:\n",
    "- **Most sample-efficient** method\n",
    "- **5-10x fewer evaluations** than grid search\n",
    "- **Finds global optimum** with high probability\n",
    "- **Overhead**: GP fitting (negligible for expensive models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL SUMMARY: tune_bayes()\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset: {df.shape[0]} observations\")\n",
    "print(f\"\\nElastic Net (2D space):\")\n",
    "print(f\"  Grid search: {n_grid_evals} evals, {grid_time:.1f}s, RMSE={grid_best_rmse:.4f}\")\n",
    "print(f\"  Bayesian Optimization: {n_bayes_evals} evals, {bayes_time:.1f}s, RMSE={bayes_best_rmse:.4f}\")\n",
    "print(f\"  Speedup: {grid_time / bayes_time:.2f}x\")\n",
    "print(f\"  Efficiency: {(1 - n_bayes_evals/n_grid_evals)*100:.0f}% fewer evaluations\")\n",
    "print(f\"\\nXGBoost (4D space):\")\n",
    "print(f\"  Bayesian Optimization: {n_xgb_evals} evals vs {equivalent_grid_size} grid evals\")\n",
    "print(f\"  Reduction: {(1 - n_xgb_evals/equivalent_grid_size)*100:.0f}%\")\n",
    "print(f\"\\nKey advantages:\")\n",
    "print(\"  \u2713 Most sample-efficient hyperparameter optimization\")\n",
    "print(\"  \u2713 Gaussian Process models performance surface + uncertainty\")\n",
    "print(\"  \u2713 Sequential: each evaluation informs next choice\")\n",
    "print(\"  \u2713 Three acquisition functions (EI, PI, UCB)\")\n",
    "print(\"  \u2713 Scales to moderate dimensions (4-10 parameters)\")\n",
    "print(\"  \u2713 Ideal for expensive models (deep learning, large ensembles)\")\n",
    "print(\"\\n\u2713 State-of-the-art hyperparameter optimization\")\n",
    "print(\"\u2713 Industry standard for expensive black-box optimization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}