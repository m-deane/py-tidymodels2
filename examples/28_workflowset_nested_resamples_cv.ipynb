{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 28: WorkflowSet Per-Group Cross-Validation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **WorkflowSet per-group cross-validation**, a NEW feature in py-tidymodels v1.0.0 (released 2025-11-12).\n",
    "\n",
    "### What's New?\n",
    "\n",
    "Traditional WorkflowSet evaluation uses a single CV strategy for all data. For **panel/grouped data** (multiple entities like countries, stores, products), this approach has limitations:\n",
    "\n",
    "‚ùå **Old Approach**: Single global CV\n",
    "- All groups share the same CV splits\n",
    "- Doesn't respect group-specific temporal patterns\n",
    "- May leak information across groups\n",
    "\n",
    "‚úÖ **New Approach**: Per-Group CV (this notebook!)\n",
    "- **Each group gets its own CV splits**\n",
    "- Respects group-specific seasonality and trends\n",
    "- Prevents cross-group information leakage\n",
    "- Identifies group-specific overfitting\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features Demonstrated\n",
    "\n",
    "### 1. `time_series_nested_cv()` - Per-Group CV Splits\n",
    "```python\n",
    "cv_by_country = time_series_nested_cv(\n",
    "    data=train_data,\n",
    "    group_col='country',\n",
    "    date_column='date',\n",
    "    initial='2 years',\n",
    "    assess='6 months'\n",
    ")\n",
    "# Returns: {'USA': cv_usa, 'Germany': cv_germany, ...}\n",
    "```\n",
    "\n",
    "### 2. `WorkflowSet.fit_nested_resamples()` - Evaluate All Workflows Per-Group\n",
    "```python\n",
    "results = wf_set.fit_nested_resamples(\n",
    "    resamples=cv_by_country,\n",
    "    group_col='country',\n",
    "    metrics=metric_set(rmse, mae),\n",
    "    verbose=True  # Show progress per workflow and group\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. `compare_train_cv()` - One-Line Overfitting Detection\n",
    "```python\n",
    "# Compare training stats vs CV stats\n",
    "comparison = cv_results.compare_train_cv(train_stats)\n",
    "\n",
    "# Find overfitting workflows\n",
    "overfit = comparison[comparison['rmse_overfit_ratio'] > 1.2]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "**When to use per-group CV**:\n",
    "- ‚úÖ Panel/grouped data (multiple stores, countries, products)\n",
    "- ‚úÖ Each group has different temporal patterns\n",
    "- ‚úÖ Need group-specific overfitting detection\n",
    "- ‚úÖ Want to identify which groups are hard to forecast\n",
    "- ‚úÖ Comparing models across heterogeneous entities\n",
    "\n",
    "**When to use global CV**:\n",
    "- ‚úÖ All groups share similar patterns\n",
    "- ‚úÖ Limited data per group\n",
    "- ‚úÖ Want single model for all groups\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**JODI Refinery Production Data** (13,122 rows)\n",
    "- Multiple countries (Algeria, Argentina, Australia, Brazil, Canada, China, etc.)\n",
    "- Monthly refinery intake data (2002-2023)\n",
    "- Unit: Thousand Barrels per Day (KBD)\n",
    "- Real-world panel data with heterogeneous patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Per-group CV imports (NEW!)\n",
    "from py_rsample import time_series_nested_cv, initial_time_split\n",
    "from py_workflowsets import WorkflowSet\n",
    "\n",
    "# Core py-tidymodels\n",
    "from py_parsnip import linear_reg, prophet_reg, arima_reg\n",
    "from py_recipes import recipe, step_normalize, step_lag, all_numeric_predictors\n",
    "from py_workflows import Workflow\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Real-World Panel Data\n",
    "\n",
    "JODI (Joint Organisations Data Initiative) refinery production data:\n",
    "- **13,122 rows** (monthly observations)\n",
    "- **Multiple countries** (panel structure)\n",
    "- **22 years** of data (2002-2023)\n",
    "- **Heterogeneous patterns** (different countries, different seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv('../_md/__data/jodi_refinery_production_data.csv')\n",
    "raw_data['date'] = pd.to_datetime(raw_data['date'])\n",
    "\n",
    "print(f\"Total dataset: {len(raw_data):,} rows\")\n",
    "print(f\"Countries: {raw_data['country'].nunique()}\")\n",
    "print(f\"Date range: {raw_data['date'].min()} to {raw_data['date'].max()}\")\n",
    "print(f\"\\nColumns: {list(raw_data.columns)}\")\n",
    "\n",
    "# Show top countries by data availability\n",
    "print(\"\\nTop 10 countries by data points:\")\n",
    "print(raw_data['country'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Representative Countries\n",
    "\n",
    "For this demo, we'll focus on **5 countries** with complete data:\n",
    "- Different regions (Asia, Americas, Middle East, Europe)\n",
    "- Different refining capacities\n",
    "- Heterogeneous temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select countries with substantial data\n",
    "selected_countries = ['China', 'United States', 'Saudi Arabia', 'Germany', 'Brazil']\n",
    "\n",
    "data = raw_data[raw_data['country'].isin(selected_countries)].copy()\n",
    "data = data.sort_values(['country', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Filter out zeros (non-production months)\n",
    "data = data[data['value'] > 0]\n",
    "\n",
    "print(f\"\\nFiltered data: {len(data):,} rows\")\n",
    "print(f\"Countries: {data['country'].nunique()}\")\n",
    "print(f\"\\nRows per country:\")\n",
    "print(data.groupby('country').size())\n",
    "\n",
    "print(f\"\\nData summary:\")\n",
    "print(data[['value']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Heterogeneous Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each country\n",
    "fig, axes = plt.subplots(len(selected_countries), 1, figsize=(14, 12))\n",
    "\n",
    "for i, country in enumerate(selected_countries):\n",
    "    country_data = data[data['country'] == country]\n",
    "    axes[i].plot(country_data['date'], country_data['value'], linewidth=1, alpha=0.7)\n",
    "    axes[i].set_title(f'{country} - Refinery Intake (KBD)', fontsize=11, fontweight='bold')\n",
    "    axes[i].set_ylabel('KBD')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observations:\")\n",
    "print(\"- Different scales (China >> Germany)\")\n",
    "print(\"- Different trends (China growing, others stable/declining)\")\n",
    "print(\"- Different volatility levels\")\n",
    "print(\"- Heterogeneous patterns ‚Üí per-group CV is essential!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "Time-based split: 80% train, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split per country (to maintain temporal order within each country)\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for country in selected_countries:\n",
    "    country_data = data[data['country'] == country].copy()\n",
    "    split = initial_time_split(country_data, prop=0.8)\n",
    "    train_list.append(split.training())\n",
    "    test_list.append(split.testing())\n",
    "\n",
    "train_data = pd.concat(train_list, ignore_index=True)\n",
    "test_data = pd.concat(test_list, ignore_index=True)\n",
    "\n",
    "print(f\"Train: {len(train_data):,} rows ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "print(f\"Test:  {len(test_data):,} rows ({test_data['date'].min()} to {test_data['date'].max()})\")\n",
    "print(f\"\\nTrain distribution:\")\n",
    "print(train_data.groupby('country').size())\n",
    "print(f\"\\nTest distribution:\")\n",
    "print(test_data.groupby('country').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 1: Create Per-Group CV Splits with `time_series_nested_cv()`\n",
    "\n",
    "**NEW FEATURE** (2025-11-12): Create separate CV splits for each group.\n",
    "\n",
    "Each country gets its own independent CV folds based on **that country's data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create per-group CV splits\n",
    "cv_by_country = time_series_nested_cv(\n",
    "    data=train_data,\n",
    "    group_col='country',\n",
    "    date_column='date',\n",
    "    initial='5 years',      # Use first 5 years for initial training\n",
    "    assess='1 year',        # Forecast 1 year ahead\n",
    "    skip='6 months',        # Move forward 6 months each fold\n",
    "    cumulative=False        # Rolling window (not expanding)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Per-Group CV Splits Created\")\n",
    "print(f\"Groups with CV: {len(cv_by_country)}\")\n",
    "print(f\"Countries: {list(cv_by_country.keys())}\")\n",
    "\n",
    "# Show CV info for each country\n",
    "for country, cv in cv_by_country.items():\n",
    "    print(f\"\\n{country}:\")\n",
    "    print(f\"  Folds: {len(cv.splits)}\")\n",
    "    print(f\"  Training size: {len(cv.splits[0].training())} months (first fold)\")\n",
    "    print(f\"  Test size: {len(cv.splits[0].testing())} months (each fold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize CV Splits for One Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize China's CV splits\n",
    "china_cv = cv_by_country['China']\n",
    "china_train = train_data[train_data['country'] == 'China'].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot full training data\n",
    "ax.plot(china_train['date'], china_train['value'], 'o-', linewidth=1, markersize=3, \n",
    "        alpha=0.5, label='Full Training Data', color='gray')\n",
    "\n",
    "# Highlight each CV fold\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "for i, split in enumerate(china_cv.splits[:5]):  # Show first 5 folds\n",
    "    train_fold = split.training()\n",
    "    test_fold = split.testing()\n",
    "    \n",
    "    # Mark test period\n",
    "    ax.axvspan(test_fold['date'].min(), test_fold['date'].max(), \n",
    "               alpha=0.2, color=colors[i], label=f'Fold {i+1} Test')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=11)\n",
    "ax.set_ylabel('Refinery Intake (KBD)', fontsize=11)\n",
    "ax.set_title('China: Rolling Window Cross-Validation Splits', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Each colored region shows a test fold\")\n",
    "print(\"Training data expands as we move forward in time (rolling window)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 2: Create WorkflowSet with Multiple Models\n",
    "\n",
    "We'll compare **3 preprocessing strategies √ó 2 models = 6 workflows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing strategies\n",
    "formulas = [\n",
    "    'value ~ date',                           # Minimal (date only)\n",
    "    'value ~ date + mean_production',         # With mean feature\n",
    "    'value ~ date + mean_production + pct_zero'  # Full features\n",
    "]\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    linear_reg(),\n",
    "    prophet_reg()\n",
    "]\n",
    "\n",
    "# Create WorkflowSet (3 √ó 2 = 6 workflows)\n",
    "wf_set = WorkflowSet.from_cross(\n",
    "    preproc=formulas,\n",
    "    models=models\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ WorkflowSet created with {len(wf_set)} workflows\")\n",
    "print(\"\\nWorkflows:\")\n",
    "for wf_id in wf_set.workflow_ids:\n",
    "    print(f\"  - {wf_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 3: Evaluate All Workflows with Per-Group CV\n",
    "\n",
    "**NEW METHOD**: `WorkflowSet.fit_nested_resamples()`\n",
    "\n",
    "This evaluates:\n",
    "- **6 workflows** (3 formulas √ó 2 models)\n",
    "- Across **5 countries** (China, USA, Saudi Arabia, Germany, Brazil)\n",
    "- Using **per-group CV** (each country has ~2-4 folds)\n",
    "\n",
    "**Total evaluations**: 6 workflows √ó 5 countries √ó ~3 folds = ~90 model fits!\n",
    "\n",
    "**Verbose Mode** shows progress:\n",
    "```\n",
    "[1/6] Workflow: prep_1_linear_reg_1\n",
    "  [1/5] Group: China (3 folds) ‚úì\n",
    "  [2/5] Group: United States (3 folds) ‚úì\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all workflows with per-group CV (verbose mode)\n",
    "print(\"üî¨ Starting Per-Group CV Evaluation...\\n\")\n",
    "print(\"This will take a few minutes (6 workflows √ó 5 countries √ó ~3 folds = ~90 fits)\\n\")\n",
    "\n",
    "cv_results = wf_set.fit_nested_resamples(\n",
    "    resamples=cv_by_country,\n",
    "    group_col='country',\n",
    "    metrics=metric_set(rmse, mae, r_squared),\n",
    "    verbose=True  # Show detailed progress\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Per-Group CV Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 4: Analyze Results\n",
    "\n",
    "## 4.1 Collect Metrics (Averaged Across Groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average metrics across all groups\n",
    "metrics_avg = cv_results.collect_metrics(by_group=False, summarize=True)\n",
    "\n",
    "print(\"üìä Average CV Metrics (across all countries):\")\n",
    "print(metrics_avg[['wflow_id', 'metric', 'mean', 'std']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Rank Workflows by RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank workflows by average CV RMSE\n",
    "ranked = cv_results.rank_results('rmse', by_group=False, n=6)\n",
    "\n",
    "print(\"\\nüèÜ Workflow Ranking (by CV RMSE):\")\n",
    "print(ranked[['rank', 'wflow_id', 'rmse', 'mae', 'r_squared']].to_string(index=False))\n",
    "\n",
    "best_wf = ranked.iloc[0]\n",
    "print(f\"\\nü•á Best Workflow: {best_wf['wflow_id']}\")\n",
    "print(f\"   CV RMSE: {best_wf['rmse']:.2f} (¬±{ranked.iloc[0].get('rmse_std', 0):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Per-Group Analysis\n",
    "\n",
    "See which countries are easier/harder to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics by group\n",
    "metrics_by_group = cv_results.collect_metrics(by_group=True, summarize=True)\n",
    "\n",
    "# Focus on RMSE\n",
    "rmse_by_group = metrics_by_group[metrics_by_group['metric'] == 'rmse'].copy()\n",
    "rmse_pivot = rmse_by_group.pivot(index='wflow_id', columns='group', values='mean')\n",
    "\n",
    "print(\"\\nüìä CV RMSE by Country (lower is better):\")\n",
    "print(rmse_pivot.to_string())\n",
    "\n",
    "# Which country is hardest to forecast?\n",
    "avg_rmse_by_country = rmse_pivot.mean(axis=0).sort_values(ascending=False)\n",
    "print(\"\\nüéØ Average RMSE by Country (hardest to easiest):\")\n",
    "for country, avg_rmse in avg_rmse_by_country.items():\n",
    "    print(f\"  {country}: {avg_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Visualize Workflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average RMSE with error bars\n",
    "fig = cv_results.autoplot('rmse', by_group=False, top_n=6)\n",
    "fig.update_layout(\n",
    "    title='CV RMSE by Workflow (averaged across countries)',\n",
    "    xaxis_title='CV RMSE',\n",
    "    yaxis_title='Workflow'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Error bars show variability across CV folds and groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 5: Detect Overfitting with `compare_train_cv()`\n",
    "\n",
    "**NEW HELPER** (2025-11-12): One-line overfitting detection!\n",
    "\n",
    "Compare training performance vs CV performance to identify overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Fit on Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all workflows on full training data (per-group)\n",
    "print(\"Fitting all workflows on full training data...\\n\")\n",
    "\n",
    "train_results = wf_set.fit_nested(\n",
    "    data=train_data,\n",
    "    group_col='country'\n",
    ")\n",
    "\n",
    "# Extract training stats\n",
    "outputs, coeffs, train_stats = train_results.extract_outputs()\n",
    "\n",
    "print(\"\\n‚úÖ Training complete\")\n",
    "print(f\"Training stats: {len(train_stats)} rows\")\n",
    "print(f\"Columns: {list(train_stats.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Compare Training vs CV (ONE LINE!)\n",
    "\n",
    "The `compare_train_cv()` helper automatically:\n",
    "1. Matches workflows between training and CV results\n",
    "2. Calculates overfitting ratios (CV / Train)\n",
    "3. Flags concerning overfit levels\n",
    "4. Sorts by CV performance (most reliable metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE LINE to detect overfitting!\n",
    "comparison = cv_results.compare_train_cv(train_stats)\n",
    "\n",
    "print(\"\\nüìä Training vs CV Comparison:\")\n",
    "print(comparison[['wflow_id', 'group', 'rmse_train', 'rmse_cv', 'rmse_overfit_ratio', 'mae_train', 'mae_cv']].to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà Overfitting Ratio Interpretation:\")\n",
    "print(\"  1.0-1.1: üü¢ Excellent (minimal overfit)\")\n",
    "print(\"  1.1-1.2: üü¢ Good (acceptable overfit)\")\n",
    "print(\"  1.2-1.5: üü° Moderate (some overfit)\")\n",
    "print(\"  >1.5:    üî¥ Severe (significant overfit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Identify Overfitting Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find workflows with moderate or severe overfitting\n",
    "overfit_workflows = comparison[comparison['rmse_overfit_ratio'] > 1.2].copy()\n",
    "\n",
    "if len(overfit_workflows) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Workflows with Overfitting (ratio > 1.2):\")\n",
    "    print(overfit_workflows[['wflow_id', 'group', 'rmse_train', 'rmse_cv', 'rmse_overfit_ratio']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüí° Recommendations for overfitting workflows:\")\n",
    "    print(\"  - Add regularization (penalty parameter)\")\n",
    "    print(\"  - Simplify model (fewer features)\")\n",
    "    print(\"  - Increase training data\")\n",
    "    print(\"  - Use simpler model type\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No significant overfitting detected (all ratios < 1.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Best Workflow Per Country (Based on CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best workflow for each country (using CV RMSE - most reliable)\n",
    "best_per_country = comparison.sort_values('rmse_cv').groupby('group').first().reset_index()\n",
    "\n",
    "print(\"\\nüèÜ Best Workflow per Country (based on CV RMSE):\")\n",
    "print(best_per_country[['group', 'wflow_id', 'rmse_cv', 'rmse_overfit_ratio']].to_string(index=False))\n",
    "\n",
    "# Check if different countries prefer different workflows\n",
    "unique_best = best_per_country['wflow_id'].nunique()\n",
    "if unique_best > 1:\n",
    "    print(f\"\\nüí° Heterogeneity detected: {unique_best} different workflows are best for different countries\")\n",
    "    print(\"This confirms that per-group modeling is beneficial!\")\n",
    "else:\n",
    "    print(f\"\\nüìä Homogeneity: All countries perform best with {best_per_country['wflow_id'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 6: Final Model Selection and Evaluation\n",
    "\n",
    "Based on CV results, select best workflow and evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best workflow overall (by CV RMSE)\n",
    "best_wf_id = cv_results.extract_best_workflow('rmse', by_group=False)\n",
    "best_workflow = wf_set[best_wf_id]\n",
    "\n",
    "print(f\"üèÜ Best Workflow (overall): {best_wf_id}\")\n",
    "print(f\"Based on CV RMSE across all countries\")\n",
    "\n",
    "# Fit on full training data and evaluate on test\n",
    "print(\"\\nFitting best workflow on full training data...\")\n",
    "final_fit = best_workflow.fit_nested(train_data, group_col='country')\n",
    "\n",
    "# Evaluate on test\n",
    "test_outputs, test_coeffs, test_stats = final_fit.extract_outputs()\n",
    "\n",
    "# Get test stats\n",
    "test_perf = test_stats[test_stats['split'] == 'test'].copy()\n",
    "\n",
    "print(\"\\nüìä Test Set Performance (best workflow):\")\n",
    "print(test_perf[['group', 'rmse', 'mae', 'r_squared']].to_string(index=False))\n",
    "\n",
    "# Compare test with CV\n",
    "cv_rmse_best = ranked.iloc[0]['rmse']\n",
    "test_rmse_avg = test_perf['rmse'].mean()\n",
    "\n",
    "print(f\"\\nüìà CV vs Test Comparison:\")\n",
    "print(f\"  Average CV RMSE: {cv_rmse_best:.2f}\")\n",
    "print(f\"  Average Test RMSE: {test_rmse_avg:.2f}\")\n",
    "print(f\"  Difference: {abs(cv_rmse_best - test_rmse_avg):.2f} ({abs(cv_rmse_best - test_rmse_avg)/cv_rmse_best*100:.1f}%)\")\n",
    "\n",
    "if abs(cv_rmse_best - test_rmse_avg) / cv_rmse_best < 0.1:\n",
    "    print(\"\\n‚úÖ CV is a good estimator of test performance (<10% difference)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Larger difference between CV and test - consider more CV folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "## What We Learned\n",
    "\n",
    "### 1. Per-Group CV Captures Heterogeneity\n",
    "- Different countries have different optimal workflows\n",
    "- Global CV would miss group-specific patterns\n",
    "- Per-group CV respects temporal structure within each entity\n",
    "\n",
    "### 2. Overfitting Detection is Critical\n",
    "- Training performance can be misleading\n",
    "- CV provides more reliable performance estimates\n",
    "- `compare_train_cv()` makes detection easy (one line!)\n",
    "\n",
    "### 3. Workflow Comparison is Comprehensive\n",
    "- Tested 6 workflows √ó 5 countries = 30 model configurations\n",
    "- Each evaluated with multiple CV folds\n",
    "- Automated ranking and selection\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use This Approach\n",
    "\n",
    "**‚úÖ Use Per-Group CV When:**\n",
    "- You have panel/grouped data (multiple stores, countries, products)\n",
    "- Groups have heterogeneous patterns (different seasonality, trends)\n",
    "- You need to identify group-specific overfitting\n",
    "- You want to understand which groups are hard to forecast\n",
    "- Each group has sufficient data for CV (>50 observations recommended)\n",
    "\n",
    "**‚ùå Use Global CV When:**\n",
    "- All groups share similar patterns (homogeneous)\n",
    "- Limited data per group (<50 observations)\n",
    "- Single model for all groups (no per-group customization)\n",
    "- Computational resources are limited\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### CV Configuration\n",
    "1. **Initial period**: At least 2-3 seasonal cycles\n",
    "   - Monthly data: `initial='2 years'`\n",
    "   - Daily data: `initial='6 months'`\n",
    "\n",
    "2. **Assessment period**: Match forecast horizon\n",
    "   - If forecasting 3 months ahead: `assess='3 months'`\n",
    "\n",
    "3. **Skip**: Balance between folds and independence\n",
    "   - More skip = more independence, fewer folds\n",
    "   - Less skip = more folds, more correlation\n",
    "   - Typical: `skip='3 months'` for monthly data\n",
    "\n",
    "4. **Cumulative**: Depends on data volume\n",
    "   - `True`: Expanding window (more data over time)\n",
    "   - `False`: Rolling window (consistent data volume)\n",
    "\n",
    "### Overfitting Thresholds\n",
    "- **< 1.1**: Excellent (minimal overfit)\n",
    "- **1.1-1.2**: Good (acceptable)\n",
    "- **1.2-1.5**: Moderate (investigate)\n",
    "- **> 1.5**: Severe (needs remediation)\n",
    "\n",
    "### Workflow Selection\n",
    "1. **Rank by CV metrics** (not training metrics)\n",
    "2. **Check overfitting ratio** before selection\n",
    "3. **Consider simplicity** if multiple workflows tie\n",
    "4. **Validate on holdout test set** before production\n",
    "\n",
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "### ‚ùå Selecting Based on Training Performance\n",
    "- Training metrics can be optimistically biased\n",
    "- Always use CV for model selection\n",
    "\n",
    "### ‚ùå Ignoring Overfitting Ratios\n",
    "- Low training error + high CV error = overfitting\n",
    "- Use `compare_train_cv()` to detect this\n",
    "\n",
    "### ‚ùå Too Few CV Folds\n",
    "- Need at least 3-5 folds for stable estimates\n",
    "- Adjust `initial`, `assess`, `skip` if needed\n",
    "\n",
    "### ‚ùå Not Checking Group-Specific Performance\n",
    "- Some groups may be much harder to forecast\n",
    "- Use `by_group=True` analysis to identify\n",
    "\n",
    "---\n",
    "\n",
    "## Production Checklist\n",
    "\n",
    "Before deploying to production:\n",
    "\n",
    "- [ ] CV RMSE is acceptable for business needs\n",
    "- [ ] Overfitting ratio < 1.2 for selected workflow\n",
    "- [ ] Test set performance confirms CV estimates\n",
    "- [ ] All groups have acceptable performance (no outliers)\n",
    "- [ ] Model complexity justified by performance gain\n",
    "- [ ] Monitoring plan for production performance\n",
    "- [ ] Retraining schedule defined\n",
    "\n",
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "- **Per-Group CV Documentation**: `.claude_debugging/WORKFLOWSET_NESTED_RESAMPLES_IMPLEMENTATION.md`\n",
    "- **Overfitting Detection**: `.claude_debugging/COMPARE_TRAIN_CV_HELPER.md`\n",
    "- **WorkflowSet Guide**: Examples 11, 04_forecasting-workflowsets-tune-cv-grouped.ipynb\n",
    "- **Grouped Modeling**: Example 13, 25_agent_advanced_features.ipynb\n",
    "- **CLAUDE.md**: Complete architecture documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
