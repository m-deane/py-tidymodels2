{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py_visualize: Interactive Model Visualization\n",
    "\n",
    "This notebook demonstrates the **py_visualize** package, which provides interactive Plotly-based visualizations for model evaluation, diagnostics, and hyperparameter tuning.\n",
    "\n",
    "## Functions Covered\n",
    "\n",
    "1. **plot_forecast()** - Time series forecast visualization\n",
    "2. **plot_residuals()** - Diagnostic plots for model validation\n",
    "3. **plot_model_comparison()** - Compare multiple models\n",
    "4. **plot_tune_results()** - Hyperparameter tuning visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import py-tidymodels packages\nfrom py_parsnip import linear_reg, rand_forest, prophet_reg\nfrom py_recipes import recipe\nfrom py_workflows import workflow\nfrom py_rsample import initial_time_split, time_series_cv\nfrom py_tune import tune, tune_grid, grid_regular\nfrom py_visualize import plot_forecast, plot_residuals, plot_model_comparison, plot_tune_results\n\nprint(\"\u2713 All packages imported successfully\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create Sample Time Series Data\n",
    "\n",
    "We'll create a time series with trend, seasonality, and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2020-01-01', periods=500, freq='D')\n",
    "time_index = np.arange(len(dates))\n",
    "\n",
    "# Trend + seasonality + noise\n",
    "trend = time_index * 0.5\n",
    "seasonality = 10 * np.sin(2 * np.pi * time_index / 30)\n",
    "noise = np.random.randn(len(dates)) * 5\n",
    "\n",
    "y = trend + seasonality + noise + 100\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'value': y\n",
    "})\n",
    "\n",
    "print(f\"Created time series with {len(data)} observations\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. plot_forecast() - Time Series Forecasting\n",
    "\n",
    "Create interactive forecast plots with prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "split = initial_time_split(data, prop=0.8)\n",
    "train_data = split.training()\n",
    "test_data = split.testing()\n",
    "\n",
    "print(f\"Training: {len(train_data)} observations\")\n",
    "print(f\"Testing: {len(test_data)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a linear regression model with lags\n",
    "rec = (\n",
    "    recipe(value ~ date, data=train_data)\n",
    "    .step_date('date', features=['month', 'week', 'doy'])\n",
    "    .step_lag('value', lags=[1, 7, 30])\n",
    "    .step_normalize(['value_lag_1', 'value_lag_7', 'value_lag_30'])\n",
    ")\n",
    "\n",
    "wf = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg())\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "fit = wf.fit(train_data)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = fit.predict(test_data)\n",
    "\n",
    "print(\"\u2713 Model fitted and predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast\n",
    "fig = plot_forecast(\n",
    "    fit,\n",
    "    prediction_intervals=True,\n",
    "    title=\"Linear Regression Forecast with Lags\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca The plot shows:\")\n",
    "print(\"  \u2022 Blue line: Training data (actual values)\")\n",
    "print(\"  \u2022 Red line: Test data (actual values)\")\n",
    "print(\"  \u2022 Green line: Model predictions\")\n",
    "print(\"  \u2022 Shaded region: 95% prediction intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. plot_residuals() - Diagnostic Plots\n",
    "\n",
    "Check model assumptions with comprehensive diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all diagnostics (2x2 grid)\n",
    "fig = plot_residuals(\n",
    "    fit,\n",
    "    plot_type=\"all\",\n",
    "    title=\"Model Diagnostics: Linear Regression\",\n",
    "    height=700,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Diagnostic plots:\")\n",
    "print(\"  \u2022 Top-left: Residuals vs Fitted (check for patterns)\")\n",
    "print(\"  \u2022 Top-right: Q-Q plot (check normality)\")\n",
    "print(\"  \u2022 Bottom-left: Residuals vs Time (check for autocorrelation)\")\n",
    "print(\"  \u2022 Bottom-right: Histogram (check distribution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Diagnostic Plots\n",
    "\n",
    "You can also create individual diagnostic plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals vs Fitted only\n",
    "fig_fitted = plot_residuals(\n",
    "    fit,\n",
    "    plot_type=\"fitted\",\n",
    "    title=\"Residuals vs Fitted Values\"\n",
    ")\n",
    "\n",
    "fig_fitted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot only\n",
    "fig_qq = plot_residuals(\n",
    "    fit,\n",
    "    plot_type=\"qq\",\n",
    "    title=\"Normal Q-Q Plot\"\n",
    ")\n",
    "\n",
    "fig_qq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. plot_model_comparison() - Compare Multiple Models\n",
    "\n",
    "Compare performance metrics across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit multiple models for comparison\n",
    "\n",
    "# Model 1: Linear Regression with lags\n",
    "wf_linear = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg())\n",
    ")\n",
    "fit_linear = wf_linear.fit(train_data)\n",
    "pred_linear = fit_linear.predict(test_data)\n",
    "\n",
    "# Model 2: Random Forest\n",
    "wf_rf = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(rand_forest(trees=50, mode='regression'))\n",
    ")\n",
    "fit_rf = wf_rf.fit(train_data)\n",
    "pred_rf = fit_rf.predict(test_data)\n",
    "\n",
    "# Model 3: Ridge Regression (linear_reg with penalty)\n",
    "wf_ridge = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg(penalty=0.1, mixture=0.0))  # Ridge\n",
    ")\n",
    "fit_ridge = wf_ridge.fit(train_data)\n",
    "pred_ridge = fit_ridge.predict(test_data)\n",
    "\n",
    "print(\"\u2713 Three models fitted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stats DataFrames\n",
    "_, _, stats_linear = fit_linear.extract_outputs()\n",
    "_, _, stats_rf = fit_rf.extract_outputs()\n",
    "_, _, stats_ridge = fit_ridge.extract_outputs()\n",
    "\n",
    "# Create bar chart comparison\n",
    "fig = plot_model_comparison(\n",
    "    stats_list=[stats_linear, stats_rf, stats_ridge],\n",
    "    model_names=[\"Linear Regression\", \"Random Forest\", \"Ridge Regression\"],\n",
    "    metrics=[\"rmse\", \"mae\", \"r_squared\"],\n",
    "    split=\"test\",\n",
    "    plot_type=\"bar\",\n",
    "    title=\"Model Performance Comparison\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Lower is better for RMSE and MAE\")\n",
    "print(\"\ud83d\udcca Higher is better for R\u00b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Comparison\n",
    "\n",
    "Useful when comparing many models across many metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap view\n",
    "fig_heatmap = plot_model_comparison(\n",
    "    stats_list=[stats_linear, stats_rf, stats_ridge],\n",
    "    model_names=[\"Linear Regression\", \"Random Forest\", \"Ridge Regression\"],\n",
    "    plot_type=\"heatmap\",\n",
    "    title=\"Model Performance Heatmap\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Chart\n",
    "\n",
    "Compare models across multiple metrics simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart (metrics are normalized)\n",
    "fig_radar = plot_model_comparison(\n",
    "    stats_list=[stats_linear, stats_rf, stats_ridge],\n",
    "    model_names=[\"Linear Regression\", \"Random Forest\", \"Ridge Regression\"],\n",
    "    plot_type=\"radar\",\n",
    "    title=\"Model Performance Radar Chart\",\n",
    "    height=500,\n",
    "    width=600\n",
    ")\n",
    "\n",
    "fig_radar.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Metrics are normalized to 0-1 scale\")\n",
    "print(\"\ud83d\udcca Larger area = better overall performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. plot_tune_results() - Hyperparameter Tuning Visualization\n",
    "\n",
    "Visualize how hyperparameters affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation splits\n",
    "cv_splits = time_series_cv(\n",
    "    train_data,\n",
    "    initial=200,\n",
    "    assess=50,\n",
    "    skip=25,\n",
    "    cumulative=False\n",
    ")\n",
    "\n",
    "print(f\"Created {cv_splits.n_splits} CV splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Parameter Tuning (Line Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune penalty parameter for linear regression\n",
    "wf_tune_1d = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg(penalty=tune(), mixture=1.0))  # Lasso\n",
    ")\n",
    "\n",
    "# Create parameter grid\n",
    "grid_1d = grid_regular(\n",
    "    penalty={'range': (0.001, 1.0), 'trans': 'log'},\n",
    "    levels=8\n",
    ")\n",
    "\n",
    "# Tune\n",
    "results_1d = tune_grid(\n",
    "    wf_tune_1d,\n",
    "    resamples=cv_splits,\n",
    "    grid=grid_1d\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Tuned {len(grid_1d)} penalty values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tuning results (line plot for single parameter)\n",
    "fig = plot_tune_results(\n",
    "    results_1d,\n",
    "    metric=\"rmse\",\n",
    "    plot_type=\"line\",\n",
    "    show_best=3,\n",
    "    title=\"Penalty Parameter Tuning (Lasso Regression)\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Line plot shows how RMSE changes with penalty\")\n",
    "print(\"\ud83d\udcca Top 3 best configurations are highlighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Parameters (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune penalty and mixture for elastic net\n",
    "wf_tune_2d = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(linear_reg(penalty=tune(), mixture=tune()))\n",
    ")\n",
    "\n",
    "# Create 2D grid\n",
    "grid_2d = grid_regular(\n",
    "    penalty={'range': (0.001, 0.5), 'trans': 'log'},\n",
    "    mixture={'range': (0.0, 1.0)},\n",
    "    levels=5\n",
    ")\n",
    "\n",
    "# Tune\n",
    "results_2d = tune_grid(\n",
    "    wf_tune_2d,\n",
    "    resamples=cv_splits,\n",
    "    grid=grid_2d\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Tuned {len(grid_2d)} penalty \u00d7 mixture combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as heatmap\n",
    "fig_heatmap = plot_tune_results(\n",
    "    results_2d,\n",
    "    metric=\"rmse\",\n",
    "    plot_type=\"heatmap\",\n",
    "    show_best=5,\n",
    "    title=\"Elastic Net Tuning: Penalty vs Mixture\"\n",
    ")\n",
    "\n",
    "fig_heatmap.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Heatmap shows RMSE across parameter combinations\")\n",
    "print(\"\ud83d\udcca Darker colors = lower RMSE (better)\")\n",
    "print(\"\ud83d\udcca Best configurations are marked with \u2b50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot view (useful for visualizing correlations)\n",
    "fig_scatter = plot_tune_results(\n",
    "    results_2d,\n",
    "    metric=\"rmse\",\n",
    "    plot_type=\"scatter\",\n",
    "    title=\"Scatter Plot: Penalty vs Mixture\"\n",
    ")\n",
    "\n",
    "fig_scatter.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Color indicates RMSE value\")\n",
    "print(\"\ud83d\udcca Useful for seeing parameter interaction effects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three+ Parameters (Parallel Coordinates)\n",
    "\n",
    "When tuning 3 or more parameters, parallel coordinates plot is most effective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune random forest with multiple parameters\n",
    "wf_tune_multi = (\n",
    "    workflow()\n",
    "    .add_recipe(rec)\n",
    "    .add_model(\n",
    "        rand_forest(\n",
    "            trees=tune(),\n",
    "            min_n=tune(),\n",
    "            mode='regression'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create multi-parameter grid\n",
    "grid_multi = grid_regular(\n",
    "    trees={'range': (50, 200)},\n",
    "    min_n={'range': (2, 20)},\n",
    "    levels=4\n",
    ")\n",
    "\n",
    "# Tune (this may take a minute)\n",
    "print(\"Tuning random forest... (this may take a moment)\")\n",
    "results_multi = tune_grid(\n",
    "    wf_tune_multi,\n",
    "    resamples=cv_splits,\n",
    "    grid=grid_multi\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Tuned {len(grid_multi)} parameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as parallel coordinates\n",
    "fig_parallel = plot_tune_results(\n",
    "    results_multi,\n",
    "    metric=\"rmse\",\n",
    "    plot_type=\"parallel\",\n",
    "    title=\"Random Forest Tuning: Trees and Min_n\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig_parallel.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Each line represents one parameter configuration\")\n",
    "print(\"\ud83d\udcca Color indicates RMSE (darker = better)\")\n",
    "print(\"\ud83d\udcca Trace lines from left to right to see parameter combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Plot Type Selection\n",
    "\n",
    "Use `plot_type=\"auto\"` to automatically select the best visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-selects best plot type based on number of parameters\n",
    "fig_auto = plot_tune_results(\n",
    "    results_2d,\n",
    "    metric=\"rmse\",\n",
    "    plot_type=\"auto\",  # Automatically chooses heatmap for 2 parameters\n",
    "    title=\"Auto-Selected Plot Type\"\n",
    ")\n",
    "\n",
    "fig_auto.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Auto-selected plot type based on:\")\n",
    "print(\"  \u2022 1 parameter \u2192 Line plot\")\n",
    "print(\"  \u2022 2 parameters \u2192 Heatmap\")\n",
    "print(\"  \u2022 3+ parameters \u2192 Parallel coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The **py_visualize** package provides four powerful visualization functions:\n",
    "\n",
    "1. **plot_forecast()** - Interactive time series forecast plots\n",
    "   - Train/test/forecast visualization\n",
    "   - Prediction intervals\n",
    "   - Support for grouped/nested models\n",
    "\n",
    "2. **plot_residuals()** - Model diagnostic plots\n",
    "   - Residuals vs Fitted\n",
    "   - Q-Q plot\n",
    "   - Residuals vs Time\n",
    "   - Histogram\n",
    "\n",
    "3. **plot_model_comparison()** - Multi-model comparison\n",
    "   - Bar charts\n",
    "   - Heatmaps\n",
    "   - Radar charts\n",
    "\n",
    "4. **plot_tune_results()** - Hyperparameter visualization\n",
    "   - Line plots (1D)\n",
    "   - Heatmaps (2D)\n",
    "   - Parallel coordinates (3+D)\n",
    "   - Scatter plot matrix\n",
    "   - Auto plot type selection\n",
    "\n",
    "All plots are interactive (Plotly) and customizable!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}