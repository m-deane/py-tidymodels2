{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Time Series Models: ETS and STL Decomposition\n",
    "\n",
    "This notebook demonstrates classical time series forecasting methods including:\n",
    "- Exponential Smoothing (ETS) models\n",
    "- Seasonal and Trend decomposition using Loess (STL)\n",
    "- Model comparison and selection criteria\n",
    "- Practical applications with real-world patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Classical Time Series Forecasting\n",
    "\n",
    "Classical time series models decompose a series into components:\n",
    "\n",
    "### Time Series Components\n",
    "\n",
    "1. **Level (L)**: The average value in the series\n",
    "2. **Trend (T)**: The long-term increase or decrease\n",
    "3. **Seasonality (S)**: Repeating patterns at fixed intervals\n",
    "4. **Remainder (R)**: Random fluctuation (noise)\n",
    "\n",
    "### Decomposition Types\n",
    "\n",
    "**Additive**: $Y_t = L_t + T_t + S_t + R_t$\n",
    "- Use when seasonal variation is constant over time\n",
    "- Seasonal fluctuations have same magnitude regardless of level\n",
    "\n",
    "**Multiplicative**: $Y_t = L_t \\times T_t \\times S_t \\times R_t$\n",
    "- Use when seasonal variation changes with level\n",
    "- Seasonal fluctuations proportional to the level\n",
    "\n",
    "### Key Methods\n",
    "\n",
    "1. **Exponential Smoothing (ETS)**: State space models with error, trend, seasonality\n",
    "2. **STL Decomposition**: Robust decomposition using LOESS smoothing\n",
    "3. **ARIMA**: Autoregressive Integrated Moving Average models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Time Series Data\n",
    "\n",
    "Create datasets with known patterns for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(\n",
    "    n_periods: int = 365,\n",
    "    freq: str = 'D',\n",
    "    level: float = 100.0,\n",
    "    trend: float = 0.1,\n",
    "    seasonal_periods: List[int] = [7],\n",
    "    seasonal_magnitude: List[float] = [10.0],\n",
    "    noise_std: float = 5.0,\n",
    "    multiplicative: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic time series with configurable components.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_periods : int\n",
    "        Number of time periods\n",
    "    freq : str\n",
    "        Frequency string (D, H, M, etc.)\n",
    "    level : float\n",
    "        Base level of the series\n",
    "    trend : float\n",
    "        Linear trend coefficient\n",
    "    seasonal_periods : List[int]\n",
    "        List of seasonal periods (e.g., [7, 365] for weekly and yearly)\n",
    "    seasonal_magnitude : List[float]\n",
    "        Magnitude of each seasonal component\n",
    "    noise_std : float\n",
    "        Standard deviation of random noise\n",
    "    multiplicative : bool\n",
    "        If True, use multiplicative seasonality\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with date index and value column\n",
    "    \"\"\"\n",
    "    # Create date range\n",
    "    dates = pd.date_range(start='2022-01-01', periods=n_periods, freq=freq)\n",
    "    \n",
    "    # Base level and trend\n",
    "    t = np.arange(n_periods)\n",
    "    level_trend = level + trend * t\n",
    "    \n",
    "    # Add seasonal components\n",
    "    seasonal = np.zeros(n_periods)\n",
    "    for period, magnitude in zip(seasonal_periods, seasonal_magnitude):\n",
    "        seasonal += magnitude * np.sin(2 * np.pi * t / period)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, noise_std, n_periods)\n",
    "    \n",
    "    # Combine components\n",
    "    if multiplicative:\n",
    "        seasonal_factor = 1 + seasonal / 100  # Convert to percentage\n",
    "        values = level_trend * seasonal_factor + noise\n",
    "    else:\n",
    "        values = level_trend + seasonal + noise\n",
    "    \n",
    "    # Ensure non-negative values\n",
    "    values = np.maximum(values, 0.1)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'value': values\n",
    "    })\n",
    "    \n",
    "    return df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different types of time series\n",
    "\n",
    "# 1. Simple series with weekly seasonality (additive)\n",
    "ts_weekly_additive = generate_time_series(\n",
    "    n_periods=365,\n",
    "    level=100,\n",
    "    trend=0.2,\n",
    "    seasonal_periods=[7],\n",
    "    seasonal_magnitude=[15],\n",
    "    noise_std=5,\n",
    "    multiplicative=False\n",
    ")\n",
    "\n",
    "# 2. Series with monthly seasonality (multiplicative)\n",
    "ts_monthly_mult = generate_time_series(\n",
    "    n_periods=365,\n",
    "    level=200,\n",
    "    trend=0.5,\n",
    "    seasonal_periods=[30],\n",
    "    seasonal_magnitude=[20],\n",
    "    noise_std=8,\n",
    "    multiplicative=True\n",
    ")\n",
    "\n",
    "# 3. Complex series with multiple seasonalities\n",
    "ts_multiple = generate_time_series(\n",
    "    n_periods=730,  # 2 years\n",
    "    level=150,\n",
    "    trend=0.3,\n",
    "    seasonal_periods=[7, 365],  # Weekly and yearly\n",
    "    seasonal_magnitude=[10, 25],\n",
    "    noise_std=6,\n",
    "    multiplicative=False\n",
    ")\n",
    "\n",
    "# 4. Series without trend (for simple exponential smoothing)\n",
    "ts_no_trend = generate_time_series(\n",
    "    n_periods=200,\n",
    "    level=100,\n",
    "    trend=0.0,\n",
    "    seasonal_periods=[7],\n",
    "    seasonal_magnitude=[0],  # No seasonality\n",
    "    noise_std=10,\n",
    "    multiplicative=False\n",
    ")\n",
    "\n",
    "print(\"Generated time series:\")\n",
    "print(f\"- Weekly additive: {len(ts_weekly_additive)} observations\")\n",
    "print(f\"- Monthly multiplicative: {len(ts_monthly_mult)} observations\")\n",
    "print(f\"- Multiple seasonalities: {len(ts_multiple)} observations\")\n",
    "print(f\"- No trend: {len(ts_no_trend)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Weekly additive\n",
    "axes[0, 0].plot(ts_weekly_additive.index, ts_weekly_additive['value'], linewidth=1)\n",
    "axes[0, 0].set_title('Weekly Seasonality (Additive)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Monthly multiplicative\n",
    "axes[0, 1].plot(ts_monthly_mult.index, ts_monthly_mult['value'], linewidth=1, color='orange')\n",
    "axes[0, 1].set_title('Monthly Seasonality (Multiplicative)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Value')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Multiple seasonalities\n",
    "axes[1, 0].plot(ts_multiple.index, ts_multiple['value'], linewidth=1, color='green')\n",
    "axes[1, 0].set_title('Multiple Seasonalities (Weekly + Yearly)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: No trend\n",
    "axes[1, 1].plot(ts_no_trend.index, ts_no_trend['value'], linewidth=1, color='red')\n",
    "axes[1, 1].set_title('No Trend (Level Only)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exponential Smoothing Methods (ETS)\n",
    "\n",
    "Exponential smoothing methods use weighted averages of past observations, with weights decaying exponentially.\n",
    "\n",
    "### ETS Framework\n",
    "\n",
    "**ETS(Error, Trend, Seasonal)**\n",
    "\n",
    "- **Error**: {A=Additive, M=Multiplicative}\n",
    "- **Trend**: {N=None, A=Additive, Ad=Additive damped}\n",
    "- **Seasonal**: {N=None, A=Additive, M=Multiplicative}\n",
    "\n",
    "### Smoothing Parameters\n",
    "\n",
    "- **α (alpha)**: Level smoothing parameter [0, 1]\n",
    "  - Higher α: more weight on recent observations\n",
    "  - Lower α: smoother, more weight on historical data\n",
    "\n",
    "- **β (beta)**: Trend smoothing parameter [0, 1]\n",
    "  - Controls how quickly trend estimates change\n",
    "\n",
    "- **γ (gamma)**: Seasonal smoothing parameter [0, 1]\n",
    "  - Controls how quickly seasonal pattern changes\n",
    "\n",
    "- **φ (phi)**: Damping parameter [0, 1]\n",
    "  - Applied to trend component\n",
    "  - Prevents trend from continuing indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple Exponential Smoothing (SES)\n",
    "\n",
    "**Model**: ETS(A,N,N)\n",
    "\n",
    "For series with no clear trend or seasonality. Only models the level.\n",
    "\n",
    "**Equation**: $\\hat{y}_{t+1} = \\alpha y_t + (1-\\alpha) \\hat{y}_t$\n",
    "\n",
    "Where:\n",
    "- $\\hat{y}_{t+1}$ is the forecast for time t+1\n",
    "- $\\alpha$ is the smoothing parameter\n",
    "- $y_t$ is the actual value at time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "# Apply Simple Exponential Smoothing to no-trend series\n",
    "# Split into train/test\n",
    "train_size = int(len(ts_no_trend) * 0.8)\n",
    "train_no_trend = ts_no_trend.iloc[:train_size]\n",
    "test_no_trend = ts_no_trend.iloc[train_size:]\n",
    "\n",
    "# Fit models with different alpha values\n",
    "alpha_values = [0.1, 0.3, 0.7]\n",
    "ses_models = {}\n",
    "ses_forecasts = {}\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    model = SimpleExpSmoothing(train_no_trend['value'])\n",
    "    fitted = model.fit(smoothing_level=alpha, optimized=False)\n",
    "    ses_models[alpha] = fitted\n",
    "    ses_forecasts[alpha] = fitted.forecast(steps=len(test_no_trend))\n",
    "\n",
    "# Also fit with optimized alpha\n",
    "model_auto = SimpleExpSmoothing(train_no_trend['value'])\n",
    "fitted_auto = model_auto.fit()\n",
    "ses_models['auto'] = fitted_auto\n",
    "ses_forecasts['auto'] = fitted_auto.forecast(steps=len(test_no_trend))\n",
    "\n",
    "print(\"Simple Exponential Smoothing Results:\")\n",
    "print(f\"Optimized alpha: {fitted_auto.params['smoothing_level']:.4f}\")\n",
    "print(f\"AIC: {fitted_auto.aic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SES with different alpha values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Left: Compare different alpha values\n",
    "axes[0].plot(train_no_trend.index, train_no_trend['value'], \n",
    "             label='Training Data', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(test_no_trend.index, test_no_trend['value'], \n",
    "             label='Test Data', linewidth=2, alpha=0.7)\n",
    "\n",
    "colors = ['red', 'green', 'blue', 'purple']\n",
    "for (alpha, forecast), color in zip(ses_forecasts.items(), colors):\n",
    "    label = f'α={alpha:.1f}' if alpha != 'auto' else f'α={fitted_auto.params[\"smoothing_level\"]:.3f} (auto)'\n",
    "    axes[0].plot(test_no_trend.index, forecast, \n",
    "                 label=label, linewidth=2, linestyle='--', color=color)\n",
    "\n",
    "axes[0].set_title('Simple Exponential Smoothing: Effect of Alpha', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Fitted values vs actual (using auto alpha)\n",
    "fitted_values = fitted_auto.fittedvalues\n",
    "axes[1].plot(train_no_trend.index, train_no_trend['value'], \n",
    "             label='Actual', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(train_no_trend.index, fitted_values, \n",
    "             label='Fitted', linewidth=2, linestyle='--', alpha=0.7)\n",
    "axes[1].set_title(f'Fitted Values (α={fitted_auto.params[\"smoothing_level\"]:.3f})', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Holt's Linear Trend Method\n",
    "\n",
    "**Model**: ETS(A,A,N)\n",
    "\n",
    "Extension of SES that adds a trend component.\n",
    "\n",
    "**Equations**:\n",
    "- Level: $l_t = \\alpha y_t + (1-\\alpha)(l_{t-1} + b_{t-1})$\n",
    "- Trend: $b_t = \\beta(l_t - l_{t-1}) + (1-\\beta)b_{t-1}$\n",
    "- Forecast: $\\hat{y}_{t+h} = l_t + h \\cdot b_t$\n",
    "\n",
    "**Damped Trend**: ETS(A,Ad,N)\n",
    "- Forecast: $\\hat{y}_{t+h} = l_t + (\\phi + \\phi^2 + ... + \\phi^h) \\cdot b_t$\n",
    "- Prevents trend from continuing indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import Holt\n",
    "\n",
    "# Use weekly additive series (has trend)\n",
    "train_size = int(len(ts_weekly_additive) * 0.8)\n",
    "train_weekly = ts_weekly_additive.iloc[:train_size]\n",
    "test_weekly = ts_weekly_additive.iloc[train_size:]\n",
    "\n",
    "# Fit Holt's linear trend model\n",
    "holt_linear = Holt(train_weekly['value'])\n",
    "fitted_linear = holt_linear.fit()\n",
    "\n",
    "# Fit Holt's damped trend model\n",
    "holt_damped = Holt(train_weekly['value'], damped_trend=True)\n",
    "fitted_damped = holt_damped.fit()\n",
    "\n",
    "# Generate forecasts\n",
    "forecast_linear = fitted_linear.forecast(steps=len(test_weekly))\n",
    "forecast_damped = fitted_damped.forecast(steps=len(test_weekly))\n",
    "\n",
    "print(\"Holt's Linear Trend Method:\")\n",
    "print(f\"  α (level): {fitted_linear.params['smoothing_level']:.4f}\")\n",
    "print(f\"  β (trend): {fitted_linear.params['smoothing_trend']:.4f}\")\n",
    "print(f\"  AIC: {fitted_linear.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted_linear.bic:.2f}\")\n",
    "\n",
    "print(\"\\nHolt's Damped Trend Method:\")\n",
    "print(f\"  α (level): {fitted_damped.params['smoothing_level']:.4f}\")\n",
    "print(f\"  β (trend): {fitted_damped.params['smoothing_trend']:.4f}\")\n",
    "print(f\"  φ (damping): {fitted_damped.params['damping_trend']:.4f}\")\n",
    "print(f\"  AIC: {fitted_damped.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted_damped.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Holt's method\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Top: Forecasts comparison\n",
    "axes[0].plot(train_weekly.index, train_weekly['value'], \n",
    "             label='Training Data', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(test_weekly.index, test_weekly['value'], \n",
    "             label='Test Data', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(test_weekly.index, forecast_linear, \n",
    "             label='Linear Trend', linewidth=2, linestyle='--')\n",
    "axes[0].plot(test_weekly.index, forecast_damped, \n",
    "             label='Damped Trend', linewidth=2, linestyle='--')\n",
    "axes[0].set_title('Holt\\'s Method: Linear vs Damped Trend', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom: Components (level and trend)\n",
    "level_linear = fitted_linear.level\n",
    "trend_linear = fitted_linear.trend\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.plot(train_weekly.index, level_linear, label='Level', linewidth=2)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Level', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_weekly.index, trend_linear, label='Trend', \n",
    "         linewidth=2, color='tab:orange')\n",
    "ax2.set_ylabel('Trend', color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "axes[1].set_title('Decomposed Components: Level and Trend', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Holt-Winters Seasonal Method\n",
    "\n",
    "**Models**: ETS(A,A,A) or ETS(A,A,M)\n",
    "\n",
    "Extends Holt's method to capture seasonality.\n",
    "\n",
    "**Additive Seasonality** (constant amplitude):\n",
    "- Level: $l_t = \\alpha(y_t - s_{t-m}) + (1-\\alpha)(l_{t-1} + b_{t-1})$\n",
    "- Trend: $b_t = \\beta(l_t - l_{t-1}) + (1-\\beta)b_{t-1}$\n",
    "- Seasonal: $s_t = \\gamma(y_t - l_t) + (1-\\gamma)s_{t-m}$\n",
    "- Forecast: $\\hat{y}_{t+h} = l_t + h \\cdot b_t + s_{t+h-m}$\n",
    "\n",
    "**Multiplicative Seasonality** (changing amplitude):\n",
    "- Level: $l_t = \\alpha(y_t / s_{t-m}) + (1-\\alpha)(l_{t-1} + b_{t-1})$\n",
    "- Trend: $b_t = \\beta(l_t - l_{t-1}) + (1-\\beta)b_{t-1}$\n",
    "- Seasonal: $s_t = \\gamma(y_t / l_t) + (1-\\gamma)s_{t-m}$\n",
    "- Forecast: $\\hat{y}_{t+h} = (l_t + h \\cdot b_t) \\times s_{t+h-m}$\n",
    "\n",
    "Where $m$ is the seasonal period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Fit Holt-Winters models\n",
    "\n",
    "# Additive seasonality\n",
    "hw_add = ExponentialSmoothing(\n",
    "    train_weekly['value'],\n",
    "    seasonal_periods=7,  # Weekly seasonality\n",
    "    trend='add',\n",
    "    seasonal='add'\n",
    ")\n",
    "fitted_hw_add = hw_add.fit()\n",
    "\n",
    "# Multiplicative seasonality\n",
    "hw_mul = ExponentialSmoothing(\n",
    "    train_weekly['value'],\n",
    "    seasonal_periods=7,\n",
    "    trend='add',\n",
    "    seasonal='mul'\n",
    ")\n",
    "fitted_hw_mul = hw_mul.fit()\n",
    "\n",
    "# Damped trend with additive seasonality\n",
    "hw_damped = ExponentialSmoothing(\n",
    "    train_weekly['value'],\n",
    "    seasonal_periods=7,\n",
    "    trend='add',\n",
    "    seasonal='add',\n",
    "    damped_trend=True\n",
    ")\n",
    "fitted_hw_damped = hw_damped.fit()\n",
    "\n",
    "# Generate forecasts\n",
    "forecast_hw_add = fitted_hw_add.forecast(steps=len(test_weekly))\n",
    "forecast_hw_mul = fitted_hw_mul.forecast(steps=len(test_weekly))\n",
    "forecast_hw_damped = fitted_hw_damped.forecast(steps=len(test_weekly))\n",
    "\n",
    "print(\"Holt-Winters Additive Seasonality:\")\n",
    "print(f\"  α (level): {fitted_hw_add.params['smoothing_level']:.4f}\")\n",
    "print(f\"  β (trend): {fitted_hw_add.params['smoothing_trend']:.4f}\")\n",
    "print(f\"  γ (seasonal): {fitted_hw_add.params['smoothing_seasonal']:.4f}\")\n",
    "print(f\"  AIC: {fitted_hw_add.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted_hw_add.bic:.2f}\")\n",
    "\n",
    "print(\"\\nHolt-Winters Multiplicative Seasonality:\")\n",
    "print(f\"  α (level): {fitted_hw_mul.params['smoothing_level']:.4f}\")\n",
    "print(f\"  β (trend): {fitted_hw_mul.params['smoothing_trend']:.4f}\")\n",
    "print(f\"  γ (seasonal): {fitted_hw_mul.params['smoothing_seasonal']:.4f}\")\n",
    "print(f\"  AIC: {fitted_hw_mul.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted_hw_mul.bic:.2f}\")\n",
    "\n",
    "print(\"\\nHolt-Winters Damped Trend + Additive Seasonality:\")\n",
    "print(f\"  α (level): {fitted_hw_damped.params['smoothing_level']:.4f}\")\n",
    "print(f\"  β (trend): {fitted_hw_damped.params['smoothing_trend']:.4f}\")\n",
    "print(f\"  γ (seasonal): {fitted_hw_damped.params['smoothing_seasonal']:.4f}\")\n",
    "print(f\"  φ (damping): {fitted_hw_damped.params['damping_trend']:.4f}\")\n",
    "print(f\"  AIC: {fitted_hw_damped.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted_hw_damped.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Holt-Winters forecasts\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Top: Forecast comparison\n",
    "axes[0].plot(train_weekly.index, train_weekly['value'], \n",
    "             label='Training Data', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(test_weekly.index, test_weekly['value'], \n",
    "             label='Test Data', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(test_weekly.index, forecast_hw_add, \n",
    "             label='Additive Seasonal', linewidth=2, linestyle='--')\n",
    "axes[0].plot(test_weekly.index, forecast_hw_mul, \n",
    "             label='Multiplicative Seasonal', linewidth=2, linestyle='--')\n",
    "axes[0].plot(test_weekly.index, forecast_hw_damped, \n",
    "             label='Damped + Additive', linewidth=2, linestyle=':')\n",
    "axes[0].set_title('Holt-Winters Method: Additive vs Multiplicative Seasonality', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom: Zoom on test period\n",
    "last_30_train = train_weekly.iloc[-30:]\n",
    "axes[1].plot(last_30_train.index, last_30_train['value'], \n",
    "             label='Training Data', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(test_weekly.index, test_weekly['value'], \n",
    "             label='Test Data', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(test_weekly.index, forecast_hw_add, \n",
    "             label='Additive Seasonal', linewidth=2, linestyle='--')\n",
    "axes[1].plot(test_weekly.index, forecast_hw_mul, \n",
    "             label='Multiplicative Seasonal', linewidth=2, linestyle='--')\n",
    "axes[1].set_title('Zoomed View: Test Period Forecasts', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and visualize Holt-Winters components\n",
    "def plot_hw_components(fitted_model, data, title):\n",
    "    \"\"\"\n",
    "    Plot decomposed components from Holt-Winters model.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 12))\n",
    "    \n",
    "    # Original series\n",
    "    axes[0].plot(data.index, data['value'], linewidth=2)\n",
    "    axes[0].set_ylabel('Original', fontsize=10)\n",
    "    axes[0].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Level\n",
    "    axes[1].plot(data.index, fitted_model.level, linewidth=2, color='green')\n",
    "    axes[1].set_ylabel('Level', fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Trend\n",
    "    axes[2].plot(data.index, fitted_model.trend, linewidth=2, color='orange')\n",
    "    axes[2].set_ylabel('Trend', fontsize=10)\n",
    "    axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Seasonal\n",
    "    axes[3].plot(data.index, fitted_model.season, linewidth=2, color='red')\n",
    "    axes[3].set_ylabel('Seasonal', fontsize=10)\n",
    "    axes[3].set_xlabel('Date', fontsize=10)\n",
    "    axes[3].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot components\n",
    "plot_hw_components(\n",
    "    fitted_hw_add, \n",
    "    train_weekly, \n",
    "    'Holt-Winters Additive: Decomposed Components'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Selection with AIC/BIC\n",
    "\n",
    "**Akaike Information Criterion (AIC)**:\n",
    "$$AIC = -2 \\log(L) + 2k$$\n",
    "\n",
    "**Bayesian Information Criterion (BIC)**:\n",
    "$$BIC = -2 \\log(L) + k \\log(n)$$\n",
    "\n",
    "Where:\n",
    "- $L$ is the likelihood\n",
    "- $k$ is the number of parameters\n",
    "- $n$ is the number of observations\n",
    "\n",
    "**Lower values indicate better models**. BIC penalizes complexity more heavily than AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different ETS models\n",
    "models_comparison = [\n",
    "    ('Simple ES', fitted_auto),\n",
    "    ('Holt Linear', fitted_linear),\n",
    "    ('Holt Damped', fitted_damped),\n",
    "    ('HW Additive', fitted_hw_add),\n",
    "    ('HW Multiplicative', fitted_hw_mul),\n",
    "    ('HW Damped', fitted_hw_damped)\n",
    "]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for name, model in models_comparison:\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'AIC': model.aic,\n",
    "        'BIC': model.bic,\n",
    "        'Parameters': len(model.params)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('AIC')\n",
    "\n",
    "print(\"\\nModel Comparison (sorted by AIC):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize model selection criteria\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# AIC comparison\n",
    "axes[0].barh(comparison_df['Model'], comparison_df['AIC'])\n",
    "axes[0].set_xlabel('AIC (lower is better)')\n",
    "axes[0].set_title('Model Comparison: AIC', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# BIC comparison\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['BIC'], color='orange')\n",
    "axes[1].set_xlabel('BIC (lower is better)')\n",
    "axes[1].set_title('Model Comparison: BIC', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. STL Decomposition (Seasonal and Trend using Loess)\n",
    "\n",
    "**STL** is a versatile and robust method for decomposing time series.\n",
    "\n",
    "### Advantages of STL\n",
    "\n",
    "1. **Handles any type of seasonality**: Not limited to additive/multiplicative\n",
    "2. **Robust to outliers**: Uses LOESS smoothing which is resistant to anomalies\n",
    "3. **Seasonal component can change over time**: More flexible than classical methods\n",
    "4. **Multiple seasonal periods**: Can model daily, weekly, yearly patterns simultaneously\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "- **seasonal**: Length of seasonal smoother (must be odd)\n",
    "  - Larger values: smoother seasonal component\n",
    "  - Smaller values: more variable seasonal pattern\n",
    "\n",
    "- **trend**: Length of trend smoother\n",
    "  - Larger values: smoother trend\n",
    "  - Recommendation: trend ≥ (1.5 × seasonal_period) / (1 - 1.5/seasonal)\n",
    "\n",
    "- **seasonal_deg**: Degree of seasonal LOESS (0 or 1)\n",
    "- **trend_deg**: Degree of trend LOESS (0 or 1)\n",
    "- **robust**: If True, uses robust weights to handle outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Single Seasonal Period STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Apply STL to weekly data\n",
    "stl_weekly = STL(\n",
    "    ts_weekly_additive['value'],\n",
    "    seasonal=7,  # Weekly seasonality\n",
    "    trend=None,  # Auto-calculate\n",
    "    robust=True  # Robust to outliers\n",
    ")\n",
    "\n",
    "result_stl_weekly = stl_weekly.fit()\n",
    "\n",
    "print(\"STL Decomposition Results:\")\n",
    "print(f\"Seasonal period: 7 days\")\n",
    "print(f\"Trend window: {stl_weekly.trend if stl_weekly.trend else 'Auto'}\")\n",
    "print(f\"\\nComponent statistics:\")\n",
    "print(f\"  Trend range: [{result_stl_weekly.trend.min():.2f}, {result_stl_weekly.trend.max():.2f}]\")\n",
    "print(f\"  Seasonal range: [{result_stl_weekly.seasonal.min():.2f}, {result_stl_weekly.seasonal.max():.2f}]\")\n",
    "print(f\"  Residual std: {result_stl_weekly.resid.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize STL decomposition\n",
    "fig = result_stl_weekly.plot()\n",
    "fig.set_size_inches(16, 10)\n",
    "fig.suptitle('STL Decomposition: Weekly Seasonality', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Strength of Seasonality and Trend\n",
    "\n",
    "**Strength of Seasonality**:\n",
    "$$F_S = \\max\\left(0, 1 - \\frac{\\text{Var}(R_t)}{\\text{Var}(S_t + R_t)}\\right)$$\n",
    "\n",
    "**Strength of Trend**:\n",
    "$$F_T = \\max\\left(0, 1 - \\frac{\\text{Var}(R_t)}{\\text{Var}(T_t + R_t)}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $S_t$ is the seasonal component\n",
    "- $T_t$ is the trend component\n",
    "- $R_t$ is the remainder\n",
    "\n",
    "**Interpretation**:\n",
    "- Values close to 0: weak component\n",
    "- Values close to 1: strong component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_strength(decomposition) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate strength of trend and seasonality from STL decomposition.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        (strength_of_trend, strength_of_seasonality)\n",
    "    \"\"\"\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    resid = decomposition.resid\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_idx = ~(np.isnan(trend) | np.isnan(seasonal) | np.isnan(resid))\n",
    "    trend = trend[valid_idx]\n",
    "    seasonal = seasonal[valid_idx]\n",
    "    resid = resid[valid_idx]\n",
    "    \n",
    "    # Calculate variances\n",
    "    var_resid = np.var(resid)\n",
    "    var_trend_resid = np.var(trend + resid)\n",
    "    var_seasonal_resid = np.var(seasonal + resid)\n",
    "    \n",
    "    # Calculate strengths\n",
    "    strength_trend = max(0, 1 - var_resid / var_trend_resid) if var_trend_resid > 0 else 0\n",
    "    strength_seasonal = max(0, 1 - var_resid / var_seasonal_resid) if var_seasonal_resid > 0 else 0\n",
    "    \n",
    "    return strength_trend, strength_seasonal\n",
    "\n",
    "# Calculate strengths\n",
    "strength_t, strength_s = calculate_strength(result_stl_weekly)\n",
    "\n",
    "print(\"Component Strength Metrics:\")\n",
    "print(f\"  Strength of Trend: {strength_t:.4f}\")\n",
    "print(f\"  Strength of Seasonality: {strength_s:.4f}\")\n",
    "\n",
    "# Visualize strengths\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "strengths = [strength_t, strength_s]\n",
    "labels = ['Trend', 'Seasonality']\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.barh(labels, strengths, color=colors)\n",
    "ax.set_xlabel('Strength (0 = weak, 1 = strong)', fontsize=12)\n",
    "ax.set_title('Strength of Time Series Components', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, strength in zip(bars, strengths):\n",
    "    ax.text(strength + 0.02, bar.get_y() + bar.get_height()/2, \n",
    "            f'{strength:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multiple Seasonal Periods with MSTL\n",
    "\n",
    "**MSTL** (Multiple Seasonal-Trend decomposition using LOESS) extends STL to handle multiple seasonal periods.\n",
    "\n",
    "**Use cases**:\n",
    "- Hourly data with daily (24) and weekly (168) seasonality\n",
    "- Daily data with weekly (7) and yearly (365) seasonality\n",
    "- Transaction data with intraday, weekly, and monthly patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import MSTL\n",
    "\n",
    "# Apply MSTL to data with multiple seasonalities\n",
    "mstl = MSTL(\n",
    "    ts_multiple['value'],\n",
    "    periods=[7, 365],  # Weekly and yearly seasonality\n",
    "    windows=[7, 365],  # Seasonal smoothing windows\n",
    "    iterate=2\n",
    ")\n",
    "\n",
    "result_mstl = mstl.fit()\n",
    "\n",
    "print(\"MSTL Decomposition Results:\")\n",
    "print(f\"Seasonal periods: {[7, 365]} (weekly, yearly)\")\n",
    "print(f\"\\nComponent statistics:\")\n",
    "print(f\"  Trend range: [{result_mstl.trend.min():.2f}, {result_mstl.trend.max():.2f}]\")\n",
    "\n",
    "# Access individual seasonal components\n",
    "seasonal_7 = result_mstl.seasonal['seasonal_7']\n",
    "seasonal_365 = result_mstl.seasonal['seasonal_365']\n",
    "\n",
    "print(f\"  Weekly seasonal range: [{seasonal_7.min():.2f}, {seasonal_7.max():.2f}]\")\n",
    "print(f\"  Yearly seasonal range: [{seasonal_365.min():.2f}, {seasonal_365.max():.2f}]\")\n",
    "print(f\"  Residual std: {result_mstl.resid.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSTL decomposition\n",
    "fig, axes = plt.subplots(5, 1, figsize=(16, 14))\n",
    "\n",
    "# Original\n",
    "axes[0].plot(ts_multiple.index, ts_multiple['value'], linewidth=1)\n",
    "axes[0].set_ylabel('Original', fontsize=10)\n",
    "axes[0].set_title('MSTL Decomposition: Multiple Seasonal Periods', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(ts_multiple.index, result_mstl.trend, linewidth=2, color='green')\n",
    "axes[1].set_ylabel('Trend', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekly seasonal\n",
    "axes[2].plot(ts_multiple.index, seasonal_7, linewidth=1, color='blue')\n",
    "axes[2].set_ylabel('Weekly\\nSeasonal', fontsize=10)\n",
    "axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Yearly seasonal\n",
    "axes[3].plot(ts_multiple.index, seasonal_365, linewidth=1, color='red')\n",
    "axes[3].set_ylabel('Yearly\\nSeasonal', fontsize=10)\n",
    "axes[3].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual\n",
    "axes[4].plot(ts_multiple.index, result_mstl.resid, linewidth=1, color='purple')\n",
    "axes[4].set_ylabel('Residual', fontsize=10)\n",
    "axes[4].set_xlabel('Date', fontsize=10)\n",
    "axes[4].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in on seasonal patterns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "# Weekly pattern (first 4 weeks)\n",
    "n_days = 28\n",
    "axes[0].plot(ts_multiple.index[:n_days], seasonal_7[:n_days], \n",
    "             marker='o', linewidth=2, markersize=6)\n",
    "axes[0].set_title('Weekly Seasonal Pattern (First 4 Weeks)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Seasonal Component')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Yearly pattern (full series)\n",
    "axes[1].plot(ts_multiple.index, seasonal_365, linewidth=2, color='red')\n",
    "axes[1].set_title('Yearly Seasonal Pattern', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Seasonal Component')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 STL for Forecasting\n",
    "\n",
    "STL can be combined with forecasting methods:\n",
    "\n",
    "1. Decompose the series using STL\n",
    "2. Forecast each component separately:\n",
    "   - Trend: Linear regression, ARIMA, etc.\n",
    "   - Seasonal: Naive seasonal forecast (repeat last period)\n",
    "3. Combine forecasts: $\\hat{y}_t = \\hat{T}_t + \\hat{S}_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.forecasting.stl import STLForecast\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# STL + ARIMA forecast\n",
    "stlf = STLForecast(\n",
    "    train_weekly['value'],\n",
    "    ARIMA,\n",
    "    model_kwargs=dict(order=(1, 1, 0)),\n",
    "    period=7\n",
    ")\n",
    "\n",
    "stlf_result = stlf.fit()\n",
    "stlf_forecast = stlf_result.forecast(steps=len(test_weekly))\n",
    "\n",
    "# Calculate forecast accuracy\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae_stlf = mean_absolute_error(test_weekly['value'], stlf_forecast)\n",
    "rmse_stlf = np.sqrt(mean_squared_error(test_weekly['value'], stlf_forecast))\n",
    "\n",
    "print(\"STL + ARIMA Forecast:\")\n",
    "print(f\"  MAE: {mae_stlf:.2f}\")\n",
    "print(f\"  RMSE: {rmse_stlf:.2f}\")\n",
    "\n",
    "# Visualize forecast\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "ax.plot(train_weekly.index, train_weekly['value'], \n",
    "        label='Training Data', linewidth=2, alpha=0.7)\n",
    "ax.plot(test_weekly.index, test_weekly['value'], \n",
    "        label='Test Data', linewidth=2, alpha=0.7)\n",
    "ax.plot(test_weekly.index, stlf_forecast, \n",
    "        label='STL + ARIMA Forecast', linewidth=2, linestyle='--')\n",
    "\n",
    "ax.set_title('STL + ARIMA Forecasting', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison: ETS vs STL vs ARIMA\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "#### Exponential Smoothing (ETS)\n",
    "**Best for:**\n",
    "- Short to medium-term forecasts\n",
    "- Data with clear trend and/or seasonality\n",
    "- When interpretability is important\n",
    "- Quick forecasts with minimal tuning\n",
    "\n",
    "**Pros:**\n",
    "- Simple and fast\n",
    "- Interpretable smoothing parameters\n",
    "- Good for stable patterns\n",
    "- Automatic parameter optimization\n",
    "\n",
    "**Cons:**\n",
    "- Limited to specific trend/seasonal patterns\n",
    "- Cannot capture complex dynamics\n",
    "- Assumes constant smoothing parameters\n",
    "\n",
    "#### STL Decomposition\n",
    "**Best for:**\n",
    "- Understanding time series structure\n",
    "- Data with multiple seasonal periods\n",
    "- Outlier detection and handling\n",
    "- When seasonal pattern changes over time\n",
    "\n",
    "**Pros:**\n",
    "- Very flexible\n",
    "- Robust to outliers\n",
    "- Handles changing seasonality\n",
    "- Multiple seasonal periods\n",
    "- Great for exploratory analysis\n",
    "\n",
    "**Cons:**\n",
    "- Requires separate forecasting method\n",
    "- More parameters to tune\n",
    "- Can be computationally intensive\n",
    "\n",
    "#### ARIMA\n",
    "**Best for:**\n",
    "- Data with autocorrelation structure\n",
    "- Non-seasonal or simple seasonal patterns\n",
    "- When you need statistical inference\n",
    "- Medium to long-term forecasts\n",
    "\n",
    "**Pros:**\n",
    "- Flexible modeling of autocorrelation\n",
    "- Statistical rigor (confidence intervals)\n",
    "- Can handle non-stationary data\n",
    "- Well-established theory\n",
    "\n",
    "**Cons:**\n",
    "- Requires stationarity\n",
    "- Model selection can be complex\n",
    "- Limited seasonality handling\n",
    "- Less interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Prepare data\n",
    "train = train_weekly['value']\n",
    "test = test_weekly['value']\n",
    "n_forecast = len(test)\n",
    "\n",
    "# Dictionary to store results\n",
    "benchmark_results = []\n",
    "\n",
    "# 1. Simple Exponential Smoothing\n",
    "start_time = time.time()\n",
    "model_ses = SimpleExpSmoothing(train)\n",
    "fit_ses = model_ses.fit()\n",
    "forecast_ses = fit_ses.forecast(steps=n_forecast)\n",
    "time_ses = time.time() - start_time\n",
    "\n",
    "benchmark_results.append({\n",
    "    'Model': 'Simple ES',\n",
    "    'MAE': mean_absolute_error(test, forecast_ses),\n",
    "    'RMSE': np.sqrt(mean_squared_error(test, forecast_ses)),\n",
    "    'MAPE': mean_absolute_percentage_error(test, forecast_ses) * 100,\n",
    "    'AIC': fit_ses.aic,\n",
    "    'BIC': fit_ses.bic,\n",
    "    'Time (s)': time_ses\n",
    "})\n",
    "\n",
    "# 2. Holt's Linear\n",
    "start_time = time.time()\n",
    "model_holt = Holt(train)\n",
    "fit_holt = model_holt.fit()\n",
    "forecast_holt = fit_holt.forecast(steps=n_forecast)\n",
    "time_holt = time.time() - start_time\n",
    "\n",
    "benchmark_results.append({\n",
    "    'Model': 'Holt Linear',\n",
    "    'MAE': mean_absolute_error(test, forecast_holt),\n",
    "    'RMSE': np.sqrt(mean_squared_error(test, forecast_holt)),\n",
    "    'MAPE': mean_absolute_percentage_error(test, forecast_holt) * 100,\n",
    "    'AIC': fit_holt.aic,\n",
    "    'BIC': fit_holt.bic,\n",
    "    'Time (s)': time_holt\n",
    "})\n",
    "\n",
    "# 3. Holt-Winters Additive\n",
    "start_time = time.time()\n",
    "model_hw = ExponentialSmoothing(train, seasonal_periods=7, trend='add', seasonal='add')\n",
    "fit_hw = model_hw.fit()\n",
    "forecast_hw = fit_hw.forecast(steps=n_forecast)\n",
    "time_hw = time.time() - start_time\n",
    "\n",
    "benchmark_results.append({\n",
    "    'Model': 'Holt-Winters',\n",
    "    'MAE': mean_absolute_error(test, forecast_hw),\n",
    "    'RMSE': np.sqrt(mean_squared_error(test, forecast_hw)),\n",
    "    'MAPE': mean_absolute_percentage_error(test, forecast_hw) * 100,\n",
    "    'AIC': fit_hw.aic,\n",
    "    'BIC': fit_hw.bic,\n",
    "    'Time (s)': time_hw\n",
    "})\n",
    "\n",
    "# 4. STL + ARIMA\n",
    "start_time = time.time()\n",
    "model_stlf = STLForecast(train, ARIMA, model_kwargs=dict(order=(1, 1, 0)), period=7)\n",
    "fit_stlf = model_stlf.fit()\n",
    "forecast_stlf = fit_stlf.forecast(steps=n_forecast)\n",
    "time_stlf = time.time() - start_time\n",
    "\n",
    "benchmark_results.append({\n",
    "    'Model': 'STL + ARIMA',\n",
    "    'MAE': mean_absolute_error(test, forecast_stlf),\n",
    "    'RMSE': np.sqrt(mean_squared_error(test, forecast_stlf)),\n",
    "    'MAPE': mean_absolute_percentage_error(test, forecast_stlf) * 100,\n",
    "    'AIC': np.nan,  # Not directly available\n",
    "    'BIC': np.nan,\n",
    "    'Time (s)': time_stlf\n",
    "})\n",
    "\n",
    "# 5. Auto ARIMA\n",
    "start_time = time.time()\n",
    "model_arima = ARIMA(train, order=(1, 1, 1), seasonal_order=(1, 0, 1, 7))\n",
    "fit_arima = model_arima.fit()\n",
    "forecast_arima = fit_arima.forecast(steps=n_forecast)\n",
    "time_arima = time.time() - start_time\n",
    "\n",
    "benchmark_results.append({\n",
    "    'Model': 'SARIMA',\n",
    "    'MAE': mean_absolute_error(test, forecast_arima),\n",
    "    'RMSE': np.sqrt(mean_squared_error(test, forecast_arima)),\n",
    "    'MAPE': mean_absolute_percentage_error(test, forecast_arima) * 100,\n",
    "    'AIC': fit_arima.aic,\n",
    "    'BIC': fit_arima.bic,\n",
    "    'Time (s)': time_arima\n",
    "})\n",
    "\n",
    "# Create DataFrame\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "benchmark_df = benchmark_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\nModel Performance Benchmark:\")\n",
    "print(\"=\" * 100)\n",
    "print(benchmark_df.to_string(index=False, float_format='%.3f'))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# MAE\n",
    "axes[0, 0].barh(benchmark_df['Model'], benchmark_df['MAE'])\n",
    "axes[0, 0].set_xlabel('MAE (lower is better)')\n",
    "axes[0, 0].set_title('Mean Absolute Error', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].barh(benchmark_df['Model'], benchmark_df['RMSE'], color='orange')\n",
    "axes[0, 1].set_xlabel('RMSE (lower is better)')\n",
    "axes[0, 1].set_title('Root Mean Squared Error', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAPE\n",
    "axes[1, 0].barh(benchmark_df['Model'], benchmark_df['MAPE'], color='green')\n",
    "axes[1, 0].set_xlabel('MAPE % (lower is better)')\n",
    "axes[1, 0].set_title('Mean Absolute Percentage Error', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Training Time\n",
    "axes[1, 1].barh(benchmark_df['Model'], benchmark_df['Time (s)'], color='red')\n",
    "axes[1, 1].set_xlabel('Training Time (seconds)')\n",
    "axes[1, 1].set_title('Computational Efficiency', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of forecasts\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot last 60 days of training data\n",
    "last_n = 60\n",
    "ax.plot(train_weekly.index[-last_n:], train_weekly['value'][-last_n:], \n",
    "        label='Training Data', linewidth=2.5, alpha=0.7, color='black')\n",
    "\n",
    "# Plot test data\n",
    "ax.plot(test_weekly.index, test_weekly['value'], \n",
    "        label='Test Data', linewidth=2.5, alpha=0.7, color='gray')\n",
    "\n",
    "# Plot forecasts\n",
    "ax.plot(test_weekly.index, forecast_ses, label='Simple ES', \n",
    "        linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.plot(test_weekly.index, forecast_holt, label='Holt Linear', \n",
    "        linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.plot(test_weekly.index, forecast_hw, label='Holt-Winters', \n",
    "        linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.plot(test_weekly.index, forecast_stlf, label='STL + ARIMA', \n",
    "        linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.plot(test_weekly.index, forecast_arima, label='SARIMA', \n",
    "        linewidth=2, linestyle='--', alpha=0.8)\n",
    "\n",
    "ax.set_title('Forecast Comparison: All Models', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract and Visualize Decomposed Components\n",
    "\n",
    "All decomposition methods provide access to individual components for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive component extraction function\n",
    "def extract_components(fitted_model, model_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract components from fitted time series models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fitted_model : fitted model object\n",
    "        Fitted time series model\n",
    "    model_type : str\n",
    "        Type of model ('ets', 'stl', 'mstl')\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with extracted components\n",
    "    \"\"\"\n",
    "    if model_type == 'ets':\n",
    "        # Holt-Winters components\n",
    "        components = pd.DataFrame({\n",
    "            'level': fitted_model.level,\n",
    "            'trend': fitted_model.trend if hasattr(fitted_model, 'trend') else np.nan,\n",
    "            'seasonal': fitted_model.season if hasattr(fitted_model, 'season') else np.nan\n",
    "        })\n",
    "    \n",
    "    elif model_type == 'stl':\n",
    "        # STL components\n",
    "        components = pd.DataFrame({\n",
    "            'trend': fitted_model.trend,\n",
    "            'seasonal': fitted_model.seasonal,\n",
    "            'residual': fitted_model.resid\n",
    "        })\n",
    "    \n",
    "    elif model_type == 'mstl':\n",
    "        # MSTL components\n",
    "        components = pd.DataFrame({\n",
    "            'trend': fitted_model.trend,\n",
    "            'residual': fitted_model.resid\n",
    "        })\n",
    "        # Add seasonal components\n",
    "        for col in fitted_model.seasonal.columns:\n",
    "            components[col] = fitted_model.seasonal[col]\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extract components from all models\n",
    "components_hw = extract_components(fitted_hw_add, 'ets')\n",
    "components_stl = extract_components(result_stl_weekly, 'stl')\n",
    "components_mstl = extract_components(result_mstl, 'mstl')\n",
    "\n",
    "print(\"Holt-Winters Components:\")\n",
    "print(components_hw.head(10))\n",
    "print(\"\\nSTL Components:\")\n",
    "print(components_stl.head(10))\n",
    "print(\"\\nMSTL Components:\")\n",
    "print(components_mstl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of components\n",
    "def component_summary(components: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate summary statistics for components.\n",
    "    \"\"\"\n",
    "    summary = components.describe().T\n",
    "    summary['var'] = components.var()\n",
    "    summary['var_pct'] = (summary['var'] / summary['var'].sum()) * 100\n",
    "    return summary\n",
    "\n",
    "print(\"\\nHolt-Winters Component Summary:\")\n",
    "print(component_summary(components_hw).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"\\nSTL Component Summary:\")\n",
    "print(component_summary(components_stl).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance decomposition\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Holt-Winters variance\n",
    "hw_var = components_hw.var()\n",
    "hw_var_clean = hw_var.dropna()\n",
    "axes[0].pie(hw_var_clean, labels=hw_var_clean.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Holt-Winters: Variance Decomposition', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "# STL variance\n",
    "stl_var = components_stl.var()\n",
    "axes[1].pie(stl_var, labels=stl_var.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('STL: Variance Decomposition', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Exponential Smoothing (ETS)\n",
    "1. **Simple ES**: Use for data with no trend or seasonality\n",
    "2. **Holt's Method**: Adds trend component to Simple ES\n",
    "3. **Holt-Winters**: Adds both trend and seasonality\n",
    "4. **Smoothing Parameters**: \n",
    "   - α (alpha): Controls level smoothing\n",
    "   - β (beta): Controls trend smoothing\n",
    "   - γ (gamma): Controls seasonal smoothing\n",
    "   - φ (phi): Damping parameter for trend\n",
    "5. **Model Selection**: Use AIC/BIC (lower is better)\n",
    "\n",
    "### STL Decomposition\n",
    "1. **Flexibility**: Handles any type of seasonality\n",
    "2. **Robustness**: Resistant to outliers when robust=True\n",
    "3. **Multiple Seasonalities**: MSTL supports multiple periods\n",
    "4. **Changing Patterns**: Seasonal component can evolve over time\n",
    "5. **Strength Metrics**: Quantify importance of trend/seasonal components\n",
    "\n",
    "### Best Practices\n",
    "1. **Always visualize** your time series first\n",
    "2. **Check stationarity** before modeling\n",
    "3. **Split data** into train/test sets\n",
    "4. **Compare multiple models** using consistent metrics\n",
    "5. **Examine residuals** to validate model assumptions\n",
    "6. **Consider computational cost** for large datasets\n",
    "7. **Use domain knowledge** to guide model selection\n",
    "\n",
    "### Model Selection Guide\n",
    "- **Quick baseline**: Simple ES or Holt's method\n",
    "- **Clear seasonality**: Holt-Winters\n",
    "- **Complex patterns**: STL + ARIMA\n",
    "- **Multiple seasonalities**: MSTL\n",
    "- **Need interpretability**: ETS methods\n",
    "- **Need flexibility**: STL/MSTL\n",
    "- **Statistical inference**: ARIMA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
