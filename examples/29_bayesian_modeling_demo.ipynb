{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aff50aa",
   "metadata": {},
   "source": [
    "# Bayesian Modeling with py-tidymodels\n",
    "\n",
    "This notebook demonstrates Bayesian modeling capabilities using PyMC integration.\n",
    "\n",
    "**Topics Covered:**\n",
    "1. Basic Bayesian linear regression\n",
    "2. Prior specification (default and custom)\n",
    "3. Prediction types (numeric, conf_int, posterior, predictive)\n",
    "4. Convergence diagnostics\n",
    "5. Comparing Bayesian vs Frequentist models\n",
    "6. Model comparison with WAIC/LOO\n",
    "7. Interpretation of credible intervals\n",
    "\n",
    "**Use Case:** Sales forecasting with uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from py_parsnip import linear_reg\n",
    "from py_workflows import workflow\n",
    "from py_recipes import recipe\n",
    "from py_yardstick import rmse, mae, r_squared\n",
    "from py_bayes import check_convergence\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5125e7",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Sales Data\n",
    "\n",
    "We'll create a realistic sales dataset with:\n",
    "- Multiple predictors (advertising, price, seasonality)\n",
    "- Non-linear relationships\n",
    "- Heteroscedastic noise (varying uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ff66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic sales data\n",
    "n = 150\n",
    "\n",
    "# Create predictors\n",
    "advertising = np.random.uniform(0, 100, n)\n",
    "price = np.random.uniform(10, 50, n)\n",
    "seasonality = np.sin(np.linspace(0, 4*np.pi, n))  # Seasonal pattern\n",
    "competition = np.random.uniform(0, 1, n)\n",
    "\n",
    "# True relationship (with interaction)\n",
    "true_sales = (\n",
    "    100 +  # Baseline\n",
    "    2.5 * advertising +  # Advertising effect\n",
    "    -1.5 * price +  # Price sensitivity\n",
    "    30 * seasonality +  # Seasonal effect\n",
    "    -20 * competition +  # Competition effect\n",
    "    0.05 * advertising * (1 - competition)  # Interaction\n",
    ")\n",
    "\n",
    "# Add heteroscedastic noise (higher variance at higher sales)\n",
    "noise_std = 5 + 0.1 * np.abs(true_sales)\n",
    "sales = true_sales + np.random.randn(n) * noise_std\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'sales': sales,\n",
    "    'advertising': advertising,\n",
    "    'price': price,\n",
    "    'seasonality': seasonality,\n",
    "    'competition': competition\n",
    "})\n",
    "\n",
    "# Split into train/test\n",
    "train_data = data.iloc[:120]\n",
    "test_data = data.iloc[120:]\n",
    "\n",
    "print(f\"Training data: {len(train_data)} observations\")\n",
    "print(f\"Test data: {len(test_data)} observations\")\n",
    "print(f\"\\nData summary:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].scatter(train_data['advertising'], train_data['sales'], alpha=0.6)\n",
    "axes[0, 0].set_xlabel('Advertising Spend')\n",
    "axes[0, 0].set_ylabel('Sales')\n",
    "axes[0, 0].set_title('Sales vs Advertising')\n",
    "\n",
    "axes[0, 1].scatter(train_data['price'], train_data['sales'], alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Price')\n",
    "axes[0, 1].set_ylabel('Sales')\n",
    "axes[0, 1].set_title('Sales vs Price')\n",
    "\n",
    "axes[1, 0].scatter(train_data['seasonality'], train_data['sales'], alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Seasonality')\n",
    "axes[1, 0].set_ylabel('Sales')\n",
    "axes[1, 0].set_title('Sales vs Seasonality')\n",
    "\n",
    "axes[1, 1].scatter(train_data['competition'], train_data['sales'], alpha=0.6)\n",
    "axes[1, 1].set_xlabel('Competition')\n",
    "axes[1, 1].set_ylabel('Sales')\n",
    "axes[1, 1].set_title('Sales vs Competition')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2c9bc",
   "metadata": {},
   "source": [
    "## 2. Basic Bayesian Linear Regression\n",
    "\n",
    "We'll start with default priors and explore the posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Bayesian model with default priors\n",
    "spec_bayes = linear_reg().set_engine(\n",
    "    \"pymc\",\n",
    "    chains=4,  # Run 4 MCMC chains\n",
    "    draws=2000,  # 2000 samples per chain\n",
    "    tune=1000  # 1000 tuning samples (discarded)\n",
    ")\n",
    "\n",
    "print(\"Fitting Bayesian model...\")\n",
    "fit_bayes = spec_bayes.fit(train_data, \"sales ~ advertising + price + seasonality + competition\")\n",
    "print(\"Bayesian model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence diagnostics\n",
    "diagnostics = check_convergence(fit_bayes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONVERGENCE DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAll chains converged: {diagnostics['converged']}\")\n",
    "print(f\"\\nRhat Summary:\")\n",
    "print(diagnostics['rhat_summary'])\n",
    "print(f\"\\nEffective Sample Size Summary:\")\n",
    "print(diagnostics['ess_summary'])\n",
    "\n",
    "if not diagnostics['converged']:\n",
    "    print(\"\\nWARNING: Chains did not converge properly!\")\n",
    "    print(\"Problematic parameters:\", diagnostics['rhat_issues'])\n",
    "else:\n",
    "    print(\"\\n✓ All chains converged successfully (Rhat < 1.01)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b018f",
   "metadata": {},
   "source": [
    "## 3. Coefficient Interpretation\n",
    "\n",
    "Extract posterior distributions for coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c26040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "outputs, coeffs, stats = fit_bayes.extract_outputs()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POSTERIOR COEFFICIENT ESTIMATES\")\n",
    "print(\"=\"*70)\n",
    "print(coeffs[['variable', 'mean', 'std', 'hdi_2.5%', 'hdi_97.5%', 'rhat', 'ess_bulk']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"- mean: Posterior mean (point estimate)\")\n",
    "print(\"- std: Posterior standard deviation (uncertainty)\")\n",
    "print(\"- hdi_2.5%, hdi_97.5%: 95% Highest Density Interval (credible interval)\")\n",
    "print(\"- rhat: Convergence diagnostic (should be < 1.01)\")\n",
    "print(\"- ess_bulk: Effective sample size (higher is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e912fc3",
   "metadata": {},
   "source": [
    "## 4. Prediction Types\n",
    "\n",
    "Bayesian models support 4 prediction types:\n",
    "1. **numeric**: Posterior mean predictions\n",
    "2. **conf_int**: 95% credible intervals\n",
    "3. **posterior**: Full posterior samples (for uncertainty analysis)\n",
    "4. **predictive**: Posterior predictive (includes observation noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Point predictions (posterior mean)\n",
    "preds_mean = fit_bayes.predict(test_data, type=\"numeric\")\n",
    "print(\"Point predictions (posterior mean):\")\n",
    "print(preds_mean.head())\n",
    "\n",
    "# 2. Credible intervals\n",
    "preds_ci = fit_bayes.predict(test_data, type=\"conf_int\")\n",
    "print(\"\\nCredible intervals (95% HDI):\")\n",
    "print(preds_ci.head())\n",
    "\n",
    "# 3. Posterior samples\n",
    "preds_posterior = fit_bayes.predict(test_data, type=\"posterior\")\n",
    "print(f\"\\nPosterior samples shape: {preds_posterior.shape}\")\n",
    "print(f\"Columns: {preds_posterior.columns.tolist()[:10]}...\")  # First 10 samples\n",
    "\n",
    "# 4. Posterior predictive (includes noise)\n",
    "preds_predictive = fit_bayes.predict(test_data, type=\"predictive\")\n",
    "print(f\"\\nPosterior predictive shape: {preds_predictive.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with uncertainty\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Actual values\n",
    "ax.scatter(range(len(test_data)), test_data['sales'].values,\n",
    "           label='Actual', color='black', s=60, zorder=3)\n",
    "\n",
    "# Posterior mean\n",
    "ax.plot(preds_mean['.pred'], label='Posterior Mean', color='blue', linewidth=2)\n",
    "\n",
    "# 95% credible interval\n",
    "ax.fill_between(\n",
    "    range(len(preds_ci)),\n",
    "    preds_ci['.pred_lower'],\n",
    "    preds_ci['.pred_upper'],\n",
    "    alpha=0.3,\n",
    "    color='blue',\n",
    "    label='95% Credible Interval'\n",
    ")\n",
    "\n",
    "# Posterior predictive interval (wider - includes noise)\n",
    "preds_pred_lower = preds_predictive.filter(like='posterior_').quantile(0.025, axis=1)\n",
    "preds_pred_upper = preds_predictive.filter(like='posterior_').quantile(0.975, axis=1)\n",
    "ax.fill_between(\n",
    "    range(len(test_data)),\n",
    "    preds_pred_lower,\n",
    "    preds_pred_upper,\n",
    "    alpha=0.2,\n",
    "    color='red',\n",
    "    label='95% Predictive Interval'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Test Observation')\n",
    "ax.set_ylabel('Sales')\n",
    "ax.set_title('Bayesian Predictions with Uncertainty')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Blue band: Parameter uncertainty (we're uncertain about coefficients)\")\n",
    "print(\"- Red band: Total uncertainty (parameter + observation noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98a769",
   "metadata": {},
   "source": [
    "## 5. Custom Priors\n",
    "\n",
    "Specify custom priors based on domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with custom priors\n",
    "spec_custom = linear_reg().set_engine(\n",
    "    \"pymc\",\n",
    "    prior_intercept=\"normal(100, 50)\",  # Expect baseline sales around 100\n",
    "    prior_coefs=\"normal(0, 10)\",  # Weakly informative\n",
    "    prior_sigma=\"half_cauchy(10)\",  # Heavy-tailed prior for noise\n",
    "    chains=4,\n",
    "    draws=2000\n",
    ")\n",
    "\n",
    "print(\"Fitting model with custom priors...\")\n",
    "fit_custom = spec_custom.fit(train_data, \"sales ~ advertising + price + seasonality + competition\")\n",
    "print(\"Custom prior model fitted!\")\n",
    "\n",
    "# Extract coefficients\n",
    "_, coeffs_custom, _ = fit_custom.extract_outputs()\n",
    "\n",
    "print(\"\\nCoefficients with custom priors:\")\n",
    "print(coeffs_custom[['variable', 'mean', 'std', 'hdi_2.5%', 'hdi_97.5%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f6dac",
   "metadata": {},
   "source": [
    "## 6. Bayesian vs Frequentist Comparison\n",
    "\n",
    "Compare Bayesian and frequentist (OLS) approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit frequentist model\n",
    "spec_ols = linear_reg()  # Default engine is sklearn\n",
    "fit_ols = spec_ols.fit(train_data, \"sales ~ advertising + price + seasonality + competition\")\n",
    "\n",
    "# Get coefficients\n",
    "_, coeffs_ols, _ = fit_ols.extract_outputs()\n",
    "\n",
    "# Compare coefficients\n",
    "comparison = pd.DataFrame({\n",
    "    'Variable': coeffs_ols['variable'],\n",
    "    'OLS_Estimate': coeffs_ols['estimate'],\n",
    "    'OLS_Std_Error': coeffs_ols['std_error'],\n",
    "    'Bayes_Mean': coeffs['mean'],\n",
    "    'Bayes_Std': coeffs['std'],\n",
    "    'Bayes_CI_Lower': coeffs['hdi_2.5%'],\n",
    "    'Bayes_CI_Upper': coeffs['hdi_97.5%']\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BAYESIAN VS FREQUENTIST COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY DIFFERENCES\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Estimates: Both methods produce similar point estimates\")\n",
    "print(\"2. Uncertainty: Bayesian provides full posterior, OLS gives asymptotic SE\")\n",
    "print(\"3. Interpretation: Bayesian CI is probability-based, OLS CI is frequentist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions\n",
    "preds_ols = fit_ols.predict(test_data)\n",
    "preds_bayes = fit_bayes.predict(test_data, type=\"numeric\")\n",
    "\n",
    "# Calculate metrics\n",
    "rmse_ols = rmse(test_data['sales'], preds_ols['.pred']).iloc[0]['value']\n",
    "rmse_bayes = rmse(test_data['sales'], preds_bayes['.pred']).iloc[0]['value']\n",
    "\n",
    "mae_ols = mae(test_data['sales'], preds_ols['.pred']).iloc[0]['value']\n",
    "mae_bayes = mae(test_data['sales'], preds_bayes['.pred']).iloc[0]['value']\n",
    "\n",
    "r2_ols = r_squared(test_data['sales'], preds_ols['.pred']).iloc[0]['value']\n",
    "r2_bayes = r_squared(test_data['sales'], preds_bayes['.pred']).iloc[0]['value']\n",
    "\n",
    "print(\"\\nPrediction Performance:\")\n",
    "print(f\"{'Metric':<10} {'OLS':<12} {'Bayesian':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'RMSE':<10} {rmse_ols:<12.4f} {rmse_bayes:<12.4f} {rmse_bayes - rmse_ols:<12.4f}\")\n",
    "print(f\"{'MAE':<10} {mae_ols:<12.4f} {mae_bayes:<12.4f} {mae_bayes - mae_ols:<12.4f}\")\n",
    "print(f\"{'R²':<10} {r2_ols:<12.4f} {r2_bayes:<12.4f} {r2_bayes - r2_ols:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78dfda",
   "metadata": {},
   "source": [
    "## 7. Model Diagnostics\n",
    "\n",
    "Examine model fit quality and assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract diagnostics\n",
    "outputs_bayes, _, stats_bayes = fit_bayes.extract_outputs()\n",
    "\n",
    "# Plot residuals\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals vs fitted\n",
    "axes[0].scatter(outputs_bayes['fitted'], outputs_bayes['residuals'], alpha=0.6)\n",
    "axes[0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0].set_xlabel('Fitted Values')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Residuals vs Fitted')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats as sp_stats\n",
    "sp_stats.probplot(outputs_bayes['residuals'], dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print model statistics\n",
    "print(\"\\nModel Statistics:\")\n",
    "print(stats_bayes[['split', 'rmse', 'mae', 'r_squared', 'n']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837379c1",
   "metadata": {},
   "source": [
    "## 8. Uncertainty Quantification\n",
    "\n",
    "Analyze prediction uncertainty for individual observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41817ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get posterior predictive samples for test data\n",
    "preds_predictive = fit_bayes.predict(test_data, type=\"predictive\")\n",
    "\n",
    "# Extract sample columns\n",
    "sample_cols = [col for col in preds_predictive.columns if col.startswith('posterior_')]\n",
    "\n",
    "# Calculate prediction intervals for each observation\n",
    "pred_means = preds_predictive[sample_cols].mean(axis=1)\n",
    "pred_stds = preds_predictive[sample_cols].std(axis=1)\n",
    "pred_lower = preds_predictive[sample_cols].quantile(0.025, axis=1)\n",
    "pred_upper = preds_predictive[sample_cols].quantile(0.975, axis=1)\n",
    "\n",
    "# Create uncertainty summary\n",
    "uncertainty_summary = pd.DataFrame({\n",
    "    'Actual': test_data['sales'].values,\n",
    "    'Pred_Mean': pred_means,\n",
    "    'Pred_Std': pred_stds,\n",
    "    'CI_Lower': pred_lower,\n",
    "    'CI_Upper': pred_upper,\n",
    "    'CI_Width': pred_upper - pred_lower,\n",
    "    'In_Interval': (test_data['sales'].values >= pred_lower) & (test_data['sales'].values <= pred_upper)\n",
    "})\n",
    "\n",
    "print(\"\\nPrediction Uncertainty Summary:\")\n",
    "print(uncertainty_summary.head(10))\n",
    "\n",
    "print(f\"\\nCoverage: {uncertainty_summary['In_Interval'].mean():.1%} of actuals fall within 95% CI\")\n",
    "print(f\"Expected: 95%\")\n",
    "print(f\"\\nMean CI width: {uncertainty_summary['CI_Width'].mean():.2f}\")\n",
    "print(f\"Min CI width: {uncertainty_summary['CI_Width'].min():.2f}\")\n",
    "print(f\"Max CI width: {uncertainty_summary['CI_Width'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a287ce6",
   "metadata": {},
   "source": [
    "## 9. Summary and Best Practices\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Bayesian Advantages:**\n",
    "   - Full uncertainty quantification\n",
    "   - Credible intervals have probability interpretation\n",
    "   - Can incorporate prior knowledge\n",
    "   - Natural handling of small samples\n",
    "\n",
    "2. **When to Use Bayesian:**\n",
    "   - Need uncertainty quantification\n",
    "   - Small sample sizes\n",
    "   - Have informative priors\n",
    "   - Decision-making under uncertainty\n",
    "\n",
    "3. **Best Practices:**\n",
    "   - Always check convergence (Rhat < 1.01)\n",
    "   - Verify ESS is sufficient (>400)\n",
    "   - Use informative priors when available\n",
    "   - Compare with frequentist methods\n",
    "   - Validate coverage on test data\n",
    "\n",
    "4. **Prior Selection:**\n",
    "   - Default priors: Weakly informative, good starting point\n",
    "   - Custom priors: Use domain knowledge\n",
    "   - Prior predictive checks: Verify priors are reasonable\n",
    "\n",
    "5. **Computational:**\n",
    "   - Multiple chains (4+) for convergence diagnosis\n",
    "   - Sufficient samples (2000+)\n",
    "   - Tune phase to adapt sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Point predictions comparison\n",
    "axes[0].scatter(preds_ols['.pred'], test_data['sales'].values, alpha=0.6, label='OLS')\n",
    "axes[0].scatter(preds_bayes['.pred'], test_data['sales'].values, alpha=0.6, label='Bayesian')\n",
    "axes[0].plot([test_data['sales'].min(), test_data['sales'].max()],\n",
    "            [test_data['sales'].min(), test_data['sales'].max()],\n",
    "            'k--', label='Perfect')\n",
    "axes[0].set_xlabel('Predicted Sales')\n",
    "axes[0].set_ylabel('Actual Sales')\n",
    "axes[0].set_title('Predictions: OLS vs Bayesian')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Uncertainty quantification (Bayesian only)\n",
    "sorted_idx = np.argsort(pred_means)\n",
    "x_pos = np.arange(len(sorted_idx))\n",
    "axes[1].errorbar(\n",
    "    x_pos,\n",
    "    pred_means[sorted_idx],\n",
    "    yerr=1.96*pred_stds[sorted_idx],\n",
    "    fmt='o',\n",
    "    alpha=0.6,\n",
    "    label='Posterior Mean ± 1.96σ'\n",
    ")\n",
    "axes[1].scatter(x_pos, test_data['sales'].values[sorted_idx],\n",
    "               color='red', marker='x', s=100, label='Actual', zorder=3)\n",
    "axes[1].set_xlabel('Observation (sorted by prediction)')\n",
    "axes[1].set_ylabel('Sales')\n",
    "axes[1].set_title('Bayesian Prediction Uncertainty')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Bayesian modeling provides full uncertainty quantification!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
