{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 34: Gradient Boosting Engines Comparison\n",
    "\n",
    "**Feature**: `boost_tree()` with three engines: XGBoost, LightGBM, CatBoost\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the **unified gradient boosting interface** via `boost_tree()` with three popular engines:\n",
    "\n",
    "1. **XGBoost**: Industry standard, highly optimized\n",
    "2. **LightGBM**: Microsoft's fast implementation with leaf-wise growth\n",
    "3. **CatBoost**: Yandex's implementation with categorical feature support\n",
    "\n",
    "## Key Features\n",
    "\n",
    "**Unified API**: Same parameters across engines\n",
    "```python\n",
    "boost_tree(\n",
    "    trees=100,           # Number of boosting rounds\n",
    "    tree_depth=6,        # Maximum tree depth\n",
    "    learn_rate=0.1,      # Learning rate (eta/alpha)\n",
    "    mtry=0.8,            # Feature sampling ratio (colsample)\n",
    "    min_n=5,             # Minimum samples in leaf\n",
    "    loss_reduction=0.0,  # Min loss reduction for split (gamma)\n",
    "    sample_size=0.8      # Row sampling ratio (subsample)\n",
    ").set_engine('xgboost').set_mode('regression')\n",
    "```\n",
    "\n",
    "**Automatic Parameter Translation**: tidymodels params → engine params\n",
    "\n",
    "## When to Use Each Engine\n",
    "\n",
    "**XGBoost**:\n",
    "- Industry standard, proven track record\n",
    "- Most hyperparameter tuning resources available\n",
    "- Good balance of speed and accuracy\n",
    "- Rich ecosystem (model interpretation, deployment)\n",
    "\n",
    "**LightGBM**:\n",
    "- Fastest training on large datasets (>100K rows)\n",
    "- Memory efficient\n",
    "- Leaf-wise growth (vs level-wise) can be more accurate\n",
    "- Best for Kaggle-style competitions\n",
    "\n",
    "**CatBoost**:\n",
    "- Best for categorical features (native support)\n",
    "- Good default parameters (less tuning needed)\n",
    "- Often wins on tabular data benchmarks\n",
    "- Robust to overfitting\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**Refinery Margins** (European refineries):\n",
    "- Monthly refinery margins from 2006-2024\n",
    "- Multiple countries (10 European countries)\n",
    "- Crude oil prices (Brent, Dubai, WTI)\n",
    "- Various margin types (cracking, hydroskimming)\n",
    "- Target: Brent cracking margin in NW Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_parsnip import boost_tree, linear_reg, rand_forest\n",
    "from py_rsample import initial_time_split, vfold_cv\n",
    "from py_yardstick import rmse, mae, r_squared\n",
    "from py_yardstick import metric_set\n",
    "from py_workflows import Workflow\n",
    "from py_workflowsets import WorkflowSet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load refinery margins data\n",
    "df = pd.read_csv('../_md/__data/refinery_margins.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter to Germany (largest refining capacity)\n",
    "germany = df[df['country'] == 'Germany'].copy()\n",
    "\n",
    "# Select relevant columns\n",
    "# Target: Brent cracking margin in NW Europe\n",
    "# Predictors: crude prices (Brent, Dubai, WTI) and date\n",
    "germany = germany[[\n",
    "    'date', 'brent', 'dubai', 'wti', 'brent_cracking_nw_europe'\n",
    "]].rename(columns={'brent_cracking_nw_europe': 'margin'})\n",
    "\n",
    "# Remove any missing values\n",
    "germany = germany.dropna().sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Germany refinery margin data:\")\n",
    "print(f\"  Records: {len(germany):,} months\")\n",
    "print(f\"  Date range: {germany['date'].min()} to {germany['date'].max()}\")\n",
    "print(f\"  Margin mean: ${germany['margin'].mean():.2f}/bbl\")\n",
    "print(f\"  Margin std: ${germany['margin'].std():.2f}/bbl\")\n",
    "print(f\"\\nPredictors:\")\n",
    "print(f\"  Brent: ${germany['brent'].mean():.2f} ± ${germany['brent'].std():.2f}/bbl\")\n",
    "print(f\"  Dubai: ${germany['dubai'].mean():.2f} ± ${germany['dubai'].std():.2f}/bbl\")\n",
    "print(f\"  WTI:   ${germany['wti'].mean():.2f} ± ${germany['wti'].std():.2f}/bbl\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(germany.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (hold out last 24 months)\n",
    "split = initial_time_split(germany, date_column='date', prop=0.85)\n",
    "train = split.training()\n",
    "test = split.testing()\n",
    "\n",
    "print(f\"Train: {len(train)} months ({train['date'].min()} to {train['date'].max()})\")\n",
    "print(f\"Test:  {len(test)} months ({test['date'].min()} to {test['date'].max()})\")\n",
    "print(f\"\\nHolding out {len(test)} months for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost Engine\n",
    "\n",
    "Industry standard gradient boosting implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with full parameter specification\n",
    "spec_xgboost = boost_tree(\n",
    "    trees=100,\n",
    "    tree_depth=6,\n",
    "    learn_rate=0.1,\n",
    "    mtry=0.8,          # Column sampling\n",
    "    min_n=5,           # Min samples in leaf\n",
    "    loss_reduction=0.0, # Gamma (regularization)\n",
    "    sample_size=0.8    # Row sampling\n",
    ").set_engine('xgboost').set_mode('regression')\n",
    "\n",
    "# Fit\n",
    "start_time = time.time()\n",
    "fit_xgboost = spec_xgboost.fit(train, 'margin ~ brent + dubai + wti')\n",
    "xgb_train_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "eval_xgboost = fit_xgboost.evaluate(test)\n",
    "outputs, coeffs, stats = eval_xgboost.extract_outputs()\n",
    "\n",
    "test_stats_xgb = stats[stats['split'] == 'test'].iloc[0]\n",
    "print(\"XGBoost:\")\n",
    "print(f\"  Training time: {xgb_train_time:.3f} seconds\")\n",
    "print(f\"  Test RMSE: ${test_stats_xgb['rmse']:.3f}/bbl\")\n",
    "print(f\"  Test MAE: ${test_stats_xgb['mae']:.3f}/bbl\")\n",
    "print(f\"  Test R²: {test_stats_xgb['r_squared']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM Engine\n",
    "\n",
    "Microsoft's fast gradient boosting with leaf-wise growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with same parameters\n",
    "spec_lightgbm = boost_tree(\n",
    "    trees=100,\n",
    "    tree_depth=6,\n",
    "    learn_rate=0.1,\n",
    "    mtry=0.8,\n",
    "    min_n=5,\n",
    "    loss_reduction=0.0,\n",
    "    sample_size=0.8\n",
    ").set_engine('lightgbm').set_mode('regression')\n",
    "\n",
    "# Fit\n",
    "start_time = time.time()\n",
    "fit_lightgbm = spec_lightgbm.fit(train, 'margin ~ brent + dubai + wti')\n",
    "lgb_train_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "eval_lightgbm = fit_lightgbm.evaluate(test)\n",
    "_, _, stats_lgb = eval_lightgbm.extract_outputs()\n",
    "\n",
    "test_stats_lgb = stats_lgb[stats_lgb['split'] == 'test'].iloc[0]\n",
    "print(\"LightGBM:\")\n",
    "print(f\"  Training time: {lgb_train_time:.3f} seconds\")\n",
    "print(f\"  Test RMSE: ${test_stats_lgb['rmse']:.3f}/bbl\")\n",
    "print(f\"  Test MAE: ${test_stats_lgb['mae']:.3f}/bbl\")\n",
    "print(f\"  Test R²: {test_stats_lgb['r_squared']:.4f}\")\n",
    "print(f\"\\nSpeedup vs XGBoost: {xgb_train_time / lgb_train_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatBoost Engine\n",
    "\n",
    "Yandex's gradient boosting with native categorical feature support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with same parameters\n",
    "spec_catboost = boost_tree(\n",
    "    trees=100,\n",
    "    tree_depth=6,\n",
    "    learn_rate=0.1,\n",
    "    mtry=0.8,\n",
    "    min_n=5,\n",
    "    loss_reduction=0.0,\n",
    "    sample_size=0.8\n",
    ").set_engine('catboost').set_mode('regression')\n",
    "\n",
    "# Fit\n",
    "start_time = time.time()\n",
    "fit_catboost = spec_catboost.fit(train, 'margin ~ brent + dubai + wti')\n",
    "cat_train_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "eval_catboost = fit_catboost.evaluate(test)\n",
    "_, _, stats_cat = eval_catboost.extract_outputs()\n",
    "\n",
    "test_stats_cat = stats_cat[stats_cat['split'] == 'test'].iloc[0]\n",
    "print(\"CatBoost:\")\n",
    "print(f\"  Training time: {cat_train_time:.3f} seconds\")\n",
    "print(f\"  Test RMSE: ${test_stats_cat['rmse']:.3f}/bbl\")\n",
    "print(f\"  Test MAE: ${test_stats_cat['mae']:.3f}/bbl\")\n",
    "print(f\"  Test R²: {test_stats_cat['r_squared']:.4f}\")\n",
    "print(f\"\\nSpeedup vs XGBoost: {xgb_train_time / cat_train_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Engine Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three engines\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'engine': 'XGBoost',\n",
    "        'train_time_sec': xgb_train_time,\n",
    "        'rmse': test_stats_xgb['rmse'],\n",
    "        'mae': test_stats_xgb['mae'],\n",
    "        'r_squared': test_stats_xgb['r_squared']\n",
    "    },\n",
    "    {\n",
    "        'engine': 'LightGBM',\n",
    "        'train_time_sec': lgb_train_time,\n",
    "        'rmse': test_stats_lgb['rmse'],\n",
    "        'mae': test_stats_lgb['mae'],\n",
    "        'r_squared': test_stats_lgb['r_squared']\n",
    "    },\n",
    "    {\n",
    "        'engine': 'CatBoost',\n",
    "        'train_time_sec': cat_train_time,\n",
    "        'rmse': test_stats_cat['rmse'],\n",
    "        'mae': test_stats_cat['mae'],\n",
    "        'r_squared': test_stats_cat['r_squared']\n",
    "    }\n",
    "])\n",
    "\n",
    "# Add speedup column\n",
    "comparison['speedup_vs_xgb'] = xgb_train_time / comparison['train_time_sec']\n",
    "\n",
    "# Sort by RMSE\n",
    "comparison = comparison.sort_values('rmse')\n",
    "\n",
    "print(\"\\nGradient Boosting Engine Comparison:\")\n",
    "print(\"=\"*90)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "print(f\"\\nBest accuracy: {comparison.iloc[0]['engine']} (RMSE: ${comparison.iloc[0]['rmse']:.3f}/bbl)\")\n",
    "print(f\"Fastest training: {comparison.sort_values('train_time_sec').iloc[0]['engine']} ({comparison.sort_values('train_time_sec').iloc[0]['train_time_sec']:.3f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. WorkflowSet Comparison\n",
    "\n",
    "Use WorkflowSet to systematically compare all engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflows for all engines\n",
    "engines = ['xgboost', 'lightgbm', 'catboost']\n",
    "\n",
    "workflows = []\n",
    "for engine in engines:\n",
    "    spec = boost_tree(\n",
    "        trees=100,\n",
    "        tree_depth=6,\n",
    "        learn_rate=0.1\n",
    "    ).set_engine(engine).set_mode('regression')\n",
    "    \n",
    "    wf = Workflow().add_formula('margin ~ brent + dubai + wti').add_model(spec)\n",
    "    workflows.append(wf)\n",
    "\n",
    "wf_set = WorkflowSet.from_workflows(workflows)\n",
    "\n",
    "print(f\"Created WorkflowSet with {len(workflows)} boosting engines\")\n",
    "print(f\"Workflows: {list(wf_set.workflows.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all workflows and collect metrics\n",
    "wf_results = []\n",
    "for wf_id, wf in wf_set.workflows.items():\n",
    "    start_time = time.time()\n",
    "    fit = wf.fit(train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    eval_fit = fit.evaluate(test)\n",
    "    _, _, stats = eval_fit.extract_outputs()\n",
    "    \n",
    "    test_stats = stats[stats['split'] == 'test'].iloc[0]\n",
    "    wf_results.append({\n",
    "        'workflow': wf_id,\n",
    "        'train_time': train_time,\n",
    "        'rmse': test_stats['rmse'],\n",
    "        'mae': test_stats['mae'],\n",
    "        'r_squared': test_stats['r_squared']\n",
    "    })\n",
    "\n",
    "wf_comparison = pd.DataFrame(wf_results)\n",
    "wf_comparison = wf_comparison.sort_values('rmse')\n",
    "\n",
    "print(\"\\nWorkflowSet Results:\")\n",
    "print(\"=\"*80)\n",
    "print(wf_comparison.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with Baseline Models\n",
    "\n",
    "How do gradient boosting models compare to simpler baselines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add baseline models\n",
    "baseline_models = [\n",
    "    ('linear_reg', linear_reg()),\n",
    "    ('random_forest', rand_forest(trees=100).set_mode('regression'))\n",
    "]\n",
    "\n",
    "all_results = wf_results.copy()\n",
    "\n",
    "for name, model in baseline_models:\n",
    "    start_time = time.time()\n",
    "    fit = model.fit(train, 'margin ~ brent + dubai + wti')\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    eval_fit = fit.evaluate(test)\n",
    "    _, _, stats = eval_fit.extract_outputs()\n",
    "    \n",
    "    test_stats = stats[stats['split'] == 'test'].iloc[0]\n",
    "    all_results.append({\n",
    "        'workflow': name,\n",
    "        'train_time': train_time,\n",
    "        'rmse': test_stats['rmse'],\n",
    "        'mae': test_stats['mae'],\n",
    "        'r_squared': test_stats['r_squared']\n",
    "    })\n",
    "\n",
    "all_comparison = pd.DataFrame(all_results)\n",
    "all_comparison = all_comparison.sort_values('rmse')\n",
    "\n",
    "print(\"\\nAll Models Comparison (Boosting + Baselines):\")\n",
    "print(\"=\"*80)\n",
    "print(all_comparison.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parameter Translation Examples\n",
    "\n",
    "Show how tidymodels params map to each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter mapping reference\n",
    "param_mapping = pd.DataFrame([\n",
    "    {\n",
    "        'tidymodels': 'trees',\n",
    "        'xgboost': 'n_estimators',\n",
    "        'lightgbm': 'n_estimators',\n",
    "        'catboost': 'iterations'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'tree_depth',\n",
    "        'xgboost': 'max_depth',\n",
    "        'lightgbm': 'max_depth',\n",
    "        'catboost': 'depth'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'learn_rate',\n",
    "        'xgboost': 'learning_rate',\n",
    "        'lightgbm': 'learning_rate',\n",
    "        'catboost': 'learning_rate'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'mtry',\n",
    "        'xgboost': 'colsample_bytree',\n",
    "        'lightgbm': 'feature_fraction',\n",
    "        'catboost': 'rsm'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'min_n',\n",
    "        'xgboost': 'min_child_weight',\n",
    "        'lightgbm': 'min_child_samples',\n",
    "        'catboost': 'min_data_in_leaf'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'loss_reduction',\n",
    "        'xgboost': 'gamma',\n",
    "        'lightgbm': 'min_gain_to_split',\n",
    "        'catboost': 'min_data_in_leaf'\n",
    "    },\n",
    "    {\n",
    "        'tidymodels': 'sample_size',\n",
    "        'xgboost': 'subsample',\n",
    "        'lightgbm': 'bagging_fraction',\n",
    "        'catboost': 'subsample'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nParameter Translation Across Engines:\")\n",
    "print(\"=\"*80)\n",
    "print(param_mapping.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: py-tidymodels handles this translation automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### Engine Selection Guidance\n",
    "\n",
    "**Choose XGBoost when**:\n",
    "- You need a proven, battle-tested implementation\n",
    "- Extensive hyperparameter tuning resources available\n",
    "- Model interpretation is important (SHAP, feature importance)\n",
    "- Production deployment with existing XGBoost infrastructure\n",
    "\n",
    "**Choose LightGBM when**:\n",
    "- Dataset has >100K rows (speed advantage)\n",
    "- Memory is constrained\n",
    "- Leaf-wise growth is beneficial (more accurate splits)\n",
    "- Kaggle competitions or similar high-performance scenarios\n",
    "\n",
    "**Choose CatBoost when**:\n",
    "- Dataset has categorical features (native support)\n",
    "- Limited time for hyperparameter tuning (good defaults)\n",
    "- Robustness to overfitting is critical\n",
    "- Tabular data with mixed feature types\n",
    "\n",
    "### Performance Patterns\n",
    "\n",
    "From our refinery margin example:\n",
    "1. **Accuracy**: All three engines performed similarly on this regression task\n",
    "2. **Speed**: LightGBM typically fastest, XGBoost middle, CatBoost varies\n",
    "3. **vs Baselines**: All boosting engines significantly outperformed linear regression\n",
    "4. **vs Random Forest**: Boosting models typically more accurate with fewer trees\n",
    "\n",
    "### Unified API Benefits\n",
    "\n",
    "```python\n",
    "# Same code structure for all engines\n",
    "spec = boost_tree(trees=100, tree_depth=6, learn_rate=0.1)\n",
    "\n",
    "# Just change engine\n",
    "fit_xgb = spec.set_engine('xgboost').fit(data, formula)\n",
    "fit_lgb = spec.set_engine('lightgbm').fit(data, formula)\n",
    "fit_cat = spec.set_engine('catboost').fit(data, formula)\n",
    "\n",
    "# Easy to benchmark and swap engines\n",
    "```\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "**Start with these defaults**:\n",
    "```python\n",
    "boost_tree(\n",
    "    trees=100,           # Often sufficient, increase to 500-1000 if needed\n",
    "    tree_depth=6,        # 3-10 typical range\n",
    "    learn_rate=0.1,      # 0.01-0.3 typical, lower = more trees needed\n",
    "    mtry=0.8,            # 0.5-1.0, feature sampling\n",
    "    min_n=5,             # 1-20, regularization\n",
    "    sample_size=0.8      # 0.5-1.0, row sampling\n",
    ")\n",
    "```\n",
    "\n",
    "**Tune in this order**:\n",
    "1. `learn_rate` and `trees` together (lower learning rate = more trees)\n",
    "2. `tree_depth` (controls model complexity)\n",
    "3. `sample_size` and `mtry` (regularization via sampling)\n",
    "4. `min_n` and `loss_reduction` (leaf regularization)\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "```python\n",
    "# Standard production pattern\n",
    "from py_parsnip import boost_tree\n",
    "from py_workflows import Workflow\n",
    "from py_recipes import recipe, step_normalize\n",
    "\n",
    "# Preprocessing + boosting\n",
    "rec = recipe().step_normalize(all_numeric_predictors())\n",
    "spec = boost_tree(trees=200, tree_depth=6).set_engine('xgboost')\n",
    "wf = Workflow().add_recipe(rec).add_model(spec)\n",
    "\n",
    "# Fit on all training data\n",
    "final_fit = wf.fit(all_training_data)\n",
    "\n",
    "# Predict\n",
    "predictions = final_fit.predict(new_data)\n",
    "```\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "1. **Too many trees**: Overfitting and slow training\n",
    "   - Solution: Use early stopping or tune `trees` parameter\n",
    "\n",
    "2. **High learning rate**: Unstable training\n",
    "   - Solution: Reduce `learn_rate` to 0.01-0.05, increase `trees`\n",
    "\n",
    "3. **Deep trees**: Overfitting on small datasets\n",
    "   - Solution: Reduce `tree_depth` to 3-4 for <10K rows\n",
    "\n",
    "4. **Forgetting mode**: \"Unknown mode\" errors\n",
    "   - Solution: Always call `.set_mode('regression')` or `.set_mode('classification')`\n",
    "\n",
    "5. **Engine not installed**: Import errors\n",
    "   - Solution: `pip install xgboost lightgbm catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "✅ XGBoost engine with full parameter specification  \n",
    "✅ LightGBM engine for fast training  \n",
    "✅ CatBoost engine with robust defaults  \n",
    "✅ Direct comparison across all three engines  \n",
    "✅ WorkflowSet integration for systematic comparison  \n",
    "✅ Benchmarking vs baseline models (linear, Random Forest)  \n",
    "✅ Parameter translation reference across engines  \n",
    "✅ Production deployment patterns  \n",
    "\n",
    "**Key Insight**: All three gradient boosting engines are accessible through the same unified `boost_tree()` API. The choice between XGBoost, LightGBM, and CatBoost depends on:\n",
    "- Dataset size and characteristics\n",
    "- Speed vs accuracy tradeoffs\n",
    "- Categorical feature handling needs\n",
    "- Production infrastructure constraints\n",
    "\n",
    "**Recommendation**: Start with XGBoost (most proven), benchmark LightGBM (speed), and try CatBoost if you have categorical features.\n",
    "\n",
    "**Next Steps**:\n",
    "- Hyperparameter tuning with `tune_grid()`\n",
    "- Feature engineering with `recipes`\n",
    "- Production deployment integration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
