{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Demo\n",
    "\n",
    "This notebook demonstrates time series forecasting using multiple model types:\n",
    "- **Prophet**: Native time series model with trend and seasonality\n",
    "- **ARIMA**: Classical time series model\n",
    "- **Random Forest**: ML model with lag features for time series\n",
    "- **Linear Regression**: Simple baseline with time features\n",
    "\n",
    "## Key Concepts:\n",
    "1. **Native time series models** (Prophet, ARIMA): Handle dates directly\n",
    "2. **ML models** (Random Forest, Linear Reg): Require feature engineering (lags, rolling stats)\n",
    "3. **Comprehensive outputs**: All models return standardized three-DataFrame structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from py_parsnip import prophet_reg, arima_reg, rand_forest, linear_reg\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Time Series Data\n",
    "\n",
    "We'll create daily sales data with:\n",
    "- Trend (increasing over time)\n",
    "- Weekly seasonality\n",
    "- Random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 years of daily data\n",
    "n_days = 730\n",
    "start_date = datetime(2022, 1, 1)\n",
    "\n",
    "dates = [start_date + timedelta(days=i) for i in range(n_days)]\n",
    "\n",
    "# Create time series components\n",
    "trend = np.linspace(100, 150, n_days)\n",
    "seasonality = 20 * np.sin(2 * np.pi * np.arange(n_days) / 7)  # Weekly pattern\n",
    "noise = np.random.normal(0, 5, n_days)\n",
    "\n",
    "sales = trend + seasonality + noise\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': sales\n",
    "})\n",
    "\n",
    "print(data.head(10))\n",
    "print(f\"\\nData shape: {data.shape}\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split for Time Series\n",
    "\n",
    "**Important**: For time series, we split chronologically (not randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: Train on first 600 days, test on last 130 days\n",
    "train = data.iloc[:600].copy()\n",
    "test = data.iloc[600:].copy()\n",
    "\n",
    "print(f\"Train: {train.shape[0]} days ({train['date'].min()} to {train['date'].max()})\")\n",
    "print(f\"Test: {test.shape[0]} days ({test['date'].min()} to {test['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 1: Prophet (Native Time Series)\n",
    "\n",
    "Prophet handles dates natively and automatically detects trend + seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create Prophet specification\n# Prophet will automatically detect weekly seasonality in our data\nspec_prophet = prophet_reg(\n    n_changepoints=25,  # Number of potential trend changes\n    changepoint_prior_scale=0.05,  # Flexibility of trend\n    seasonality_prior_scale=10.0   # Flexibility of seasonality\n)\n\nprint(spec_prophet)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Prophet\n",
    "fit_prophet = spec_prophet.fit(train, \"sales ~ date\")\n",
    "print(\"Prophet model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pred_prophet = fit_prophet.predict(test)\n",
    "print(pred_prophet.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and extract outputs\n",
    "fit_prophet = fit_prophet.evaluate(test)\n",
    "outputs_prophet, coefs_prophet, stats_prophet = fit_prophet.extract_outputs()\n",
    "\n",
    "print(\"Prophet OUTPUTS:\")\n",
    "print(outputs_prophet[outputs_prophet['split'] == 'test'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test metrics\n",
    "prophet_test_metrics = stats_prophet[\n",
    "    (stats_prophet['split'] == 'test') & \n",
    "    (stats_prophet['metric'].isin(['rmse', 'mae', 'mape', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"\\nProphet Test Metrics:\")\n",
    "print(prophet_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 2: ARIMA (Classical Time Series)\n",
    "\n",
    "ARIMA models the autocorrelation structure of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ARIMA specification\n",
    "spec_arima = arima_reg(\n",
    "    seasonal_period=7,  # Weekly seasonality\n",
    "    non_seasonal_ar=1,\n",
    "    non_seasonal_differences=1,\n",
    "    non_seasonal_ma=1,\n",
    "    seasonal_ar=1,\n",
    "    seasonal_differences=0,\n",
    "    seasonal_ma=1\n",
    ")\n",
    "\n",
    "print(spec_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA\n",
    "fit_arima = spec_arima.fit(train, \"sales ~ date\")\n",
    "print(\"ARIMA model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pred_arima = fit_arima.predict(test)\n",
    "print(pred_arima.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and extract outputs\n",
    "fit_arima = fit_arima.evaluate(test)\n",
    "outputs_arima, coefs_arima, stats_arima = fit_arima.extract_outputs()\n",
    "\n",
    "# Get test metrics\n",
    "arima_test_metrics = stats_arima[\n",
    "    (stats_arima['split'] == 'test') & \n",
    "    (stats_arima['metric'].isin(['rmse', 'mae', 'mape', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"ARIMA Test Metrics:\")\n",
    "print(arima_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 3: Random Forest (ML with Time Features)\n",
    "\n",
    "Random Forest doesn't handle dates natively, so we need to engineer features:\n",
    "- Lag features (previous values)\n",
    "- Rolling statistics (moving averages)\n",
    "- Time-based features (day of week, month, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_features(df, target_col='sales', lags=[1, 7, 14]):\n",
    "    \"\"\"\n",
    "    Create time series features for ML models.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'date' and target column\n",
    "        target_col: Name of target variable\n",
    "        lags: List of lag periods to create\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Time-based features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['rolling_mean_7'] = df[target_col].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['rolling_std_7'] = df[target_col].shift(1).rolling(window=7, min_periods=1).std()\n",
    "    df['rolling_mean_14'] = df[target_col].shift(1).rolling(window=14, min_periods=1).mean()\n",
    "    \n",
    "    # Drop rows with NaN (from lag/rolling features)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features for train and test\n",
    "train_rf = create_time_series_features(train)\n",
    "test_rf = create_time_series_features(test)\n",
    "\n",
    "print(\"Random Forest features:\")\n",
    "print(train_rf.head(20))\n",
    "print(f\"\\nTrain shape: {train_rf.shape}\")\n",
    "print(f\"Test shape: {test_rf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest specification\n",
    "spec_rf = rand_forest(\n",
    "    trees=300,\n",
    "    mtry=4,\n",
    "    min_n=5\n",
    ").set_mode(\"regression\")\n",
    "\n",
    "print(spec_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Forest (using engineered features)\n",
    "formula_rf = \"sales ~ day_of_week + day_of_month + month + lag_1 + lag_7 + lag_14 + rolling_mean_7 + rolling_std_7 + rolling_mean_14\"\n",
    "\n",
    "fit_rf = spec_rf.fit(train_rf, formula_rf)\n",
    "print(\"Random Forest model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pred_rf = fit_rf.predict(test_rf)\n",
    "print(pred_rf.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and extract outputs\n",
    "fit_rf = fit_rf.evaluate(test_rf)\n",
    "outputs_rf, coefs_rf, stats_rf = fit_rf.extract_outputs()\n",
    "\n",
    "print(\"\\nRandom Forest Feature Importances:\")\n",
    "print(coefs_rf.sort_values('coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test metrics\n",
    "rf_test_metrics = stats_rf[\n",
    "    (stats_rf['split'] == 'test') & \n",
    "    (stats_rf['metric'].isin(['rmse', 'mae', 'mape', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"Random Forest Test Metrics:\")\n",
    "print(rf_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 4: Linear Regression (Simple Baseline)\n",
    "\n",
    "Linear regression with the same time features as Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Linear Regression specification\n",
    "spec_lm = linear_reg()\n",
    "\n",
    "# Fit using same formula as Random Forest\n",
    "fit_lm = spec_lm.fit(train_rf, formula_rf)\n",
    "print(\"Linear Regression model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "fit_lm = fit_lm.evaluate(test_rf)\n",
    "outputs_lm, coefs_lm, stats_lm = fit_lm.extract_outputs()\n",
    "\n",
    "# Get test metrics\n",
    "lm_test_metrics = stats_lm[\n",
    "    (stats_lm['split'] == 'test') & \n",
    "    (stats_lm['metric'].isin(['rmse', 'mae', 'mape', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"Linear Regression Test Metrics:\")\n",
    "print(lm_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model Comparison\n",
    "\n",
    "Compare all models on test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all test metrics\n",
    "prophet_test_metrics['model'] = 'Prophet'\n",
    "arima_test_metrics['model'] = 'ARIMA'\n",
    "rf_test_metrics['model'] = 'Random Forest'\n",
    "lm_test_metrics['model'] = 'Linear Regression'\n",
    "\n",
    "all_metrics = pd.concat([\n",
    "    prophet_test_metrics,\n",
    "    arima_test_metrics,\n",
    "    rf_test_metrics,\n",
    "    lm_test_metrics\n",
    "], ignore_index=True)\n",
    "\n",
    "# Pivot for easy comparison\n",
    "comparison = all_metrics.pivot(index='metric', columns='model', values='value')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON - TEST SET METRICS\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison)\n",
    "print(\"\\nLower is better for: RMSE, MAE, MAPE\")\n",
    "print(\"Higher is better for: R²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model for each metric\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BEST MODEL FOR EACH METRIC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for metric in ['rmse', 'mae', 'mape']:\n",
    "    best_model = comparison.loc[metric].idxmin()\n",
    "    best_value = comparison.loc[metric].min()\n",
    "    print(f\"{metric.upper():6s}: {best_model:20s} ({best_value:.2f})\")\n",
    "\n",
    "# R² is higher-is-better\n",
    "best_model = comparison.loc['r_squared'].idxmax()\n",
    "best_value = comparison.loc['r_squared'].max()\n",
    "print(f\"R²    : {best_model:20s} ({best_value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Future Forecasting\n",
    "\n",
    "Generate forecasts for the next 30 days beyond the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future dates\n",
    "last_date = data['date'].max()\n",
    "future_dates = [last_date + timedelta(days=i+1) for i in range(30)]\n",
    "future_data = pd.DataFrame({'date': future_dates})\n",
    "\n",
    "print(f\"Forecasting for: {future_data['date'].min()} to {future_data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet Future Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet can forecast directly\n",
    "future_prophet = fit_prophet.predict(future_data)\n",
    "\n",
    "print(\"Prophet Future Forecast:\")\n",
    "print(future_prophet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Future Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA can also forecast directly\n",
    "future_arima = fit_arima.predict(future_data)\n",
    "\n",
    "print(\"ARIMA Future Forecast:\")\n",
    "print(future_arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Future Forecast\n",
    "\n",
    "**Note**: For ML models, we need to generate features iteratively for multi-step forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ML models, we need to forecast iteratively\n",
    "# Start with full historical data\n",
    "full_history = data.copy()\n",
    "\n",
    "# Forecast one day at a time\n",
    "future_forecasts_rf = []\n",
    "\n",
    "for future_date in future_dates:\n",
    "    # Create features for this future date\n",
    "    temp_data = pd.concat([\n",
    "        full_history,\n",
    "        pd.DataFrame({'date': [future_date], 'sales': [np.nan]})\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    temp_features = create_time_series_features(temp_data.dropna())\n",
    "    \n",
    "    if len(temp_features) == 0:\n",
    "        print(f\"Warning: Could not create features for {future_date}\")\n",
    "        continue\n",
    "    \n",
    "    # Get last row (our future date)\n",
    "    future_row = temp_features.iloc[[-1]].copy()\n",
    "    \n",
    "    # Predict\n",
    "    pred = fit_rf.predict(future_row)\n",
    "    forecast_value = pred['.pred'].values[0]\n",
    "    \n",
    "    # Store forecast\n",
    "    future_forecasts_rf.append({\n",
    "        'date': future_date,\n",
    "        '.pred': forecast_value\n",
    "    })\n",
    "    \n",
    "    # Add to history for next iteration\n",
    "    full_history = pd.concat([\n",
    "        full_history,\n",
    "        pd.DataFrame({'date': [future_date], 'sales': [forecast_value]})\n",
    "    ], ignore_index=True)\n",
    "\n",
    "future_rf = pd.DataFrame(future_forecasts_rf)\n",
    "print(\"Random Forest Future Forecast:\")\n",
    "print(future_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Future Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all forecasts\n",
    "forecast_comparison = pd.DataFrame({\n",
    "    'date': future_dates,\n",
    "    'Prophet': future_prophet['.pred'].values,\n",
    "    'ARIMA': future_arima['.pred'].values,\n",
    "    'Random Forest': future_rf['.pred'].values\n",
    "})\n",
    "\n",
    "print(\"\\nFuture Forecast Comparison:\")\n",
    "print(forecast_comparison)\n",
    "\n",
    "print(\"\\nForecast Statistics:\")\n",
    "print(forecast_comparison[['Prophet', 'ARIMA', 'Random Forest']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## Model Characteristics:\n",
    "\n",
    "### 1. Prophet\n",
    "- **Pros**: Handles dates natively, automatic trend/seasonality detection, robust to missing data\n",
    "- **Cons**: Can be slower, less flexible for custom features\n",
    "- **Best for**: Business time series with strong seasonality\n",
    "\n",
    "### 2. ARIMA\n",
    "- **Pros**: Classical approach, interpretable parameters, works well with stationary series\n",
    "- **Cons**: Requires stationarity, parameter tuning can be complex\n",
    "- **Best for**: Stationary time series, short-term forecasts\n",
    "\n",
    "### 3. Random Forest\n",
    "- **Pros**: Captures non-linear relationships, handles complex interactions, feature importances\n",
    "- **Cons**: Requires feature engineering, can't extrapolate trends, slower for multi-step forecasting\n",
    "- **Best for**: Time series with rich features, non-linear patterns\n",
    "\n",
    "### 4. Linear Regression\n",
    "- **Pros**: Fast, interpretable coefficients, simple baseline\n",
    "- **Cons**: Assumes linear relationships, limited flexibility\n",
    "- **Best for**: Simple trends, baseline comparisons\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "1. **Native time series models** (Prophet, ARIMA) are easier to use but less flexible\n",
    "2. **ML models** (Random Forest, Linear Reg) require feature engineering but can capture complex patterns\n",
    "3. **All models** return standardized three-DataFrame outputs for consistent analysis\n",
    "4. **evaluate()** method enables easy train/test comparison across all model types\n",
    "5. **Multi-step forecasting** is straightforward for Prophet/ARIMA, iterative for ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py-tidymodels2)",
   "language": "python",
   "name": "py-tidymodels2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}