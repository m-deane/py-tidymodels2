{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Demo: Automated Forecasting Workflow Generation\n",
    "\n",
    "This notebook demonstrates the `py_agent` package for automated time series forecasting.\n",
    "\n",
    "The `ForecastAgent` can:\n",
    "- Analyze your data automatically\n",
    "- Recommend appropriate models\n",
    "- Generate preprocessing recipes\n",
    "- Create complete workflows\n",
    "- Debug performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from py_agent import ForecastAgent\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Daily Sales Forecasting\n",
    "\n",
    "Let's create synthetic daily sales data with weekly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic sales data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2020-01-01', periods=365*2, freq='D')\n",
    "\n",
    "# Components: trend + weekly seasonality + noise\n",
    "trend = np.arange(len(dates)) * 0.1\n",
    "seasonality = np.sin(np.arange(len(dates)) * 2 * np.pi / 7) * 20\n",
    "noise = np.random.randn(len(dates)) * 5\n",
    "sales = 100 + trend + seasonality + noise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': sales\n",
    "})\n",
    "\n",
    "# Split train/test\n",
    "train = df.iloc[:int(len(df)*0.8)]\n",
    "test = df.iloc[int(len(df)*0.8):]\n",
    "\n",
    "print(f\"Train: {len(train)} days\")\n",
    "print(f\"Test: {len(test)} days\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train['date'], train['sales'], label='Train', alpha=0.7)\n",
    "plt.plot(test['date'], test['sales'], label='Test', alpha=0.7)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Daily Sales Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Workflow with AI Agent\n",
    "\n",
    "Simply describe what you want in natural language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "agent = ForecastAgent(verbose=True)\n",
    "\n",
    "# Generate workflow from natural language\n",
    "workflow = agent.generate_workflow(\n",
    "    data=train,\n",
    "    request=\"Forecast daily sales with weekly seasonality\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Workflow generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the Agent Analyzed\n",
    "\n",
    "Let's see what the agent discovered about our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the analysis results\n",
    "info = agent.last_workflow_info\n",
    "data_chars = info['data_characteristics']\n",
    "\n",
    "print(\"üìä DATA ANALYSIS:\")\n",
    "print(f\"  Frequency: {data_chars['frequency']}\")\n",
    "print(f\"  Seasonality Detected: {data_chars['seasonality']['detected']}\")\n",
    "print(f\"  Seasonal Strength: {data_chars['seasonality']['strength']:.2%}\")\n",
    "print(f\"  Seasonal Period: {data_chars['seasonality']['period']} days\")\n",
    "print(f\"  Trend: {data_chars['trend']['direction']} (strength={data_chars['trend']['strength']:.2%})\")\n",
    "print(f\"  Autocorrelation (lag-1): {data_chars['autocorrelation']['lag_1']:.2f}\")\n",
    "print(f\"  Missing Data: {data_chars['missing_rate']:.1%}\")\n",
    "print(f\"  Outliers: {data_chars['outlier_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the recommended model\n",
    "print(\"\\nü§ñ RECOMMENDED MODEL:\")\n",
    "print(f\"  Model: {info['model_type']}\")\n",
    "print(f\"\\nüìù GENERATED RECIPE:\")\n",
    "print(info['recipe_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict\n",
    "\n",
    "Now use the generated workflow like any py-tidymodels workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the workflow\n",
    "fit = workflow.fit(train)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = fit.predict(test)\n",
    "\n",
    "print(\"‚úÖ Model fitted and predictions made!\")\n",
    "print(f\"\\nPredictions shape: {predictions.shape}\")\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train['date'].iloc[-60:], train['sales'].iloc[-60:], label='Train (last 60 days)', alpha=0.7)\n",
    "plt.plot(test['date'], test['sales'], label='Actual', alpha=0.7)\n",
    "plt.plot(test['date'], predictions['.pred'], label='Predicted', alpha=0.7, linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Forecast Results')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Debugging\n",
    "\n",
    "Let the agent analyze the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug the model\n",
    "diagnostics = agent.debug_session(fit, test)\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "for i, rec in enumerate(diagnostics['recommendations'], 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Grouped Forecasting (Multiple Stores)\n",
    "\n",
    "Let's forecast sales for multiple stores simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-store data\n",
    "np.random.seed(42)\n",
    "stores = ['Store_A', 'Store_B', 'Store_C']\n",
    "dates = pd.date_range('2020-01-01', periods=365, freq='D')\n",
    "\n",
    "data_list = []\n",
    "for store in stores:\n",
    "    # Each store has different baseline and trend\n",
    "    baseline = np.random.uniform(80, 120)\n",
    "    trend_strength = np.random.uniform(0.05, 0.15)\n",
    "    \n",
    "    trend = np.arange(len(dates)) * trend_strength\n",
    "    seasonality = np.sin(np.arange(len(dates)) * 2 * np.pi / 7) * 15\n",
    "    noise = np.random.randn(len(dates)) * 5\n",
    "    sales = baseline + trend + seasonality + noise\n",
    "    \n",
    "    store_df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'store_id': store,\n",
    "        'sales': sales\n",
    "    })\n",
    "    data_list.append(store_df)\n",
    "\n",
    "multi_store_df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Split train/test\n",
    "train_multi = multi_store_df.groupby('store_id').apply(lambda x: x.iloc[:int(len(x)*0.8)]).reset_index(drop=True)\n",
    "test_multi = multi_store_df.groupby('store_id').apply(lambda x: x.iloc[int(len(x)*0.8):]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total rows: {len(multi_store_df)}\")\n",
    "print(f\"Stores: {multi_store_df['store_id'].unique()}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(train_multi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate workflow for grouped forecasting\n",
    "agent_multi = ForecastAgent(verbose=True)\n",
    "\n",
    "workflow_multi = agent_multi.generate_workflow(\n",
    "    data=train_multi,\n",
    "    request=\"Forecast sales for each store with weekly seasonality\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-store workflow generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with grouped modeling\n",
    "fit_multi = workflow_multi.fit_nested(train_multi, group_col='store_id')\n",
    "\n",
    "# Predict for all stores\n",
    "predictions_multi = fit_multi.predict(test_multi)\n",
    "\n",
    "print(\"‚úÖ Fitted models for all stores!\")\n",
    "print(f\"\\nPredictions shape: {predictions_multi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-store forecasts\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, store in enumerate(stores):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    train_store = train_multi[train_multi['store_id'] == store].iloc[-60:]\n",
    "    test_store = test_multi[test_multi['store_id'] == store]\n",
    "    pred_store = predictions_multi[predictions_multi['store_id'] == store]\n",
    "    \n",
    "    ax.plot(train_store['date'], train_store['sales'], label='Train', alpha=0.7)\n",
    "    ax.plot(test_store['date'], test_store['sales'], label='Actual', alpha=0.7)\n",
    "    ax.plot(pred_store['date'], pred_store['.pred'], label='Predicted', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    ax.set_title(store)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Sales')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Conversational Session\n",
    "\n",
    "Build workflows through conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversational session\n",
    "session = agent.start_session()\n",
    "\n",
    "# Provide data to session\n",
    "session.context['data'] = train\n",
    "\n",
    "# Multi-turn conversation\n",
    "session.send(\"I need to forecast sales\")\n",
    "session.send(\"Daily data\")\n",
    "session.send(\"Forecast 30 days ahead\")\n",
    "\n",
    "# Generate workflow from conversation\n",
    "workflow_conv = session.get_workflow()\n",
    "\n",
    "print(\"\\n‚úÖ Workflow generated from conversation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Custom Constraints\n",
    "\n",
    "Specify constraints for model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate workflow with constraints\n",
    "agent_constrained = ForecastAgent(verbose=True)\n",
    "\n",
    "workflow_constrained = agent_constrained.generate_workflow(\n",
    "    data=train,\n",
    "    request=\"Forecast sales\",\n",
    "    constraints={\n",
    "        'max_train_time': 10,  # 10 seconds max\n",
    "        'interpretability': 'high',  # Must be highly interpretable\n",
    "        'max_memory': 100  # 100 MB max memory\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Constrained workflow generated!\")\n",
    "print(f\"Selected model: {agent_constrained.last_workflow_info['model_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `py_agent` package provides:\n",
    "\n",
    "1. **Automatic Data Analysis**: Frequency, seasonality, trend detection\n",
    "2. **Intelligent Model Selection**: Based on data characteristics and constraints\n",
    "3. **Recipe Generation**: Automatic preprocessing based on data quality\n",
    "4. **Workflow Creation**: Complete py-tidymodels workflows from natural language\n",
    "5. **Performance Debugging**: Identify and fix common issues\n",
    "6. **Conversational Interface**: Build workflows through dialogue\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try with your own data\n",
    "- Experiment with different constraints\n",
    "- Use debug_session() to improve models\n",
    "- Explore conversational interface for complex scenarios\n",
    "\n",
    "For more information, see: `py_agent/README.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
