{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Forecasting Demo\n",
    "\n",
    "This notebook demonstrates **recursive (autoregressive) forecasting** for multi-step time series prediction using `recursive_reg()`.\n",
    "\n",
    "## What is Recursive Forecasting?\n",
    "\n",
    "Recursive forecasting uses **lagged values** of the target variable as features to predict future values:\n",
    "- Trains a regression model on past observations (lags)\n",
    "- Predicts one step ahead\n",
    "- Uses that prediction as input for the next prediction\n",
    "- Repeats recursively for multi-step forecasts\n",
    "\n",
    "## Key Features:\n",
    "\n",
    "1. **Wraps any sklearn-compatible model**: Use `linear_reg()`, `rand_forest()`, etc. as base models\n",
    "2. **Flexible lag specification**: Integer (use lags 1-n) or list (specific lags)\n",
    "3. **Differentiation support**: Make non-stationary series stationary\n",
    "4. **Prediction intervals**: Get uncertainty estimates\n",
    "5. **Three-DataFrame outputs**: Standardized outputs for all models\n",
    "\n",
    "## When to Use Recursive Forecasting:\n",
    "\n",
    "- **Short to medium-term forecasts**: Works well for horizons up to 30-90 days\n",
    "- **Autocorrelated data**: When past values predict future values\n",
    "- **Non-linear patterns**: Random Forest can capture complex relationships\n",
    "- **Simple implementation**: No need for manual feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from py_parsnip import recursive_reg, linear_reg, rand_forest\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Time Series Data\n",
    "\n",
    "We'll create daily data with:\n",
    "- **Trend**: Increasing over time\n",
    "- **Weekly seasonality**: 7-day pattern\n",
    "- **Noise**: Random variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview:\n",
      "                 sales\n",
      "date                  \n",
      "2023-01-01  102.483571\n",
      "2023-01-02  115.280879\n",
      "2023-01-03  123.408142\n",
      "2023-01-04  117.299535\n",
      "2023-01-05   91.493840\n",
      "2023-01-06   81.008609\n",
      "2023-01-07   94.272857\n",
      "2023-01-08  106.186167\n",
      "2023-01-09  115.973821\n",
      "2023-01-10  125.231493\n",
      "\n",
      "Shape: (150, 1)\n",
      "Date range: 2023-01-01 00:00:00 to 2023-05-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Generate 150 days of data\n",
    "n_days = 150\n",
    "dates = pd.date_range(\"2023-01-01\", periods=n_days, freq=\"D\")\n",
    "\n",
    "# Create time series components\n",
    "trend = np.linspace(100, 150, n_days)\n",
    "seasonality = 20 * np.sin(2 * np.pi * np.arange(n_days) / 7)  # Weekly pattern\n",
    "noise = np.random.normal(0, 5, n_days)\n",
    "\n",
    "sales = trend + seasonality + noise\n",
    "\n",
    "data = pd.DataFrame({\"date\": dates, \"sales\": sales})\n",
    "data = data.set_index(\"date\")\n",
    "\n",
    "print(\"Data Overview:\")\n",
    "print(data.head(10))\n",
    "print(f\"\\nShape: {data.shape}\")\n",
    "print(f\"Date range: {data.index.min()} to {data.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "Split chronologically (not randomly) for time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 120 days (2023-01-01 00:00:00 to 2023-04-30 00:00:00)\n",
      "Test: 30 days (2023-05-01 00:00:00 to 2023-05-30 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Train on first 120 days, test on last 30 days\n",
    "train = data.iloc[:120]\n",
    "test = data.iloc[120:]\n",
    "\n",
    "print(f\"Train: {len(train)} days ({train.index.min()} to {train.index.max()})\")\n",
    "print(f\"Test: {len(test)} days ({test.index.min()} to {test.index.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 1: Recursive with Linear Regression\n",
    "\n",
    "Start with a simple linear model using 7 lags (past week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSpec(model_type='recursive_reg', engine='skforecast', mode='regression', args={'base_model': ModelSpec(model_type='linear_reg', engine='sklearn', mode='regression', args={}), 'lags': 7, 'differentiation': None})\n",
      "\n",
      "Base model type: linear_reg\n",
      "Lags: 7\n"
     ]
    }
   ],
   "source": [
    "# Create recursive specification with linear base model\n",
    "spec_linear = recursive_reg(\n",
    "    base_model=linear_reg(),\n",
    "    lags=7  # Use past 7 days as features\n",
    ")\n",
    "\n",
    "print(spec_linear)\n",
    "print(f\"\\nBase model type: {spec_linear.args['base_model'].model_type}\")\n",
    "print(f\"Lags: {spec_linear.args['lags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear recursive model fitted!\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "fit_linear = spec_linear.fit(train, \"sales ~ .\")\n",
    "print(\"Linear recursive model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "                 .pred\n",
      "date                  \n",
      "2023-05-01  164.557752\n",
      "2023-05-02  163.216553\n",
      "2023-05-03  148.829369\n",
      "2023-05-04  131.781997\n",
      "2023-05-05  119.604799\n",
      "2023-05-06  131.433865\n",
      "2023-05-07  148.611666\n",
      "2023-05-08  165.747579\n",
      "2023-05-09  166.317394\n",
      "2023-05-10  150.899573\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "pred_linear = fit_linear.predict(test)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(pred_linear.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Outputs - Three-DataFrame Structure\n",
    "\n",
    "All models return three DataFrames:\n",
    "1. **Outputs**: Observation-level data (actuals, fitted, forecast, residuals)\n",
    "2. **Coefficients**: Model parameters (lag coefficients for linear models)\n",
    "3. **Stats**: Model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. OUTPUTS DataFrame (first 10 rows):\n",
      "        date     actuals  fitted    forecast  residuals  split          model  \\\n",
      "0 2023-01-01  102.483571     NaN  102.483571        NaN  train  recursive_reg   \n",
      "1 2023-01-02  115.280879     NaN  115.280879        NaN  train  recursive_reg   \n",
      "2 2023-01-03  123.408142     NaN  123.408142        NaN  train  recursive_reg   \n",
      "3 2023-01-04  117.299535     NaN  117.299535        NaN  train  recursive_reg   \n",
      "4 2023-01-05   91.493840     NaN   91.493840        NaN  train  recursive_reg   \n",
      "5 2023-01-06   81.008609     NaN   81.008609        NaN  train  recursive_reg   \n",
      "6 2023-01-07   94.272857     NaN   94.272857        NaN  train  recursive_reg   \n",
      "7 2023-01-08  106.186167     NaN  106.186167        NaN  train  recursive_reg   \n",
      "8 2023-01-09  115.973821     NaN  115.973821        NaN  train  recursive_reg   \n",
      "9 2023-01-10  125.231493     NaN  125.231493        NaN  train  recursive_reg   \n",
      "\n",
      "  model_group_name   group  \n",
      "0                   global  \n",
      "1                   global  \n",
      "2                   global  \n",
      "3                   global  \n",
      "4                   global  \n",
      "5                   global  \n",
      "6                   global  \n",
      "7                   global  \n",
      "8                   global  \n",
      "9                   global  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set first\n",
    "fit_linear = fit_linear.evaluate(test)\n",
    "\n",
    "# Extract outputs\n",
    "outputs_linear, coefs_linear, stats_linear = fit_linear.extract_outputs()\n",
    "\n",
    "print(\"1. OUTPUTS DataFrame (first 10 rows):\")\n",
    "print(outputs_linear.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. COEFFICIENTS DataFrame:\n",
      "    variable  coefficient  std_error  t_stat  p_value  ci_0.025  ci_0.975  \\\n",
      "0      lag_1     0.336396        NaN     NaN      NaN       NaN       NaN   \n",
      "1      lag_2     0.068139        NaN     NaN      NaN       NaN       NaN   \n",
      "2      lag_3    -0.106501        NaN     NaN      NaN       NaN       NaN   \n",
      "3      lag_4    -0.182646        NaN     NaN      NaN       NaN       NaN   \n",
      "4      lag_5     0.265701        NaN     NaN      NaN       NaN       NaN   \n",
      "5      lag_6     0.149203        NaN     NaN      NaN       NaN       NaN   \n",
      "6      lag_7     0.487109        NaN     NaN      NaN       NaN       NaN   \n",
      "7  Intercept    -0.447153        NaN     NaN      NaN       NaN       NaN   \n",
      "\n",
      "   vif          model model_group_name   group  \n",
      "0  NaN  recursive_reg                   global  \n",
      "1  NaN  recursive_reg                   global  \n",
      "2  NaN  recursive_reg                   global  \n",
      "3  NaN  recursive_reg                   global  \n",
      "4  NaN  recursive_reg                   global  \n",
      "5  NaN  recursive_reg                   global  \n",
      "6  NaN  recursive_reg                   global  \n",
      "7  NaN  recursive_reg                   global  \n",
      "\n",
      "Lag Coefficients (importance of each past day):\n",
      "  variable  coefficient\n",
      "6    lag_7     0.487109\n",
      "0    lag_1     0.336396\n",
      "4    lag_5     0.265701\n",
      "5    lag_6     0.149203\n",
      "1    lag_2     0.068139\n",
      "2    lag_3    -0.106501\n",
      "3    lag_4    -0.182646\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. COEFFICIENTS DataFrame:\")\n",
    "print(coefs_linear)\n",
    "\n",
    "# Lag coefficients show importance of each lag\n",
    "lag_coefs = coefs_linear[coefs_linear['variable'].str.contains('lag_', na=False)]\n",
    "print(\"\\nLag Coefficients (importance of each past day):\")\n",
    "print(lag_coefs[['variable', 'coefficient']].sort_values('coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. STATS DataFrame:\n",
      "             metric       value  split          model model_group_name   group\n",
      "0              rmse         NaN  train  recursive_reg                   global\n",
      "1               mae         NaN  train  recursive_reg                   global\n",
      "2              mape         NaN  train  recursive_reg                   global\n",
      "3         r_squared         NaN  train  recursive_reg                   global\n",
      "4              rmse    7.682572   test  recursive_reg                   global\n",
      "5               mae    6.247134   test  recursive_reg                   global\n",
      "6              mape    4.391373   test  recursive_reg                   global\n",
      "7         r_squared    0.755406   test  recursive_reg                   global\n",
      "8           formula   sales ~ .         recursive_reg                   global\n",
      "9       n_obs_train         120  train  recursive_reg                   global\n",
      "10             lags           7         recursive_reg                   global\n",
      "11  differentiation        None         recursive_reg                   global\n",
      "12       base_model  linear_reg         recursive_reg                   global\n",
      "\n",
      "Test Set Metrics:\n",
      "      metric     value\n",
      "4       rmse  7.682572\n",
      "5        mae  6.247134\n",
      "7  r_squared  0.755406\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. STATS DataFrame:\")\n",
    "print(stats_linear)\n",
    "\n",
    "# Get test metrics\n",
    "test_metrics = stats_linear[\n",
    "    (stats_linear['split'] == 'test') & \n",
    "    (stats_linear['metric'].isin(['rmse', 'mae', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 2: Recursive with Random Forest\n",
    "\n",
    "Random Forest can capture **non-linear relationships** between lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSpec(model_type='recursive_reg', engine='skforecast', mode='regression', args={'base_model': ModelSpec(model_type='rand_forest', engine='sklearn', mode='unknown', args={'trees': 200, 'min_n': 5}), 'lags': 7, 'differentiation': None})\n"
     ]
    }
   ],
   "source": [
    "# Create recursive specification with Random Forest base model\n",
    "spec_rf = recursive_reg(\n",
    "    base_model=rand_forest(trees=200, min_n=5),\n",
    "    lags=7\n",
    ")\n",
    "\n",
    "print(spec_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest recursive model fitted and evaluated!\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate\n",
    "fit_rf = spec_rf.fit(train, \"sales ~ .\")\n",
    "fit_rf = fit_rf.evaluate(test)\n",
    "\n",
    "print(\"Random Forest recursive model fitted and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      "  variable  coefficient\n",
      "6    lag_7     0.929886\n",
      "0    lag_1     0.018474\n",
      "5    lag_6     0.014600\n",
      "4    lag_5     0.012253\n",
      "2    lag_3     0.008688\n",
      "3    lag_4     0.008314\n",
      "1    lag_2     0.007785\n",
      "\n",
      "Interpretation: Higher values indicate more important lags for prediction\n"
     ]
    }
   ],
   "source": [
    "# Extract outputs\n",
    "outputs_rf, coefs_rf, stats_rf = fit_rf.extract_outputs()\n",
    "\n",
    "# Random Forest reports feature importances\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(coefs_rf[['variable', 'coefficient']].sort_values('coefficient', ascending=False))\n",
    "\n",
    "print(\"\\nInterpretation: Higher values indicate more important lags for prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Metrics:\n",
      "      metric      value\n",
      "4       rmse  11.148346\n",
      "5        mae   9.059137\n",
      "7  r_squared   0.484945\n"
     ]
    }
   ],
   "source": [
    "# Get test metrics\n",
    "rf_test_metrics = stats_rf[\n",
    "    (stats_rf['split'] == 'test') & \n",
    "    (stats_rf['metric'].isin(['rmse', 'mae', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"Random Forest Test Metrics:\")\n",
    "print(rf_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 3: Specific Lag Selection\n",
    "\n",
    "Instead of using all lags 1-7, we can select **specific lags** that match known patterns.\n",
    "\n",
    "For example, with weekly data:\n",
    "- Lag 1: Yesterday\n",
    "- Lag 7: Same day last week\n",
    "- Lag 14: Same day 2 weeks ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSpec(model_type='recursive_reg', engine='skforecast', mode='regression', args={'base_model': ModelSpec(model_type='rand_forest', engine='sklearn', mode='unknown', args={'trees': 200, 'min_n': 5}), 'lags': [1, 7, 14], 'differentiation': None})\n",
      "\n",
      "Using lags: [1, 7, 14]\n"
     ]
    }
   ],
   "source": [
    "# Create recursive specification with specific lags\n",
    "spec_lags = recursive_reg(\n",
    "    base_model=rand_forest(trees=200, min_n=5),\n",
    "    lags=[1, 7, 14]  # Specific lag indices\n",
    ")\n",
    "\n",
    "print(spec_lags)\n",
    "print(f\"\\nUsing lags: {spec_lags.args['lags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances for Specific Lags:\n",
      "  variable  coefficient\n",
      "2   lag_14     0.522144\n",
      "1    lag_7     0.460430\n",
      "0    lag_1     0.017426\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate\n",
    "fit_lags = spec_lags.fit(train, \"sales ~ .\")\n",
    "fit_lags = fit_lags.evaluate(test)\n",
    "\n",
    "outputs_lags, coefs_lags, stats_lags = fit_lags.extract_outputs()\n",
    "\n",
    "# Feature importances for specific lags\n",
    "print(\"Feature Importances for Specific Lags:\")\n",
    "print(coefs_lags[['variable', 'coefficient']].sort_values('coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific Lags Test Metrics:\n",
      "      metric      value\n",
      "4       rmse  11.173599\n",
      "5        mae   9.247505\n",
      "7  r_squared   0.482609\n"
     ]
    }
   ],
   "source": [
    "# Get test metrics\n",
    "lags_test_metrics = stats_lags[\n",
    "    (stats_lags['split'] == 'test') & \n",
    "    (stats_lags['metric'].isin(['rmse', 'mae', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"Specific Lags Test Metrics:\")\n",
    "print(lags_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model 4: Differentiation for Non-Stationary Data\n",
    "\n",
    "For data with strong trends, **differencing** can improve model performance by making the series stationary.\n",
    "\n",
    "- `differentiation=1`: First difference (removes linear trend)\n",
    "- `differentiation=2`: Second difference (removes quadratic trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSpec(model_type='recursive_reg', engine='skforecast', mode='regression', args={'base_model': ModelSpec(model_type='linear_reg', engine='sklearn', mode='regression', args={}), 'lags': 7, 'differentiation': 1})\n",
      "\n",
      "Differentiation order: 1\n"
     ]
    }
   ],
   "source": [
    "# Create recursive specification with differentiation\n",
    "spec_diff = recursive_reg(\n",
    "    base_model=linear_reg(),\n",
    "    lags=7,\n",
    "    differentiation=1  # Apply first differencing\n",
    ")\n",
    "\n",
    "print(spec_diff)\n",
    "print(f\"\\nDifferentiation order: {spec_diff.args['differentiation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differentiated Model Test Metrics:\n",
      "      metric     value\n",
      "4       rmse  6.529885\n",
      "5        mae  5.556278\n",
      "7  r_squared  0.823297\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate\n",
    "fit_diff = spec_diff.fit(train, \"sales ~ .\")\n",
    "fit_diff = fit_diff.evaluate(test)\n",
    "\n",
    "outputs_diff, coefs_diff, stats_diff = fit_diff.extract_outputs()\n",
    "\n",
    "# Get test metrics\n",
    "diff_test_metrics = stats_diff[\n",
    "    (stats_diff['split'] == 'test') & \n",
    "    (stats_diff['metric'].isin(['rmse', 'mae', 'r_squared']))\n",
    "][['metric', 'value']]\n",
    "\n",
    "print(\"Differentiated Model Test Metrics:\")\n",
    "print(diff_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prediction Intervals\n",
    "\n",
    "Get **uncertainty estimates** with prediction intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with 90% Prediction Intervals:\n",
      "                 .pred  .pred_lower  .pred_upper\n",
      "date                                            \n",
      "2023-05-01  158.512917   155.036640   165.479643\n",
      "2023-05-02  157.096032   154.380623   164.503835\n",
      "2023-05-03  150.126702   147.842040   157.521057\n",
      "2023-05-04  136.720868   131.999045   141.257660\n",
      "2023-05-05  115.790545   110.261882   118.417427\n",
      "2023-05-06  136.155311   131.372863   140.285499\n",
      "2023-05-07  147.067404   144.441834   153.764168\n",
      "2023-05-08  158.375612   155.095576   165.460412\n",
      "2023-05-09  156.883055   153.372913   164.172953\n",
      "2023-05-10  150.357190   148.257829   160.703553\n",
      "2023-05-11  142.503815   134.308324   145.714845\n",
      "2023-05-12  113.757639   109.758064   119.994012\n",
      "2023-05-13  141.753752   132.562102   144.029083\n",
      "2023-05-14  151.115195   147.825910   160.045315\n",
      "2023-05-15  158.493686   155.092864   165.535867\n",
      "\n",
      "Interval Coverage Check:\n",
      "Lower <= Prediction: True\n",
      "Prediction <= Upper: True\n"
     ]
    }
   ],
   "source": [
    "# Predict with intervals (works best with Random Forest)\n",
    "pred_intervals = fit_rf.predict(test, type=\"pred_int\")\n",
    "\n",
    "print(\"Predictions with 90% Prediction Intervals:\")\n",
    "print(pred_intervals.head(15))\n",
    "\n",
    "# Verify intervals are properly ordered\n",
    "print(\"\\nInterval Coverage Check:\")\n",
    "print(f\"Lower <= Prediction: {(pred_intervals['.pred_lower'] <= pred_intervals['.pred']).all()}\")\n",
    "print(f\"Prediction <= Upper: {(pred_intervals['.pred'] <= pred_intervals['.pred_upper']).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model Comparison\n",
    "\n",
    "Compare all models on test set performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MODEL COMPARISON - TEST SET METRICS\n",
      "====================================================================================================\n",
      "model     Linear (7 lags) Linear (7 lags, diff=1) Random Forest (1,7,14 lags)  \\\n",
      "metric                                                                          \n",
      "mae              6.247134                5.556278                    9.247505   \n",
      "r_squared        0.755406                0.823297                    0.482609   \n",
      "rmse             7.682572                6.529885                   11.173599   \n",
      "\n",
      "model     Random Forest (7 lags)  \n",
      "metric                            \n",
      "mae                     9.059137  \n",
      "r_squared               0.484945  \n",
      "rmse                   11.148346  \n",
      "\n",
      "Lower is better for: RMSE, MAE\n",
      "Higher is better for: R²\n"
     ]
    }
   ],
   "source": [
    "# Combine all test metrics\n",
    "linear_metrics = test_metrics.copy()\n",
    "linear_metrics['model'] = 'Linear (7 lags)'\n",
    "\n",
    "rf_metrics = rf_test_metrics.copy()\n",
    "rf_metrics['model'] = 'Random Forest (7 lags)'\n",
    "\n",
    "lags_metrics = lags_test_metrics.copy()\n",
    "lags_metrics['model'] = 'Random Forest (1,7,14 lags)'\n",
    "\n",
    "diff_metrics = diff_test_metrics.copy()\n",
    "diff_metrics['model'] = 'Linear (7 lags, diff=1)'\n",
    "\n",
    "all_metrics = pd.concat([\n",
    "    linear_metrics,\n",
    "    rf_metrics,\n",
    "    lags_metrics,\n",
    "    diff_metrics\n",
    "], ignore_index=True)\n",
    "\n",
    "# Pivot for easy comparison\n",
    "comparison = all_metrics.pivot(index='metric', columns='model', values='value')\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"MODEL COMPARISON - TEST SET METRICS\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison)\n",
    "print(\"\\nLower is better for: RMSE, MAE\")\n",
    "print(\"Higher is better for: R²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "BEST MODEL FOR EACH METRIC\n",
      "====================================================================================================\n",
      "RMSE      : Linear (7 lags, diff=1)             (6.5299)\n",
      "MAE       : Linear (7 lags, diff=1)             (5.5563)\n",
      "R²        : Linear (7 lags, diff=1)             (0.8233)\n"
     ]
    }
   ],
   "source": [
    "# Find best model for each metric\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"BEST MODEL FOR EACH METRIC\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for metric in ['rmse', 'mae']:\n",
    "    best_model = comparison.loc[metric].idxmin()\n",
    "    best_value = comparison.loc[metric].min()\n",
    "    print(f\"{metric.upper():10s}: {best_model:35s} ({best_value:.4f})\")\n",
    "\n",
    "# R² is higher-is-better\n",
    "best_model = comparison.loc['r_squared'].idxmax()\n",
    "best_value = comparison.loc['r_squared'].max()\n",
    "print(f\"{'R²':10s}: {best_model:35s} ({best_value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Future Forecasting\n",
    "\n",
    "Forecast beyond the training data into the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting for: 2023-05-31 00:00:00 to 2023-06-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create future dates (30 days beyond test set)\n",
    "last_date = data.index.max()\n",
    "future_dates = pd.date_range(last_date + timedelta(days=1), periods=30, freq=\"D\")\n",
    "future_data = pd.DataFrame(index=future_dates)\n",
    "\n",
    "print(f\"Forecasting for: {future_data.index.min()} to {future_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Forecast (next 30 days):\n",
      "                 .pred\n",
      "2023-05-31  158.512917\n",
      "2023-06-01  157.096032\n",
      "2023-06-02  150.126702\n",
      "2023-06-03  136.720868\n",
      "2023-06-04  115.790545\n",
      "2023-06-05  136.155311\n",
      "2023-06-06  147.067404\n",
      "2023-06-07  158.375612\n",
      "2023-06-08  156.883055\n",
      "2023-06-09  150.357190\n",
      "2023-06-10  142.503815\n",
      "2023-06-11  113.757639\n",
      "2023-06-12  141.753752\n",
      "2023-06-13  151.115195\n",
      "2023-06-14  158.493686\n",
      "2023-06-15  157.222961\n",
      "2023-06-16  150.750451\n",
      "2023-06-17  145.029739\n",
      "2023-06-18  112.669461\n",
      "2023-06-19  144.832870\n",
      "2023-06-20  152.577169\n",
      "2023-06-21  158.493686\n",
      "2023-06-22  157.222961\n",
      "2023-06-23  152.635717\n",
      "2023-06-24  148.514315\n",
      "2023-06-25  112.342070\n",
      "2023-06-26  150.109137\n",
      "2023-06-27  152.805923\n",
      "2023-06-28  158.615999\n",
      "2023-06-29  157.244901\n",
      "\n",
      "Forecast Statistics:\n",
      "Mean: 146.19\n",
      "Std: 14.45\n",
      "Min: 112.34\n",
      "Max: 158.62\n"
     ]
    }
   ],
   "source": [
    "# Generate forecasts with best model (Random Forest)\n",
    "future_forecast = fit_rf.predict(future_data)\n",
    "\n",
    "print(\"Future Forecast (next 30 days):\")\n",
    "print(future_forecast)\n",
    "\n",
    "print(f\"\\nForecast Statistics:\")\n",
    "print(f\"Mean: {future_forecast['.pred'].mean():.2f}\")\n",
    "print(f\"Std: {future_forecast['.pred'].std():.2f}\")\n",
    "print(f\"Min: {future_forecast['.pred'].min():.2f}\")\n",
    "print(f\"Max: {future_forecast['.pred'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Forecast with 90% Prediction Intervals:\n",
      "                 .pred  .pred_lower  .pred_upper\n",
      "2023-05-31  158.512917   155.036640   165.479643\n",
      "2023-06-01  157.096032   154.380623   164.503835\n",
      "2023-06-02  150.126702   147.842040   157.521057\n",
      "2023-06-03  136.720868   131.999045   141.257660\n",
      "2023-06-04  115.790545   110.261882   118.417427\n",
      "2023-06-05  136.155311   131.372863   140.285499\n",
      "2023-06-06  147.067404   144.441834   153.764168\n",
      "2023-06-07  158.375612   155.095576   165.460412\n",
      "2023-06-08  156.883055   153.372913   164.172953\n",
      "2023-06-09  150.357190   148.257829   160.703553\n",
      "2023-06-10  142.503815   134.308324   145.714845\n",
      "2023-06-11  113.757639   109.758064   119.994012\n",
      "2023-06-12  141.753752   132.562102   144.029083\n",
      "2023-06-13  151.115195   147.825910   160.045315\n",
      "2023-06-14  158.493686   155.092864   165.535867\n",
      "2023-06-15  157.222961   154.399088   164.326156\n",
      "2023-06-16  150.750451   149.291289   160.766481\n",
      "2023-06-17  145.029739   137.487554   153.003189\n",
      "2023-06-18  112.669461   108.495924   120.865863\n",
      "2023-06-19  144.832870   134.454248   148.496355\n",
      "2023-06-20  152.577169   150.030054   163.190507\n",
      "2023-06-21  158.493686   155.427355   165.236577\n",
      "2023-06-22  157.222961   153.553850   165.049208\n",
      "2023-06-23  152.635717   150.010163   162.982647\n",
      "2023-06-24  148.514315   139.730409   156.025357\n",
      "2023-06-25  112.342070   109.294249   124.659220\n",
      "2023-06-26  150.109137   137.588477   157.031375\n",
      "2023-06-27  152.805923   152.442599   163.929789\n",
      "2023-06-28  158.615999   155.292765   165.509526\n",
      "2023-06-29  157.244901   153.504183   165.096909\n"
     ]
    }
   ],
   "source": [
    "# Future forecast with intervals\n",
    "future_intervals = fit_rf.predict(future_data, type=\"pred_int\")\n",
    "\n",
    "print(\"Future Forecast with 90% Prediction Intervals:\")\n",
    "print(future_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## Recursive Forecasting Key Takeaways:\n",
    "\n",
    "### 1. Base Model Selection\n",
    "- **Linear Regression**: Fast, interpretable, works well with linear autocorrelation\n",
    "- **Random Forest**: Captures non-linear patterns, provides feature importances\n",
    "- **Any sklearn model**: Can use any regression model that fits sklearn API\n",
    "\n",
    "### 2. Lag Configuration\n",
    "- **Integer lags** (`lags=7`): Uses all lags from 1 to n\n",
    "- **Specific lags** (`lags=[1, 7, 14]`): Use only certain lags\n",
    "- **Choose based on domain knowledge**: Weekly patterns → use lag 7, monthly → use lag 30\n",
    "\n",
    "### 3. Differentiation\n",
    "- Use `differentiation=1` for data with trends\n",
    "- Makes non-stationary series stationary\n",
    "- Can improve forecast accuracy\n",
    "\n",
    "### 4. Prediction Intervals\n",
    "- Use `type=\"pred_int\"` for uncertainty estimates\n",
    "- Based on in-sample residuals\n",
    "- Important for decision-making under uncertainty\n",
    "\n",
    "### 5. Three-DataFrame Output\n",
    "- **Outputs**: Train and test predictions with residuals\n",
    "- **Coefficients**: Model parameters or feature importances\n",
    "- **Stats**: Performance metrics (RMSE, MAE, R²)\n",
    "\n",
    "## When to Use Recursive Forecasting:\n",
    "\n",
    "✅ **Good for:**\n",
    "- Short to medium-term forecasts (1-90 days)\n",
    "- Data with strong autocorrelation\n",
    "- When you want to use ML models for time series\n",
    "- When you need non-linear relationships\n",
    "\n",
    "❌ **Consider alternatives for:**\n",
    "- Very long-term forecasts (error compounds)\n",
    "- Data with complex seasonality (use Prophet/ARIMA)\n",
    "- When you have many exogenous variables\n",
    "- When interpretability is paramount\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **Try different base models**: XGBoost, LightGBM, etc.\n",
    "2. **Experiment with lag configurations**: Find optimal lags for your data\n",
    "3. **Use with WorkflowSet**: Compare multiple recursive configurations\n",
    "4. **Add exogenous variables**: Include external predictors alongside lags\n",
    "5. **Cross-validation**: Use time series splits for robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
