{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 28: Refinery Production Forecasting with WorkflowSet and Diversity Maintenance\n",
    "\n",
    "This notebook demonstrates **diversity maintenance** in genetic algorithms to prevent premature convergence and explore alternative feature subsets.\n",
    "\n",
    "**Dataset**: JODI refinery production data (60+ countries, 2002-2024)\n",
    "\n",
    "**Key Techniques**:\n",
    "- Diversity measurement via Hamming distance\n",
    "- Fitness sharing to maintain population diversity\n",
    "- Comparison of different diversity thresholds\n",
    "- WorkflowSet for systematic threshold comparison\n",
    "- Cross-validation with diversity-aware GA\n",
    "- **Enhancement demonstrated**: Diversity maintenance for robust feature selection\n",
    "\n",
    "**Diversity Maintenance Benefits**:\n",
    "- Prevents premature convergence to local optima\n",
    "- Explores broader solution space\n",
    "- Finds alternative feature subsets\n",
    "- More robust to initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from py_recipes import recipe\n",
    "from py_recipes.steps import (\n",
    "    step_select_genetic_algorithm,\n",
    "    step_normalize,\n",
    "    step_mutate\n",
    ")\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, rand_forest\n",
    "from py_yardstick import rmse, mae, r_squared, metric_set\n",
    "from py_rsample import time_series_cv\n",
    "from py_workflowsets import WorkflowSet\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load refinery production data\n",
    "data = pd.read_csv('../_md/__data/jodi_refinery_production_data.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nCountries: {len(data['country'].unique())} countries\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"\\nMissing values:\\n{data.isnull().sum()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create time series features: lags, rolling statistics, temporal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select a single country for analysis\n# Available countries include 'United States of America' (not 'USA')\ncountry = 'United States of America'\ncountry_data = data[data['country'] == country].copy()\ncountry_data = country_data.sort_values('date').reset_index(drop=True)\n\nprint(f\"Country: {country}\")\nprint(f\"Data points: {len(country_data)}\")\nprint(f\"Date range: {country_data['date'].min()} to {country_data['date'].max()}\")\n\n# Use 'value' column as target (refinery production)\ntarget_col = 'value'\nprint(f\"\\nTarget variable: {target_col}\")\nprint(f\"Available columns: {list(country_data.columns)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (1, 3, 6, 12 months)\n",
    "for lag in [1, 3, 6, 12]:\n",
    "    country_data[f'{target_col}_lag_{lag}'] = country_data[target_col].shift(lag)\n",
    "\n",
    "# Create rolling statistics (3, 6, 12 months)\n",
    "for window in [3, 6, 12]:\n",
    "    country_data[f'{target_col}_ma_{window}'] = country_data[target_col].rolling(\n",
    "        window=window, min_periods=1).mean()\n",
    "    country_data[f'{target_col}_std_{window}'] = country_data[target_col].rolling(\n",
    "        window=window, min_periods=1).std()\n",
    "\n",
    "# Create momentum features (% change)\n",
    "for period in [1, 3, 6, 12]:\n",
    "    country_data[f'{target_col}_pct_change_{period}'] = country_data[target_col].pct_change(period)\n",
    "\n",
    "# Temporal features\n",
    "country_data['month'] = country_data['date'].dt.month\n",
    "country_data['quarter'] = country_data['date'].dt.quarter\n",
    "country_data['year'] = country_data['date'].dt.year\n",
    "country_data['month_sin'] = np.sin(2 * np.pi * country_data['month'] / 12)\n",
    "country_data['month_cos'] = np.cos(2 * np.pi * country_data['month'] / 12)\n",
    "\n",
    "# Drop rows with NaN\n",
    "country_data = country_data.dropna()\n",
    "\n",
    "print(f\"\\nAfter feature engineering: {country_data.shape}\")\n",
    "print(f\"Features: {[c for c in country_data.columns if c not in ['date', 'country', target_col]]}\")\n",
    "print(f\"Total features: {len([c for c in country_data.columns if c not in ['date', 'country', target_col]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20)\n",
    "split_idx = int(len(country_data) * 0.8)\n",
    "train_data = country_data.iloc[:split_idx].copy()\n",
    "test_data = country_data.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {train_data.shape[0]} rows, {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "print(f\"Test: {test_data.shape[0]} rows, {test_data['date'].min()} to {test_data['date'].max()}\")\n",
    "\n",
    "# Remove date and country columns\n",
    "train = train_data.drop(['date', 'country'], axis=1).copy()\n",
    "test = test_data.drop(['date', 'country'], axis=1).copy()\n",
    "\n",
    "print(f\"\\nTraining features: {train.shape[1] - 1} (target: {target_col})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Multiple Diversity Configurations\n",
    "\n",
    "Compare:\n",
    "1. **Standard GA** (no diversity maintenance)\n",
    "2. **Diversity threshold = 0.2** (low threshold - triggers often)\n",
    "3. **Diversity threshold = 0.3** (moderate)\n",
    "4. **Diversity threshold = 0.4** (moderate-high)\n",
    "5. **Diversity threshold = 0.5** (high threshold - triggers rarely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: All features\n",
    "rec_all = recipe(train).step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Standard GA (no diversity maintenance)\n",
    "rec_ga_standard = (recipe(train)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_select_genetic_algorithm(\n",
    "        outcome=target_col,\n",
    "        model=linear_reg(),\n",
    "        metric='rmse',\n",
    "        top_n=10,\n",
    "        population_size=30,\n",
    "        generations=30,\n",
    "        cv_folds=3,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Diversity maintenance with different thresholds\n",
    "diversity_thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "diversity_recipes = {}\n",
    "\n",
    "for threshold in diversity_thresholds:\n",
    "    rec = (recipe(train)\n",
    "        .step_normalize(all_numeric_predictors())\n",
    "        .step_select_genetic_algorithm(\n",
    "            outcome=target_col,\n",
    "            model=linear_reg(),\n",
    "            metric='rmse',\n",
    "            top_n=10,\n",
    "            maintain_diversity=True,\n",
    "            diversity_threshold=threshold,\n",
    "            population_size=30,\n",
    "            generations=30,\n",
    "            cv_folds=3,\n",
    "            random_state=42\n",
    "        )\n",
    "    )\n",
    "    diversity_recipes[f'diversity_{int(threshold*10)}'] = rec\n",
    "\n",
    "# Combine all recipes\n",
    "recipes = {\n",
    "    'all_features': rec_all,\n",
    "    'ga_standard': rec_ga_standard,\n",
    "    **diversity_recipes\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(recipes)} preprocessing strategies\")\n",
    "for name in recipes.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create WorkflowSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use linear regression\n",
    "models = {'linear_reg': linear_reg()}\n",
    "\n",
    "# Create WorkflowSet\n",
    "wf_set = WorkflowSet.from_cross(\n",
    "    preproc=recipes,\n",
    "    models=models,\n",
    "    ids=list(recipes.keys())\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated WorkflowSet with {len(wf_set.workflows)} workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV splits\n",
    "n_train = len(train)\n",
    "initial_size = int(n_train * 0.6)\n",
    "assess_size = int(n_train * 0.1)\n",
    "\n",
    "cv_folds = time_series_cv(\n",
    "    train_data,\n",
    "    date_column='date',\n",
    "    initial=initial_size,\n",
    "    assess=assess_size,\n",
    "    skip=assess_size,\n",
    "    cumulative=True\n",
    ")\n",
    "\n",
    "print(f\"Created {cv_folds.n_splits} CV folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate All Workflows\n",
    "\n",
    "**Note**: This will take several minutes as we're running GAs with 30 generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metrics = metric_set(rmse, mae, r_squared)\n",
    "\n",
    "# Fit resamples\n",
    "print(\"Fitting all workflows across CV folds...\")\n",
    "print(f\"Total fits: {len(wf_set.workflows)} workflows × {cv_folds.n_splits} folds = {len(wf_set.workflows) * cv_folds.n_splits}\")\n",
    "print(\"\\nThis may take 10-15 minutes...\\n\")\n",
    "\n",
    "wf_results = wf_set.fit_resamples(\n",
    "    resamples=cv_folds,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "print(\"\\n✓ CV evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Collect and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metrics\n",
    "cv_metrics = wf_results.collect_metrics()\n",
    "\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(cv_metrics.to_string(index=False))\n",
    "\n",
    "# Rank by RMSE\n",
    "ranked = wf_results.rank_results('rmse', n=10)\n",
    "print(\"\\n=== Ranked Workflows (by RMSE) ===\")\n",
    "print(ranked[['wflow_id', 'rmse', 'mae', 'rsq', 'rank']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization: Diversity Threshold Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autoplot\n",
    "fig = wf_results.autoplot('rmse')\n",
    "fig.update_layout(height=600, title='Diversity Threshold Comparison: RMSE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sorted_metrics = cv_metrics.sort_values('rmse')\n",
    "labels = sorted_metrics['wflow_id'].str.replace('_linear_reg', '').str.replace('_', ' ').str.title()\n",
    "\n",
    "# Color coding\n",
    "colors = []\n",
    "for wf_id in sorted_metrics['wflow_id']:\n",
    "    if 'diversity' in wf_id:\n",
    "        colors.append('forestgreen')\n",
    "    elif 'ga_standard' in wf_id:\n",
    "        colors.append('orange')\n",
    "    else:\n",
    "        colors.append('lightgray')\n",
    "\n",
    "bars = ax.barh(range(len(labels)), sorted_metrics['rmse'], color=colors, alpha=0.8)\n",
    "ax.set_yticks(range(len(labels)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('RMSE (lower is better)', fontsize=11)\n",
    "ax.set_title('Feature Selection Strategy Comparison: RMSE', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, sorted_metrics['rmse'])):\n",
    "    ax.text(val, bar.get_y() + bar.get_height()/2, f'{val:.2f}', \n",
    "            ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgray', alpha=0.8, label='Baseline (All Features)'),\n",
    "    Patch(facecolor='orange', alpha=0.8, label='Standard GA (No Diversity)'),\n",
    "    Patch(facecolor='forestgreen', alpha=0.8, label='GA with Diversity Maintenance')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('production_diversity_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as: production_diversity_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inspect Diversity History\n",
    "\n",
    "Fit all GA variants on full training data to examine diversity evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all GA-based workflows\n",
    "diversity_analysis = {}\n",
    "\n",
    "for wf_id in wf_set.workflows.keys():\n",
    "    if 'ga_' in wf_id or 'diversity' in wf_id:\n",
    "        print(f\"\\nFitting: {wf_id}\")\n",
    "        \n",
    "        wf = wf_set[wf_id]\n",
    "        fit = wf.fit(train)\n",
    "        \n",
    "        # Get prepared recipe\n",
    "        prepped = fit.extract_preprocessor()\n",
    "        \n",
    "        # Find GA step\n",
    "        ga_step = None\n",
    "        for step in prepped.prepared_steps:\n",
    "            if hasattr(step, '_selected_features'):\n",
    "                ga_step = step\n",
    "                break\n",
    "        \n",
    "        if ga_step is not None:\n",
    "            diversity_analysis[wf_id] = {\n",
    "                'selected_features': ga_step._selected_features,\n",
    "                'n_features': len(ga_step._selected_features),\n",
    "                'converged': ga_step._converged if hasattr(ga_step, '_converged') else None,\n",
    "                'n_generations': ga_step._n_generations if hasattr(ga_step, '_n_generations') else None,\n",
    "                'diversity_history': ga_step._diversity_history if hasattr(ga_step, '_diversity_history') else None\n",
    "            }\n",
    "\n",
    "print(\"\\n✓ Diversity analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Diversity Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot diversity over generations\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for wf_id, analysis in diversity_analysis.items():\n",
    "    if analysis['diversity_history'] is not None:\n",
    "        label = wf_id.replace('_linear_reg', '').replace('_', ' ').replace('diversity ', 'thresh=')\n",
    "        ax.plot(analysis['diversity_history'], marker='o', label=label, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Generation', fontsize=11)\n",
    "ax.set_ylabel('Population Diversity', fontsize=11)\n",
    "ax.set_title('Diversity Evolution Over Generations', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Add threshold lines\n",
    "for threshold in diversity_thresholds:\n",
    "    ax.axhline(y=threshold, color='red', linestyle='--', alpha=0.3, linewidth=1)\n",
    "    ax.text(0, threshold, f'  {threshold}', color='red', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('production_diversity_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as: production_diversity_evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Stability Analysis\n",
    "\n",
    "Compare which features were selected by each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature selection matrix\n",
    "all_features = set()\n",
    "for analysis in diversity_analysis.values():\n",
    "    all_features.update(analysis['selected_features'])\n",
    "\n",
    "all_features = sorted(all_features)\n",
    "\n",
    "feature_matrix = pd.DataFrame(0, index=all_features, \n",
    "                               columns=[wf_id.replace('_linear_reg', '') \n",
    "                                        for wf_id in diversity_analysis.keys()])\n",
    "\n",
    "for wf_id, analysis in diversity_analysis.items():\n",
    "    col_name = wf_id.replace('_linear_reg', '')\n",
    "    for feat in analysis['selected_features']:\n",
    "        feature_matrix.loc[feat, col_name] = 1\n",
    "\n",
    "# Calculate feature selection frequency\n",
    "feature_matrix['total'] = feature_matrix.sum(axis=1)\n",
    "feature_matrix = feature_matrix.sort_values('total', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Selection Matrix ===\")\n",
    "print(\"(1 = selected, 0 = not selected)\")\n",
    "print(feature_matrix)\n",
    "\n",
    "# Identify stable features (selected by all or most configurations)\n",
    "n_configs = len(diversity_analysis)\n",
    "stable_features = feature_matrix[feature_matrix['total'] >= n_configs * 0.8].index.tolist()\n",
    "\n",
    "print(f\"\\n=== Stable Features (selected by ≥80% of configurations) ===\")\n",
    "for feat in stable_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Select Best Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best workflow\n",
    "best_wf_id = ranked.iloc[0]['wflow_id']\n",
    "print(f\"Best workflow: {best_wf_id}\")\n",
    "print(f\"CV RMSE: {ranked.iloc[0]['rmse']:.2f}\")\n",
    "\n",
    "# Fit on full training data\n",
    "best_wf = wf_set[best_wf_id]\n",
    "best_fit = best_wf.fit(train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_eval = best_fit.evaluate(test)\n",
    "outputs, coeffs, stats = test_eval.extract_outputs()\n",
    "\n",
    "print(f\"\\n=== Test Set Performance ===\")\n",
    "test_stats = stats[stats['split'] == 'test']\n",
    "print(f\"RMSE: {test_stats['rmse'].values[0]:.2f}\")\n",
    "print(f\"MAE: {test_stats['mae'].values[0]:.2f}\")\n",
    "print(f\"R²: {test_stats['rsq'].values[0]:.4f}\")\n",
    "\n",
    "# Show selected features\n",
    "if best_wf_id in diversity_analysis:\n",
    "    print(f\"\\n=== Selected Features ===\")\n",
    "    analysis = diversity_analysis[best_wf_id]\n",
    "    print(f\"Number of features: {analysis['n_features']}\")\n",
    "    print(f\"\\nFeatures:\")\n",
    "    for feat in analysis['selected_features']:\n",
    "        stable_marker = '★' if feat in stable_features else ' '\n",
    "        print(f\"  {stable_marker} {feat}\")\n",
    "    print(\"\\n★ = stable feature (selected by ≥80% of configurations)\")\n",
    "    \n",
    "    if analysis['diversity_history'] is not None:\n",
    "        print(f\"\\n=== Diversity Statistics ===\")\n",
    "        div_hist = analysis['diversity_history']\n",
    "        print(f\"Initial diversity: {div_hist[0]:.3f}\")\n",
    "        print(f\"Final diversity: {div_hist[-1]:.3f}\")\n",
    "        print(f\"Mean diversity: {np.mean(div_hist):.3f}\")\n",
    "        print(f\"Min diversity: {np.min(div_hist):.3f}\")\n",
    "        print(f\"Max diversity: {np.max(div_hist):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Comprehensive Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "comparison_data = []\n",
    "\n",
    "for wf_id in wf_set.workflows.keys():\n",
    "    # Get CV performance\n",
    "    cv_perf = cv_metrics[cv_metrics['wflow_id'] == wf_id].iloc[0]\n",
    "    \n",
    "    # Get test performance\n",
    "    wf = wf_set[wf_id]\n",
    "    fit = wf.fit(train)\n",
    "    test_eval = fit.evaluate(test)\n",
    "    _, _, test_stats = test_eval.extract_outputs()\n",
    "    test_perf = test_stats[test_stats['split'] == 'test'].iloc[0]\n",
    "    \n",
    "    # Get feature count\n",
    "    if wf_id in diversity_analysis:\n",
    "        n_features = diversity_analysis[wf_id]['n_features']\n",
    "        n_stable = sum(1 for f in diversity_analysis[wf_id]['selected_features'] if f in stable_features)\n",
    "        \n",
    "        # Get diversity stats\n",
    "        if diversity_analysis[wf_id]['diversity_history'] is not None:\n",
    "            div_mean = np.mean(diversity_analysis[wf_id]['diversity_history'])\n",
    "            div_final = diversity_analysis[wf_id]['diversity_history'][-1]\n",
    "        else:\n",
    "            div_mean, div_final = None, None\n",
    "    else:\n",
    "        n_features = len([c for c in train.columns if c != target_col])\n",
    "        n_stable = None\n",
    "        div_mean, div_final = None, None\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Configuration': wf_id.replace('_linear_reg', ''),\n",
    "        'N Features': n_features,\n",
    "        'N Stable': n_stable,\n",
    "        'CV RMSE': cv_perf['rmse'],\n",
    "        'Test RMSE': test_perf['rmse'],\n",
    "        'Test R²': test_perf['rsq'],\n",
    "        'Mean Diversity': div_mean,\n",
    "        'Final Diversity': div_final\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).sort_values('Test RMSE')\n",
    "print(\"\\n=== Comprehensive Comparison ===\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Key Takeaways\n",
    "\n",
    "### Diversity Maintenance Benefits:\n",
    "1. **Prevents Premature Convergence**: Maintains exploration throughout evolution\n",
    "2. **Alternative Solutions**: Finds different feature subsets with similar performance\n",
    "3. **Robustness**: Less sensitive to initialization and local optima\n",
    "4. **Feature Stability**: Helps identify truly important features vs. noise\n",
    "\n",
    "### Threshold Selection:\n",
    "- **Low (0.2-0.3)**: Maintains high diversity, slower convergence, explores more\n",
    "- **Moderate (0.3-0.4)**: Balanced exploration/exploitation (recommended)\n",
    "- **High (0.4-0.5)**: Less intervention, closer to standard GA\n",
    "\n",
    "### Diversity Evolution Patterns:\n",
    "1. Diversity naturally decreases as GA converges\n",
    "2. Fitness sharing activates when diversity drops below threshold\n",
    "3. Multiple activation cycles indicate thorough search\n",
    "4. Final diversity > 0.2 suggests healthy population variation\n",
    "\n",
    "### Feature Stability Insights:\n",
    "- Features selected consistently across thresholds are most reliable\n",
    "- Stable features should be prioritized in production models\n",
    "- Unstable features may be noise or marginally useful\n",
    "\n",
    "### Comparison with Standard GA:\n",
    "- Standard GA may converge faster but risk local optima\n",
    "- Diversity-maintained GA explores more thoroughly\n",
    "- Small performance difference can indicate local optimum in standard GA\n",
    "\n",
    "### WorkflowSet Advantages:\n",
    "- Systematic threshold comparison\n",
    "- Robust performance estimation via CV\n",
    "- Easy identification of optimal diversity settings\n",
    "\n",
    "### Production Recommendations:\n",
    "1. Use diversity maintenance for complex problems with many features\n",
    "2. Start with threshold 0.3-0.4 for most applications\n",
    "3. Monitor diversity history to verify adequate exploration\n",
    "4. Focus on stable features for production deployment\n",
    "5. Run multiple diversity thresholds to identify feature stability\n",
    "6. Use longer runs (40+ generations) for complex fitness landscapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "py-tidymodels2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}