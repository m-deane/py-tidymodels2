{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regression Models in py-tidymodels\n",
    "\n",
    "This notebook demonstrates three advanced regression techniques:\n",
    "\n",
    "1. **MARS (Multivariate Adaptive Regression Splines)** - Automatic non-linearity detection\n",
    "2. **Poisson Regression** - For count data and rare events\n",
    "3. **GAM (Generalized Additive Models)** - Flexible non-parametric relationships\n",
    "\n",
    "Each model has unique strengths for different data patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from py_parsnip import mars, poisson_reg, gen_additive_mod\n",
    "from py_yardstick import rmse, rsq\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MARS - Multivariate Adaptive Regression Splines\n",
    "\n",
    "MARS is a non-parametric regression technique that:\n",
    "- Automatically detects non-linear relationships\n",
    "- Uses piecewise linear basis functions (hinge functions)\n",
    "- Can model interactions between predictors\n",
    "- Performs automatic feature selection\n",
    "\n",
    "**Key Parameters:**\n",
    "- `num_terms`: Maximum number of basis functions (default: unlimited)\n",
    "- `prod_degree`: Maximum interaction degree (1=additive, 2=pairwise interactions)\n",
    "- `prune_method`: How to prune the model (\"backward\", \"none\", \"exhaustive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-linear data with quadratic and sinusoidal patterns\n",
    "x = np.linspace(0, 10, 60)\n",
    "y_mars = x**2 + np.sin(x) * 5 + np.random.normal(0, 3, 60)\n",
    "data_mars = pd.DataFrame({\"y\": y_mars, \"x\": x})\n",
    "\n",
    "# Split into train/test\n",
    "train_mars = data_mars.iloc[:45]\n",
    "test_mars = data_mars.iloc[45:]\n",
    "\n",
    "print(f\"Training data: {train_mars.shape[0]} observations\")\n",
    "print(f\"Test data: {test_mars.shape[0]} observations\")\n",
    "print(f\"\\nData preview:\")\n",
    "print(train_mars.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the non-linear data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(train_mars[\"x\"], train_mars[\"y\"], label=\"Training data\", alpha=0.6)\n",
    "plt.scatter(test_mars[\"x\"], test_mars[\"y\"], label=\"Test data\", alpha=0.6, color=\"orange\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Non-linear Data: Quadratic + Sinusoidal Pattern\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MARS model with 15 terms and pairwise interactions\n",
    "print(\"Fitting MARS model with 15 terms and pairwise interactions...\")\n",
    "spec_mars = mars(num_terms=15, prod_degree=2)\n",
    "fit_mars = spec_mars.fit(train_mars, \"y ~ x\")\n",
    "\n",
    "print(\"\\nModel fitted successfully!\")\n",
    "print(f\"Engine: {fit_mars.spec.engine}\")\n",
    "print(f\"Model type: {fit_mars.spec.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred_mars = fit_mars.predict(test_mars)\n",
    "print(f\"Predictions shape: {pred_mars.shape}\")\n",
    "print(f\"\\nFirst 5 predictions:\")\n",
    "print(pred_mars.head())\n",
    "\n",
    "# Calculate test set metrics\n",
    "test_mars_with_pred = test_mars.copy()\n",
    "test_mars_with_pred[\".pred\"] = pred_mars[\".pred\"].values\n",
    "\n",
    "test_rmse = rmse(test_mars_with_pred, \"y\", \".pred\")\n",
    "test_rsq = rsq(test_mars_with_pred, \"y\", \".pred\")\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  RMSE: {test_rmse['.estimate'].iloc[0]:.4f}\")\n",
    "print(f\"  R-squared: {test_rsq['.estimate'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model details\n",
    "outputs_mars, basis_funcs, stats_mars = fit_mars.extract_outputs()\n",
    "\n",
    "print(f\"Model used {len(basis_funcs)} basis functions\")\n",
    "print(f\"\\nBasis functions:\")\n",
    "print(basis_funcs[[\"variable\", \"coefficient\"]].head(10))\n",
    "\n",
    "print(f\"\\nModel statistics:\")\n",
    "print(stats_mars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MARS predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training fit\n",
    "plt.subplot(1, 2, 1)\n",
    "train_outputs = outputs_mars[outputs_mars[\"split\"] == \"train\"]\n",
    "plt.scatter(train_outputs[\"x\"], train_outputs[\"y\"], label=\"Actuals\", alpha=0.6)\n",
    "plt.plot(train_outputs[\"x\"], train_outputs[\".pred\"], label=\"MARS Fit\", color=\"red\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"MARS: Training Fit\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot test predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_mars[\"x\"], test_mars[\"y\"], label=\"Actuals\", alpha=0.6, color=\"orange\")\n",
    "plt.plot(test_mars[\"x\"], pred_mars[\".pred\"], label=\"MARS Predictions\", color=\"red\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"MARS: Test Predictions (RMSE={test_rmse['.estimate'].iloc[0]:.2f})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Poisson Regression - For Count Data\n",
    "\n",
    "Poisson regression is designed for modeling count outcomes:\n",
    "- Uses a log link function: log(E[Y]) = β₀ + β₁X₁ + β₂X₂ + ...\n",
    "- Ideal for rare events, event counts, non-negative integers\n",
    "- Assumes variance = mean (can be relaxed with quasi-Poisson)\n",
    "\n",
    "**Common Applications:**\n",
    "- Number of website visits per day\n",
    "- Number of defects in manufacturing\n",
    "- Number of insurance claims\n",
    "- Epidemiology: disease counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count data with two predictors\n",
    "x1_pois = np.random.uniform(0, 5, 50)\n",
    "x2_pois = np.random.uniform(0, 3, 50)\n",
    "lambda_true = np.exp(0.3 + 0.4 * x1_pois + 0.5 * x2_pois)\n",
    "counts = np.random.poisson(lambda_true)\n",
    "data_pois = pd.DataFrame({\"count\": counts, \"x1\": x1_pois, \"x2\": x2_pois})\n",
    "\n",
    "# Split into train/test\n",
    "train_pois = data_pois.iloc[:35]\n",
    "test_pois = data_pois.iloc[35:]\n",
    "\n",
    "print(f\"Training data: {train_pois.shape[0]} observations\")\n",
    "print(f\"Test data: {test_pois.shape[0]} observations\")\n",
    "print(f\"\\nCount distribution in training data:\")\n",
    "print(train_pois[\"count\"].describe())\n",
    "print(f\"\\nData preview:\")\n",
    "print(train_pois.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the count data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Count distribution\n",
    "axes[0].hist(train_pois[\"count\"], bins=15, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Count\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Distribution of Count Data\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 3D scatter plot projection\n",
    "scatter = axes[1].scatter(train_pois[\"x1\"], train_pois[\"x2\"], c=train_pois[\"count\"], \n",
    "                          cmap=\"viridis\", s=100, alpha=0.6, edgecolors=\"black\")\n",
    "axes[1].set_xlabel(\"x1\")\n",
    "axes[1].set_ylabel(\"x2\")\n",
    "axes[1].set_title(\"Count as Function of x1 and x2\")\n",
    "plt.colorbar(scatter, ax=axes[1], label=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Poisson GLM\n",
    "print(\"Fitting Poisson GLM...\")\n",
    "spec_pois = poisson_reg()\n",
    "fit_pois = spec_pois.fit(train_pois, \"count ~ x1 + x2\")\n",
    "\n",
    "print(\"\\nModel fitted successfully!\")\n",
    "print(f\"Engine: {fit_pois.spec.engine}\")\n",
    "print(f\"Model type: {fit_pois.spec.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with confidence intervals\n",
    "pred_pois = fit_pois.predict(test_pois, type=\"conf_int\")\n",
    "print(f\"Predictions with confidence intervals:\")\n",
    "print(pred_pois.head(10))\n",
    "\n",
    "# Calculate test set metrics (using point predictions)\n",
    "pred_pois_numeric = fit_pois.predict(test_pois, type=\"numeric\")\n",
    "test_pois_with_pred = test_pois.copy()\n",
    "test_pois_with_pred[\".pred\"] = pred_pois_numeric[\".pred\"].values\n",
    "\n",
    "test_rmse_pois = rmse(test_pois_with_pred, \"count\", \".pred\")\n",
    "print(f\"\\nTest Set RMSE: {test_rmse_pois['.estimate'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model details\n",
    "outputs_pois, coefs_pois, stats_pois = fit_pois.extract_outputs()\n",
    "\n",
    "print(f\"Coefficients (with z-statistics):\")\n",
    "print(coefs_pois[[\"variable\", \"coefficient\", \"z_stat\", \"p_value\"]])\n",
    "\n",
    "print(f\"\\nModel statistics:\")\n",
    "print(stats_pois)\n",
    "\n",
    "# Interpret coefficients\n",
    "print(f\"\\nCoefficient interpretation:\")\n",
    "for idx, row in coefs_pois.iterrows():\n",
    "    if row[\"variable\"] != \"Intercept\":\n",
    "        effect = (np.exp(row[\"coefficient\"]) - 1) * 100\n",
    "        print(f\"  {row['variable']}: 1-unit increase → {effect:.1f}% change in expected count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Poisson predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Actual vs predicted\n",
    "axes[0].scatter(test_pois[\"count\"], pred_pois_numeric[\".pred\"], alpha=0.6, s=100)\n",
    "axes[0].plot([0, test_pois[\"count\"].max()], [0, test_pois[\"count\"].max()], \n",
    "             \"r--\", linewidth=2, label=\"Perfect predictions\")\n",
    "axes[0].set_xlabel(\"Actual Count\")\n",
    "axes[0].set_ylabel(\"Predicted Count\")\n",
    "axes[0].set_title(\"Poisson Regression: Actual vs Predicted\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = test_pois[\"count\"].values - pred_pois_numeric[\".pred\"].values\n",
    "axes[1].scatter(pred_pois_numeric[\".pred\"], residuals, alpha=0.6, s=100)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\", linewidth=2)\n",
    "axes[1].set_xlabel(\"Predicted Count\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Poisson Regression: Residual Plot\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generalized Additive Models (GAM)\n",
    "\n",
    "GAMs fit smooth non-parametric functions to each predictor:\n",
    "- E[Y] = β₀ + f₁(X₁) + f₂(X₂) + ... where f() are smooth functions\n",
    "- Automatically detects non-linear relationships\n",
    "- More interpretable than black-box ML models\n",
    "- Can include both smooth and linear terms\n",
    "\n",
    "**Key Parameters:**\n",
    "- `adjust_deg_free`: Degrees of freedom for smoothing (higher = more flexible)\n",
    "- `select_features`: Automatic feature selection (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with non-linear relationships\n",
    "x1_gam = np.linspace(0, 10, 50)\n",
    "x2_gam = np.linspace(0, 5, 50)\n",
    "y_gam = np.sin(x1_gam) * 10 + x2_gam**2 + np.random.normal(0, 2, 50)\n",
    "data_gam = pd.DataFrame({\"y\": y_gam, \"x1\": x1_gam, \"x2\": x2_gam})\n",
    "\n",
    "# Split into train/test\n",
    "train_gam = data_gam.iloc[:35]\n",
    "test_gam = data_gam.iloc[35:]\n",
    "\n",
    "print(f\"Training data: {train_gam.shape[0]} observations\")\n",
    "print(f\"Test data: {test_gam.shape[0]} observations\")\n",
    "print(f\"\\nData preview:\")\n",
    "print(train_gam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the non-linear relationships\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# y vs x1 (sinusoidal pattern)\n",
    "axes[0].scatter(train_gam[\"x1\"], train_gam[\"y\"], alpha=0.6)\n",
    "axes[0].set_xlabel(\"x1\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].set_title(\"Non-linear Relationship: y vs x1 (sinusoidal)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# y vs x2 (quadratic pattern)\n",
    "axes[1].scatter(train_gam[\"x2\"], train_gam[\"y\"], alpha=0.6, color=\"orange\")\n",
    "axes[1].set_xlabel(\"x2\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].set_title(\"Non-linear Relationship: y vs x2 (quadratic)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GAM with moderate smoothing (12 splines per feature)\n",
    "print(\"Fitting GAM with 12 splines per feature...\")\n",
    "spec_gam = gen_additive_mod(adjust_deg_free=12)\n",
    "fit_gam = spec_gam.fit(train_gam, \"y ~ x1 + x2\")\n",
    "\n",
    "print(\"\\nModel fitted successfully!\")\n",
    "print(f\"Engine: {fit_gam.spec.engine}\")\n",
    "print(f\"Model type: {fit_gam.spec.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred_gam = fit_gam.predict(test_gam)\n",
    "print(f\"Predictions shape: {pred_gam.shape}\")\n",
    "print(f\"\\nFirst 5 predictions:\")\n",
    "print(pred_gam.head())\n",
    "\n",
    "# Calculate test set metrics\n",
    "test_gam_with_pred = test_gam.copy()\n",
    "test_gam_with_pred[\".pred\"] = pred_gam[\".pred\"].values\n",
    "\n",
    "test_rmse_gam = rmse(test_gam_with_pred, \"y\", \".pred\")\n",
    "test_rsq_gam = rsq(test_gam_with_pred, \"y\", \".pred\")\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  RMSE: {test_rmse_gam['.estimate'].iloc[0]:.4f}\")\n",
    "print(f\"  R-squared: {test_rsq_gam['.estimate'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model details\n",
    "outputs_gam, partial_effects, stats_gam = fit_gam.extract_outputs()\n",
    "\n",
    "print(f\"Partial effects (feature contributions):\")\n",
    "print(partial_effects[[\"feature\", \"effect_range\", \"data_range\"]])\n",
    "\n",
    "print(f\"\\nModel statistics:\")\n",
    "print(stats_gam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GAM predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Predictions for x1\n",
    "train_outputs_gam = outputs_gam[outputs_gam[\"split\"] == \"train\"].sort_values(\"x1\")\n",
    "axes[0].scatter(train_outputs_gam[\"x1\"], train_outputs_gam[\"y\"], \n",
    "                label=\"Actuals\", alpha=0.6)\n",
    "axes[0].plot(train_outputs_gam[\"x1\"], train_outputs_gam[\".pred\"], \n",
    "             label=\"GAM Fit\", color=\"red\", linewidth=2)\n",
    "axes[0].set_xlabel(\"x1\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].set_title(\"GAM: Smooth Function for x1\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test predictions\n",
    "axes[1].scatter(test_gam[\"y\"], pred_gam[\".pred\"], alpha=0.6, s=100)\n",
    "axes[1].plot([test_gam[\"y\"].min(), test_gam[\"y\"].max()], \n",
    "             [test_gam[\"y\"].min(), test_gam[\"y\"].max()], \n",
    "             \"r--\", linewidth=2, label=\"Perfect predictions\")\n",
    "axes[1].set_xlabel(\"Actual y\")\n",
    "axes[1].set_ylabel(\"Predicted y\")\n",
    "axes[1].set_title(f\"GAM: Test Predictions (R²={test_rsq_gam['.estimate'].iloc[0]:.3f})\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Selection Guide\n",
    "\n",
    "### When to Use Each Model:\n",
    "\n",
    "#### MARS (Multivariate Adaptive Regression Splines)\n",
    "**Best for:**\n",
    "- Automatic non-linearity detection\n",
    "- Automatic interaction detection\n",
    "- When you don't know the functional form\n",
    "- Piecewise linear approximations are acceptable\n",
    "\n",
    "**Pros:**\n",
    "- Automatically finds knots and interactions\n",
    "- Built-in feature selection\n",
    "- Interpretable piecewise linear functions\n",
    "- Handles missing data well\n",
    "\n",
    "**Cons:**\n",
    "- Can overfit with too many terms\n",
    "- Less smooth than GAMs\n",
    "- Harder to interpret with many basis functions\n",
    "\n",
    "#### Poisson Regression\n",
    "**Best for:**\n",
    "- Count data (non-negative integers)\n",
    "- Rare events\n",
    "- When variance approximately equals mean\n",
    "- Epidemiology, quality control, website analytics\n",
    "\n",
    "**Pros:**\n",
    "- Specifically designed for count data\n",
    "- Interpretable coefficients (multiplicative effects)\n",
    "- Standard statistical inference (p-values, confidence intervals)\n",
    "- Handles zero counts naturally\n",
    "\n",
    "**Cons:**\n",
    "- Assumes mean = variance (can use quasi-Poisson if violated)\n",
    "- Limited to count outcomes\n",
    "- May not fit overdispersed data well\n",
    "\n",
    "#### GAM (Generalized Additive Model)\n",
    "**Best for:**\n",
    "- Smooth non-parametric relationships\n",
    "- When you need interpretable non-linear effects\n",
    "- Visualizing how each predictor affects outcome\n",
    "- When flexibility is needed but interpretability matters\n",
    "\n",
    "**Pros:**\n",
    "- Very flexible smooth functions\n",
    "- More interpretable than black-box ML\n",
    "- Can visualize partial effects\n",
    "- Works with different distributions (Gaussian, Poisson, etc.)\n",
    "\n",
    "**Cons:**\n",
    "- Doesn't capture interactions automatically\n",
    "- Can be slow with large datasets\n",
    "- Requires tuning smoothing parameters\n",
    "- Assumes additive structure\n",
    "\n",
    "### Quick Selection Guide:\n",
    "\n",
    "```\n",
    "Data Type: Count data → Use Poisson Regression\n",
    "\n",
    "Need smooth curves + interpretability → Use GAM\n",
    "\n",
    "Unknown functional form + want automatic interactions → Use MARS\n",
    "\n",
    "Need maximum flexibility + interactions → Use MARS or ensemble methods\n",
    "\n",
    "Need statistical inference (p-values) → Use Poisson or GAM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated three advanced regression techniques in py-tidymodels:\n",
    "\n",
    "1. **MARS** - Automatic non-linearity and interaction detection with piecewise linear functions\n",
    "2. **Poisson Regression** - Statistical modeling of count data with interpretable coefficients\n",
    "3. **GAM** - Flexible smooth non-parametric functions with interpretable partial effects\n",
    "\n",
    "All three models:\n",
    "- Follow the tidymodels workflow (spec → fit → predict)\n",
    "- Support the three-DataFrame output structure\n",
    "- Work with py_workflows for preprocessing\n",
    "- Can be tuned with py_tune\n",
    "- Provide comprehensive model diagnostics\n",
    "\n",
    "Choose the model that best matches your:\n",
    "- Data type (continuous vs count)\n",
    "- Need for interpretability\n",
    "- Type of non-linearity expected\n",
    "- Whether interactions are important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
