{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tuning: Simulated Annealing (tune_sim_anneal)\n",
    "\n",
    "This notebook demonstrates **simulated annealing** for hyperparameter optimization.\n",
    "\n",
    "## Key Benefits:\n",
    "- **Global optimization**: Escapes local optima via probabilistic acceptance\n",
    "- **Efficient exploration**: Focuses on promising regions over time\n",
    "- **Continuous spaces**: Excellent for continuous hyperparameters\n",
    "- **Fewer evaluations**: More efficient than grid search for large spaces\n",
    "\n",
    "## Simulated Annealing Algorithm:\n",
    "1. Start with random (or provided) initial configuration\n",
    "2. Generate neighbor by perturbing current parameters\n",
    "3. Accept better neighbors always\n",
    "4. Accept worse neighbors with probability exp(\u0394/T)\n",
    "5. Decrease temperature T over iterations (cooling)\n",
    "6. Stop after max iterations or no improvement\n",
    "\n",
    "## Temperature & Acceptance:\n",
    "- **High temperature**: Accept most moves (exploration)\n",
    "- **Low temperature**: Accept only improvements (exploitation)\n",
    "- **Cooling schedule**: Controls exploration \u2192 exploitation transition\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, boost_tree, svm_rbf\n",
    "from py_rsample import vfold_cv\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "from py_tune import (\n",
    "    tune, grid_regular, tune_grid,\n",
    "    tune_sim_anneal, control_sim_anneal\n",
    ")\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../_md/__data/preem.csv')\n",
    "# Convert and save date range before dropping\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "date_min, date_max = df['date'].min(), df['date'].max()\n",
    "df = df.drop(columns=['date'])  # Drop date to avoid patsy categorical issues\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {date_min} to {date_max}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "FORMULA = \"target ~ totaltar + mean_med_diesel_crack_input1_trade_month_lag2 + mean_nwe_hsfo_crack_trade_month_lag1 + mean_nwe_lsfo_crack_trade_month\"\n",
    "\n",
    "print(f\"Formula: {FORMULA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression with Regularization\n",
    "\n",
    "### 1.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net workflow (2D parameter space)\n",
    "wf_elasticnet = (\n",
    "    workflow()\n",
    "    .add_formula(FORMULA)\n",
    "    .add_model(\n",
    "        linear_reg(\n",
    "            penalty=tune(),   # L1/L2 regularization strength\n",
    "            mixture=tune()    # L1/L2 mixture (0=ridge, 1=lasso)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define parameter space\n",
    "param_info = {\n",
    "    'penalty': {'range': (0.001, 10.0), 'trans': 'log'},\n",
    "    'mixture': {'range': (0.0, 1.0)}  # No transformation\n",
    "}\n",
    "\n",
    "print(\"Parameter space:\")\n",
    "for param, info in param_info.items():\n",
    "    print(f\"  {param}: {info['range']} (trans: {info.get('trans', 'none')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV folds\n",
    "cv_folds = vfold_cv(df, v=5)\n",
    "print(f\"Created {len(cv_folds)} CV folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Baseline: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for comparison\n",
    "grid = grid_regular(param_info, levels=10)  # 100 combinations\n",
    "\n",
    "print(f\"Running grid search with {len(grid)} combinations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "grid_results = tune_grid(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    grid=grid,\n",
    "    metrics=metric_set(rmse, mae)\n",
    ")\n",
    "\n",
    "grid_time = time.time() - start_time\n",
    "grid_best_rmse = grid_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "\n",
    "print(f\"\u2713 Grid search: {grid_time:.1f}s, best RMSE: {grid_best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Simulated Annealing with Exponential Cooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure simulated annealing\n",
    "ctrl_exp = control_sim_anneal(\n",
    "    initial_temp=2.0,           # Starting temperature\n",
    "    cooling_schedule='exponential',  # T = T0 * rate^iteration\n",
    "    cooling_rate=0.95,          # Decay factor\n",
    "    max_iter=50,                # Maximum iterations\n",
    "    no_improve=15,              # Stop if no improvement for 15 iterations\n",
    "    restart_after=None,         # No restarts\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Simulated Annealing Configuration:\")\n",
    "print(f\"  Initial temperature: {ctrl_exp.initial_temp}\")\n",
    "print(f\"  Cooling schedule: {ctrl_exp.cooling_schedule}\")\n",
    "print(f\"  Cooling rate: {ctrl_exp.cooling_rate}\")\n",
    "print(f\"  Max iterations: {ctrl_exp.max_iter}\")\n",
    "print(f\"  Early stopping: {ctrl_exp.no_improve} iterations without improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulated annealing\n",
    "print(\"\\nRunning simulated annealing with exponential cooling...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "sa_exp_results = tune_sim_anneal(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse, mae),\n",
    "    control=ctrl_exp\n",
    ")\n",
    "\n",
    "sa_exp_time = time.time() - start_time\n",
    "print(f\"\\n\u2713 Simulated annealing complete in {sa_exp_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "sa_best_rmse = sa_exp_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "n_sa_evals = len(sa_exp_results.grid)\n",
    "n_grid_evals = len(grid)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: Grid Search vs Simulated Annealing\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nGrid search:\")\n",
    "print(f\"  Evaluations: {n_grid_evals}\")\n",
    "print(f\"  Time: {grid_time:.1f}s\")\n",
    "print(f\"  Best RMSE: {grid_best_rmse:.4f}\")\n",
    "print(f\"\\nSimulated Annealing:\")\n",
    "print(f\"  Evaluations: {n_sa_evals}\")\n",
    "print(f\"  Time: {sa_exp_time:.1f}s\")\n",
    "print(f\"  Best RMSE: {sa_best_rmse:.4f}\")\n",
    "print(f\"\\nEfficiency:\")\n",
    "print(f\"  Speedup: {grid_time / sa_exp_time:.2f}x\")\n",
    "print(f\"  Evaluation reduction: {(1 - n_sa_evals/n_grid_evals)*100:.1f}%\")\n",
    "print(f\"  Performance ratio: {sa_best_rmse / grid_best_rmse:.4f}\")\n",
    "\n",
    "if sa_best_rmse <= grid_best_rmse * 1.01:\n",
    "    print(\"\\n\u2713 SA found comparable or better solution with fewer evaluations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualize Search Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract search trajectory\n",
    "sa_metrics = sa_exp_results.metrics\n",
    "rmse_values = sa_metrics[sa_metrics['metric'] == 'rmse'].groupby('.config')['value'].mean()\n",
    "configs = [int(c.split('_')[1]) for c in rmse_values.index]\n",
    "\n",
    "# Plot convergence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE over iterations\n",
    "ax1.plot(configs, rmse_values.values, 'o-', alpha=0.6, label='Evaluated')\n",
    "ax1.plot(configs, np.minimum.accumulate(rmse_values.values), 'r-', linewidth=2, label='Best so far')\n",
    "ax1.axhline(grid_best_rmse, color='green', linestyle='--', label='Grid search best')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_title('Simulated Annealing Convergence')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter space exploration\n",
    "penalty_values = sa_exp_results.grid['penalty'].values\n",
    "mixture_values = sa_exp_results.grid['mixture'].values\n",
    "scatter = ax2.scatter(penalty_values, mixture_values, c=rmse_values.values, \n",
    "                     cmap='viridis', s=100, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Penalty (log scale)')\n",
    "ax2.set_ylabel('Mixture')\n",
    "ax2.set_title('Parameter Space Exploration')\n",
    "plt.colorbar(scatter, ax=ax2, label='RMSE')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Left plot: RMSE decreases over iterations\")\n",
    "print(\"\u2713 Right plot: Parameter space exploration (darker = better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Different Cooling Schedules\n",
    "\n",
    "### 2.1 Linear Cooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear cooling: T = T0 - rate * iteration\n",
    "ctrl_linear = control_sim_anneal(\n",
    "    initial_temp=2.0,\n",
    "    cooling_schedule='linear',\n",
    "    cooling_rate=0.04,  # Decrease by 0.04 each iteration\n",
    "    max_iter=50,\n",
    "    no_improve=15,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Running simulated annealing with linear cooling...\")\n",
    "start_time = time.time()\n",
    "\n",
    "sa_linear_results = tune_sim_anneal(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse),\n",
    "    control=ctrl_linear\n",
    ")\n",
    "\n",
    "sa_linear_time = time.time() - start_time\n",
    "print(f\"\u2713 Linear cooling: {sa_linear_time:.1f}s, {len(sa_linear_results.grid)} evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Logarithmic Cooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic cooling: T = T0 / (1 + rate * log(1 + iteration))\n",
    "ctrl_log = control_sim_anneal(\n",
    "    initial_temp=2.0,\n",
    "    cooling_schedule='logarithmic',\n",
    "    cooling_rate=0.5,\n",
    "    max_iter=50,\n",
    "    no_improve=15,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Running simulated annealing with logarithmic cooling...\")\n",
    "start_time = time.time()\n",
    "\n",
    "sa_log_results = tune_sim_anneal(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse),\n",
    "    control=ctrl_log\n",
    ")\n",
    "\n",
    "sa_log_time = time.time() - start_time\n",
    "print(f\"\u2713 Logarithmic cooling: {sa_log_time:.1f}s, {len(sa_log_results.grid)} evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Compare Cooling Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best RMSE for each schedule\n",
    "exp_best = sa_exp_results.select_best(metric=\"rmse\", maximize=False)\n",
    "linear_best = sa_linear_results.select_best(metric=\"rmse\", maximize=False)\n",
    "log_best = sa_log_results.select_best(metric=\"rmse\", maximize=False)\n",
    "\n",
    "exp_rmse = sa_exp_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "linear_rmse = sa_linear_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "log_rmse = sa_log_results.show_best(metric=\"rmse\", n=1, maximize=False)['mean'].values[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COOLING SCHEDULE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nExponential:  RMSE = {exp_rmse:.4f}, {len(sa_exp_results.grid):3d} evals, {sa_exp_time:5.1f}s\")\n",
    "print(f\"Linear:       RMSE = {linear_rmse:.4f}, {len(sa_linear_results.grid):3d} evals, {sa_linear_time:5.1f}s\")\n",
    "print(f\"Logarithmic:  RMSE = {log_rmse:.4f}, {len(sa_log_results.grid):3d} evals, {sa_log_time:5.1f}s\")\n",
    "\n",
    "print(\"\\nCharacteristics:\")\n",
    "print(\"  Exponential: Fast initial cooling, good for quick convergence\")\n",
    "print(\"  Linear: Steady cooling, balanced exploration/exploitation\")\n",
    "print(\"  Logarithmic: Slow cooling, thorough exploration (longer runs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost with Simulated Annealing\n",
    "\n",
    "Test on high-dimensional parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost workflow (4D parameter space)\n",
    "wf_xgb = (\n",
    "    workflow()\n",
    "    .add_formula(FORMULA)\n",
    "    .add_model(\n",
    "        boost_tree(\n",
    "            trees=tune(),\n",
    "            tree_depth=tune(),\n",
    "            learn_rate=tune(),\n",
    "            min_n=tune()\n",
    "        ).set_mode(\"regression\").set_engine(\"xgboost\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4D parameter space\n",
    "xgb_param_info = {\n",
    "    'trees': {'range': (50, 300), 'type': 'int'},\n",
    "    'tree_depth': {'range': (3, 10), 'type': 'int'},\n",
    "    'learn_rate': {'range': (0.001, 0.3), 'trans': 'log'},\n",
    "    'min_n': {'range': (2, 40), 'type': 'int'}\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameter space (4D):\")\n",
    "for param, info in xgb_param_info.items():\n",
    "    print(f\"  {param}: {info['range']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulated annealing on XGBoost\n",
    "xgb_ctrl = control_sim_anneal(\n",
    "    initial_temp=1.5,\n",
    "    cooling_schedule='exponential',\n",
    "    cooling_rate=0.93,\n",
    "    max_iter=40,\n",
    "    no_improve=12,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nRunning simulated annealing on XGBoost (4D)...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_sa_results = tune_sim_anneal(\n",
    "    wf_xgb,\n",
    "    resamples=cv_folds,\n",
    "    param_info=xgb_param_info,\n",
    "    metrics=metric_set(rmse, mae, r_squared),\n",
    "    control=xgb_ctrl\n",
    ")\n",
    "\n",
    "xgb_sa_time = time.time() - start_time\n",
    "print(f\"\\n\u2713 XGBoost SA complete in {xgb_sa_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best XGBoost configurations\n",
    "print(\"Top 5 XGBoost configurations:\")\n",
    "xgb_sa_results.show_best(metric=\"rmse\", n=5, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with grid search equivalence\n",
    "n_xgb_evals = len(xgb_sa_results.grid)\n",
    "equivalent_grid_size = 5 ** 4  # 5 levels for 4 parameters\n",
    "\n",
    "print(f\"\\nXGBoost efficiency:\")\n",
    "print(f\"  Simulated Annealing: {n_xgb_evals} evaluations\")\n",
    "print(f\"  Equivalent grid (5^4): {equivalent_grid_size} evaluations\")\n",
    "print(f\"  Reduction: {(1 - n_xgb_evals/equivalent_grid_size)*100:.1f}%\")\n",
    "print(f\"\\n\u2713 SA scales well to high-dimensional spaces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Features\n",
    "\n",
    "### 4.1 Restart Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated annealing with restarts\n",
    "ctrl_restart = control_sim_anneal(\n",
    "    initial_temp=2.0,\n",
    "    cooling_schedule='exponential',\n",
    "    cooling_rate=0.95,\n",
    "    max_iter=60,\n",
    "    no_improve=20,\n",
    "    restart_after=10,  # Restart from best after 10 iterations without improvement\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Running SA with restart mechanism...\\n\")\n",
    "\n",
    "sa_restart_results = tune_sim_anneal(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    metrics=metric_set(rmse),\n",
    "    control=ctrl_restart\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 SA with restarts allows escaping local optima\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Custom Initial Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from domain knowledge or prior results\n",
    "initial_point = {\n",
    "    'penalty': 1.0,  # Start with moderate regularization\n",
    "    'mixture': 0.5   # Start with equal L1/L2 mix\n",
    "}\n",
    "\n",
    "print(f\"Running SA from custom initial point: {initial_point}\\n\")\n",
    "\n",
    "sa_custom_results = tune_sim_anneal(\n",
    "    wf_elasticnet,\n",
    "    resamples=cv_folds,\n",
    "    param_info=param_info,\n",
    "    initial=initial_point,  # Provide starting point\n",
    "    metrics=metric_set(rmse),\n",
    "    control=control_sim_anneal(max_iter=30, verbose=False)\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Custom starting points can leverage domain knowledge\")\n",
    "print(\"\u2713 Useful for refinement after grid search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Best Practices\n",
    "\n",
    "### When to use Simulated Annealing:\n",
    "- \u2713 **Large continuous parameter spaces** (expensive to grid search)\n",
    "- \u2713 **High-dimensional** spaces (3+ parameters)\n",
    "- \u2713 **Non-convex** optimization landscapes (many local optima)\n",
    "- \u2713 **Budget-constrained** tuning (limited evaluations)\n",
    "\n",
    "### Cooling Schedule Selection:\n",
    "- **Exponential**: Fast convergence, good for most cases\n",
    "- **Linear**: Balanced, predictable behavior\n",
    "- **Logarithmic**: Thorough exploration, longer runs\n",
    "\n",
    "### Configuration Guidelines:\n",
    "\n",
    "**initial_temp**:\n",
    "- 1.0-2.0: Standard (moderate exploration)\n",
    "- 3.0-5.0: High (more exploration, escapes local optima)\n",
    "- 0.5-1.0: Low (less exploration, faster convergence)\n",
    "\n",
    "**cooling_rate**:\n",
    "- Exponential: 0.90-0.99 (higher = slower cooling)\n",
    "- Linear: 0.01-0.1 (larger = faster cooling)\n",
    "- Logarithmic: 0.1-1.0\n",
    "\n",
    "**max_iter**:\n",
    "- 30-50: Quick search\n",
    "- 50-100: Standard\n",
    "- 100+: Thorough search\n",
    "\n",
    "**restart_after**:\n",
    "- None: No restarts (faster)\n",
    "- 10-20: Moderate (escape local optima)\n",
    "- Used when landscape has many valleys\n",
    "\n",
    "### Expected Performance:\n",
    "- **2-10x faster** than grid search in high dimensions\n",
    "- **Finds near-optimal solutions** with fewer evaluations\n",
    "- **Stochastic**: Results vary between runs (set seed for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL SUMMARY: tune_sim_anneal()\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset: {df.shape[0]} observations\")\n",
    "print(f\"\\nElastic Net (2D space):\")\n",
    "print(f\"  Grid search: {n_grid_evals} evals, {grid_time:.1f}s, RMSE={grid_best_rmse:.4f}\")\n",
    "print(f\"  Simulated Annealing: {n_sa_evals} evals, {sa_exp_time:.1f}s, RMSE={sa_best_rmse:.4f}\")\n",
    "print(f\"  Speedup: {grid_time / sa_exp_time:.2f}x\")\n",
    "print(f\"\\nXGBoost (4D space):\")\n",
    "print(f\"  Simulated Annealing: {n_xgb_evals} evals vs {equivalent_grid_size} grid evals\")\n",
    "print(f\"  Reduction: {(1 - n_xgb_evals/equivalent_grid_size)*100:.0f}%\")\n",
    "print(f\"\\nKey advantages:\")\n",
    "print(\"  \u2713 Efficient for continuous parameter spaces\")\n",
    "print(\"  \u2713 Escapes local optima via probabilistic acceptance\")\n",
    "print(\"  \u2713 Scales to high-dimensional problems\")\n",
    "print(\"  \u2713 Flexible cooling schedules for different scenarios\")\n",
    "print(\"  \u2713 Can start from prior knowledge (warm start)\")\n",
    "print(\"\\n\u2713 Excellent alternative to exhaustive grid search\")\n",
    "print(\"\u2713 Combine with Bayesian optimization for best results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}