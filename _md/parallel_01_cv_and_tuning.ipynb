{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing Demo 1: Cross-Validation and Grid Search\n",
    "\n",
    "This notebook demonstrates parallel execution for:\n",
    "- `fit_resamples()` - Parallel CV fold evaluation\n",
    "- `tune_grid()` - Parallel grid search\n",
    "- CPU core warnings and validation\n",
    "- Performance comparisons (sequential vs parallel)\n",
    "\n",
    "**Key Features Demonstrated:**\n",
    "- ‚úÖ `n_jobs` parameter usage\n",
    "- ‚úÖ CPU warning system\n",
    "- ‚úÖ Progress tracking with `verbose=True`\n",
    "- ‚úÖ Speedup measurements\n",
    "- ‚úÖ Results consistency validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, rand_forest\n",
    "from py_rsample import vfold_cv, initial_split, training, testing\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "from py_tune import fit_resamples, tune_grid, grid_regular, tune\n",
    "from py_tune.parallel_utils import get_cpu_count, validate_n_jobs\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv('__data/preem.csv')\n",
    "df = raw_data.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "split = initial_split(df, prop=0.75, seed=123)\n",
    "train_data = training(split)\n",
    "test_data = testing(split)\n",
    "\n",
    "print(f\"Training set: {train_data.shape[0]} rows\")\n",
    "print(f\"Test set: {test_data.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula and metrics\n",
    "FORMULA = \"target ~ .\"\n",
    "metrics = metric_set(rmse, mae, r_squared)\n",
    "\n",
    "print(f\"Formula: {FORMULA}\")\n",
    "print(f\"Metrics: rmse, mae, r_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "cpu_count = get_cpu_count()\n",
    "print(f\"‚úì Detected {cpu_count} CPU cores\")\n",
    "print(f\"‚úì Joblib backend: loky (multiprocessing)\")\n",
    "print(f\"‚úì Platform: {import sys; sys.platform}\")\n",
    "print(f\"\\nThis system can efficiently run up to {cpu_count} parallel jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Parallel fit_resamples() Demonstration\n",
    "\n",
    "We'll compare sequential vs parallel execution for CV fold evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflow\n",
    "wf = workflow().add_formula(FORMULA).add_model(linear_reg())\n",
    "\n",
    "# Create 5-fold CV\n",
    "folds = vfold_cv(train_data, v=5, seed=123)\n",
    "\n",
    "print(f\"Workflow: {wf}\")\n",
    "print(f\"CV folds: {len(folds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Execution (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential execution\n",
    "print(\"Running SEQUENTIAL fit_resamples...\")\n",
    "start = time.time()\n",
    "results_seq = fit_resamples(\n",
    "    wf,\n",
    "    folds,\n",
    "    metrics=metrics,\n",
    "    n_jobs=1,  # Sequential\n",
    "    verbose=True\n",
    ")\n",
    "seq_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚úì Sequential execution completed in {seq_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sequential results\n",
    "metrics_seq = results_seq.collect_metrics()\n",
    "display(metrics_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution with 2 Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel execution with 2 cores\n",
    "print(\"Running PARALLEL fit_resamples (n_jobs=2)...\")\n",
    "start = time.time()\n",
    "results_par2 = fit_resamples(\n",
    "    wf,\n",
    "    folds,\n",
    "    metrics=metrics,\n",
    "    n_jobs=2,  # Use 2 cores\n",
    "    verbose=True\n",
    ")\n",
    "par2_time = time.time() - start\n",
    "\n",
    "speedup_2 = seq_time / par2_time\n",
    "efficiency_2 = (speedup_2 / 2) * 100\n",
    "\n",
    "print(f\"\\n‚úì Parallel execution (2 cores) completed in {par2_time:.2f} seconds\")\n",
    "print(f\"‚úì Speedup: {speedup_2:.2f}x\")\n",
    "print(f\"‚úì Efficiency: {efficiency_2:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution with All Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel execution with all cores\n",
    "print(f\"Running PARALLEL fit_resamples (n_jobs=-1, using all {cpu_count} cores)...\")\n",
    "start = time.time()\n",
    "results_par_all = fit_resamples(\n",
    "    wf,\n",
    "    folds,\n",
    "    metrics=metrics,\n",
    "    n_jobs=-1,  # Use all cores\n",
    "    verbose=True\n",
    ")\n",
    "par_all_time = time.time() - start\n",
    "\n",
    "speedup_all = seq_time / par_all_time\n",
    "efficiency_all = (speedup_all / cpu_count) * 100\n",
    "\n",
    "print(f\"\\n‚úì Parallel execution (all cores) completed in {par_all_time:.2f} seconds\")\n",
    "print(f\"‚úì Speedup: {speedup_all:.2f}x\")\n",
    "print(f\"‚úì Efficiency: {efficiency_all:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results are identical\n",
    "metrics_par2 = results_par2.collect_metrics()\n",
    "metrics_par_all = results_par_all.collect_metrics()\n",
    "\n",
    "# Compare metrics\n",
    "print(\"Consistency Check:\")\n",
    "for metric in ['rmse', 'mae', 'rsq']:\n",
    "    seq_val = metrics_seq[metrics_seq['metric'] == metric]['mean'].values[0]\n",
    "    par2_val = metrics_par2[metrics_par2['metric'] == metric]['mean'].values[0]\n",
    "    par_all_val = metrics_par_all[metrics_par_all['metric'] == metric]['mean'].values[0]\n",
    "    \n",
    "    match = np.allclose([seq_val, par2_val, par_all_val], seq_val, rtol=1e-10)\n",
    "    status = \"‚úì IDENTICAL\" if match else \"‚úó DIFFERENT\"\n",
    "    print(f\"  {metric}: {status}\")\n",
    "\n",
    "print(\"\\n‚úì All parallel executions produce identical results to sequential!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison table\n",
    "perf_df = pd.DataFrame({\n",
    "    'Configuration': ['Sequential', f'Parallel (2 cores)', f'Parallel ({cpu_count} cores)'],\n",
    "    'n_jobs': [1, 2, -1],\n",
    "    'Time (s)': [seq_time, par2_time, par_all_time],\n",
    "    'Speedup': [1.0, speedup_2, speedup_all],\n",
    "    'Efficiency (%)': [100.0, efficiency_2, efficiency_all]\n",
    "})\n",
    "\n",
    "display(perf_df)\n",
    "\n",
    "# Plot speedup\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(perf_df['Configuration'], perf_df['Speedup'], color=['gray', 'blue', 'green'])\n",
    "plt.ylabel('Speedup (x)')\n",
    "plt.title('fit_resamples() Speedup: Sequential vs Parallel')\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='Baseline')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CPU Warning Demonstrations\n",
    "\n",
    "The parallel processing system includes intelligent warnings to help users avoid inefficient configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning 1: Oversubscription (n_jobs > available cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger oversubscription warning\n",
    "print(f\"System has {cpu_count} cores. Requesting {cpu_count + 4} cores...\\n\")\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    results_over = fit_resamples(\n",
    "        wf,\n",
    "        folds,\n",
    "        metrics=metrics,\n",
    "        n_jobs=cpu_count + 4,  # Request more cores than available\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if w:\n",
    "        print(\"‚ö†Ô∏è  WARNING TRIGGERED:\")\n",
    "        print(f\"    {w[0].message}\")\n",
    "        print(\"\\nüí° Recommendation: Use n_jobs=-1 or n_jobs={cpu_count} instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning 2: Inefficiency (n_jobs > task count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller CV with only 3 folds\n",
    "folds_3 = vfold_cv(train_data, v=3, seed=123)\n",
    "print(f\"Created {len(folds_3)} CV folds. Requesting 10 workers...\\n\")\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    results_ineff = fit_resamples(\n",
    "        wf,\n",
    "        folds_3,\n",
    "        metrics=metrics,\n",
    "        n_jobs=10,  # More workers than tasks\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if w:\n",
    "        print(\"‚ö†Ô∏è  WARNING TRIGGERED:\")\n",
    "        print(f\"    {w[0].message}\")\n",
    "        print(\"\\nüí° Recommendation: Use n_jobs=3 (number of folds) instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Parallel Grid Search with tune_grid()\n",
    "\n",
    "Grid search benefits significantly from parallel execution since it involves many model fits (configs √ó folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tunable workflow\n",
    "spec_tunable = linear_reg(\n",
    "    penalty=tune(),\n",
    "    mixture=tune()\n",
    ").set_engine(\"sklearn\")\n",
    "\n",
    "wf_tune = workflow().add_formula(FORMULA).add_model(spec_tunable)\n",
    "\n",
    "# Define parameter space\n",
    "param_info = {\n",
    "    'penalty': {'range': (0.001, 1.0), 'trans': 'log'},\n",
    "    'mixture': {'range': (0, 1)}\n",
    "}\n",
    "\n",
    "# Create grid (5√ó5 = 25 configurations)\n",
    "grid = grid_regular(param_info, levels=5)\n",
    "n_configs = len(grid)\n",
    "n_folds = 5\n",
    "total_fits = n_configs * n_folds\n",
    "\n",
    "print(f\"Grid search configuration:\")\n",
    "print(f\"  Configurations: {n_configs}\")\n",
    "print(f\"  CV folds: {n_folds}\")\n",
    "print(f\"  Total fits: {total_fits}\")\n",
    "print(f\"\\nThis is a good candidate for parallel execution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Grid Search (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running SEQUENTIAL grid search ({total_fits} fits)...\")\n",
    "start = time.time()\n",
    "tune_results_seq = tune_grid(\n",
    "    wf_tune,\n",
    "    folds,\n",
    "    grid=grid,\n",
    "    metrics=metrics,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "tune_seq_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚úì Sequential grid search completed in {tune_seq_time:.2f} seconds\")\n",
    "print(f\"  ({tune_seq_time / total_fits:.2f} seconds per fit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running PARALLEL grid search ({total_fits} fits, n_jobs=-1)...\")\n",
    "start = time.time()\n",
    "tune_results_par = tune_grid(\n",
    "    wf_tune,\n",
    "    folds,\n",
    "    grid=grid,\n",
    "    metrics=metrics,\n",
    "    n_jobs=-1,  # Use all cores\n",
    "    verbose=True\n",
    ")\n",
    "tune_par_time = time.time() - start\n",
    "\n",
    "tune_speedup = tune_seq_time / tune_par_time\n",
    "tune_efficiency = (tune_speedup / cpu_count) * 100\n",
    "\n",
    "print(f\"\\n‚úì Parallel grid search completed in {tune_par_time:.2f} seconds\")\n",
    "print(f\"  ({tune_par_time / total_fits:.2f} seconds per fit)\")\n",
    "print(f\"‚úì Speedup: {tune_speedup:.2f}x\")\n",
    "print(f\"‚úì Efficiency: {tune_efficiency:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best results\n",
    "best_results = tune_results_par.show_best(metric='rmse', n=5)\n",
    "display(best_results)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = tune_results_par.select_best(metric='rmse', maximize=False)\n",
    "print(f\"\\nBest parameters:\")\n",
    "print(f\"  penalty: {best_params['penalty']:.4f}\")\n",
    "print(f\"  mixture: {best_params['mixture']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PARALLEL PROCESSING PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSystem: {cpu_count} CPU cores\")\n",
    "print(f\"\\n1. fit_resamples() - 5-fold CV\")\n",
    "print(f\"   Sequential: {seq_time:.2f}s\")\n",
    "print(f\"   Parallel (2 cores): {par2_time:.2f}s (speedup: {speedup_2:.2f}x)\")\n",
    "print(f\"   Parallel (all cores): {par_all_time:.2f}s (speedup: {speedup_all:.2f}x)\")\n",
    "\n",
    "print(f\"\\n2. tune_grid() - {total_fits} fits\")\n",
    "print(f\"   Sequential: {tune_seq_time:.2f}s\")\n",
    "print(f\"   Parallel (all cores): {tune_par_time:.2f}s (speedup: {tune_speedup:.2f}x)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Use parallel execution (n_jobs=-1) for:\")\n",
    "print(f\"   - Grid search with many configurations (>10)\")\n",
    "print(f\"   - CV with many folds (>5) and complex models\")\n",
    "print(f\"   - Any task taking >30 seconds total\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Use sequential execution (n_jobs=1) for:\")\n",
    "print(f\"   - Quick tasks (<10 seconds)\")\n",
    "print(f\"   - Simple models with few folds\")\n",
    "print(f\"   - Debugging (easier to trace errors)\")\n",
    "\n",
    "print(f\"\\nüí° Tips:\")\n",
    "print(f\"   - Always use verbose=True to monitor progress\")\n",
    "print(f\"   - Watch for CPU warnings - they help optimize performance\")\n",
    "print(f\"   - On shared machines, use n_jobs={max(1, cpu_count-1)} to leave cores free\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
