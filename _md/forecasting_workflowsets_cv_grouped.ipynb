{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# WorkflowSets with Time Series Cross-Validation - NEW Grouped API\n",
    "\n",
    "This notebook combines WorkflowSet multi-model comparison with time series cross-validation for robust model selection on grouped panel data.\n",
    "\n",
    "**NEW**: Uses `fit_nested()` to evaluate ALL workflows across ALL groups\n",
    "\n",
    "## Contents:\n",
    "1. Data loading and panel structure\n",
    "2. Define multiple preprocessing strategies\n",
    "3. Define multiple model specifications\n",
    "4. Create WorkflowSet from cross product\n",
    "5. **NEW**: Fit all workflows across all groups with fit_nested()\n",
    "6. **NEW**: Collect and rank group-aware metrics\n",
    "7. **NEW**: Compare workflows overall and per-group\n",
    "8. Evaluate best workflow on test data\n",
    "9. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/matthewdeane/Documents/Data%20Science/python/_projects/py-tidymodels/_md\n",
      "\u001b[31mERROR: file:///Users/matthewdeane/Documents/Data%20Science/python/_projects/py-tidymodels/_md does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Imports complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg, rand_forest, boost_tree\n",
    "from py_rsample import initial_split, training, testing, time_series_cv\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "from py_tune import fit_resamples\n",
    "from py_workflowsets import WorkflowSet\n",
    "\n",
    "# Recipe imports\n",
    "from py_recipes import recipe\n",
    "from py_recipes.selectors import all_numeric_predictors\n",
    "from py_visualize import plot_forecast\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\u2713 Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load refinery margins panel data with multiple countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1920, 20)\n",
      "Countries: ['Algeria', 'Denmark', 'Germany', 'Italy', 'Netherlands', 'Norway', 'Romania', 'Russian Federation', 'Turkey', 'United Kingdom']\n",
      "Date range: 2006-01-01 00:00:00 to 2021-12-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>refinery_kbd</th>\n",
       "      <th>brent</th>\n",
       "      <th>dubai</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent_cracking_nw_europe</th>\n",
       "      <th>brent_hydroskimming_nw_europe</th>\n",
       "      <th>urals_cracking_nw_europe</th>\n",
       "      <th>urals_hydroskimming_nw_europe</th>\n",
       "      <th>es_sider_cracking_med</th>\n",
       "      <th>es_sider_hydroskimming_med</th>\n",
       "      <th>urals_cracking_med</th>\n",
       "      <th>urals_hydroskimming_med</th>\n",
       "      <th>dubai_cracking_singapore</th>\n",
       "      <th>dubai_hydroskimming_singapore</th>\n",
       "      <th>tapis_hydroskimming_singapore</th>\n",
       "      <th>x50_50_hls_lls_cracking_usgc</th>\n",
       "      <th>x30_70_wcs_bakken_cracking_usmc</th>\n",
       "      <th>bakken_coking_usmc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>450.0000</td>\n",
       "      <td>63.57</td>\n",
       "      <td>58.31</td>\n",
       "      <td>65.48</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>172.9948</td>\n",
       "      <td>63.57</td>\n",
       "      <td>58.31</td>\n",
       "      <td>65.48</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2270.5419</td>\n",
       "      <td>63.57</td>\n",
       "      <td>58.31</td>\n",
       "      <td>65.48</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1859.7058</td>\n",
       "      <td>63.57</td>\n",
       "      <td>58.31</td>\n",
       "      <td>65.48</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>907.5555</td>\n",
       "      <td>63.57</td>\n",
       "      <td>58.31</td>\n",
       "      <td>65.48</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      country  refinery_kbd  brent  dubai    wti  \\\n",
       "0 2006-01-01      Algeria      450.0000  63.57  58.31  65.48   \n",
       "1 2006-01-01      Denmark      172.9948  63.57  58.31  65.48   \n",
       "2 2006-01-01      Germany     2270.5419  63.57  58.31  65.48   \n",
       "3 2006-01-01        Italy     1859.7058  63.57  58.31  65.48   \n",
       "4 2006-01-01  Netherlands      907.5555  63.57  58.31  65.48   \n",
       "\n",
       "   brent_cracking_nw_europe  brent_hydroskimming_nw_europe  \\\n",
       "0                      3.12                          -2.51   \n",
       "1                      3.12                          -2.51   \n",
       "2                      3.12                          -2.51   \n",
       "3                      3.12                          -2.51   \n",
       "4                      3.12                          -2.51   \n",
       "\n",
       "   urals_cracking_nw_europe  urals_hydroskimming_nw_europe  \\\n",
       "0                       5.3                          -2.18   \n",
       "1                       5.3                          -2.18   \n",
       "2                       5.3                          -2.18   \n",
       "3                       5.3                          -2.18   \n",
       "4                       5.3                          -2.18   \n",
       "\n",
       "   es_sider_cracking_med  es_sider_hydroskimming_med  urals_cracking_med  \\\n",
       "0                   4.81                       -0.17                 6.8   \n",
       "1                   4.81                       -0.17                 6.8   \n",
       "2                   4.81                       -0.17                 6.8   \n",
       "3                   4.81                       -0.17                 6.8   \n",
       "4                   4.81                       -0.17                 6.8   \n",
       "\n",
       "   urals_hydroskimming_med  dubai_cracking_singapore  \\\n",
       "0                    -1.52                      2.47   \n",
       "1                    -1.52                      2.47   \n",
       "2                    -1.52                      2.47   \n",
       "3                    -1.52                      2.47   \n",
       "4                    -1.52                      2.47   \n",
       "\n",
       "   dubai_hydroskimming_singapore  tapis_hydroskimming_singapore  \\\n",
       "0                          -3.16                          -1.79   \n",
       "1                          -3.16                          -1.79   \n",
       "2                          -3.16                          -1.79   \n",
       "3                          -3.16                          -1.79   \n",
       "4                          -3.16                          -1.79   \n",
       "\n",
       "   x50_50_hls_lls_cracking_usgc  x30_70_wcs_bakken_cracking_usmc  \\\n",
       "0                         -5.68                             0.38   \n",
       "1                         -5.68                             0.38   \n",
       "2                         -5.68                             0.38   \n",
       "3                         -5.68                             0.38   \n",
       "4                         -5.68                             0.38   \n",
       "\n",
       "   bakken_coking_usmc  \n",
       "0                2.57  \n",
       "1                2.57  \n",
       "2                2.57  \n",
       "3                2.57  \n",
       "4                2.57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import data\n",
    "raw_data = pd.read_csv('__data/refinery_margins.csv')\n",
    "df = raw_data.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Countries: {sorted(df['country'].unique())}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1440 rows\n",
      "Test: 480 rows\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "split = initial_split(df, prop=0.75, seed=123)\n",
    "train_data = training(split)\n",
    "test_data = testing(split)\n",
    "\n",
    "print(f\"Training: {train_data.shape[0]} rows\")\n",
    "print(f\"Test: {test_data.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Define Multiple Preprocessing Strategies\n",
    "\n",
    "Create different preprocessing approaches to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 4 preprocessing strategies defined\n"
     ]
    }
   ],
   "source": [
    "# Strategy 1: Minimal formula (just one predictor)\n",
    "formula_minimal = \"refinery_kbd ~ brent\"\n",
    "\n",
    "# Strategy 2: Two predictors\n",
    "formula_two = \"refinery_kbd ~ brent + dubai\"\n",
    "\n",
    "# Strategy 3: All predictors\n",
    "formula_all = \"refinery_kbd ~ .\"\n",
    "\n",
    "# Strategy 4: Recipe with normalization\n",
    "rec_normalized = (\n",
    "    recipe()\n",
    "    .step_normalize(all_numeric_predictors())\n",
    ")\n",
    "\n",
    "print(\"\u2713 4 preprocessing strategies defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Define Multiple Model Specifications\n",
    "\n",
    "Create different model types to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 3 model specifications defined\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear Regression\n",
    "spec_lr = linear_reg().set_engine(\"sklearn\")\n",
    "\n",
    "# Model 2: Random Forest\n",
    "spec_rf = rand_forest(trees=100, mtry=3, min_n=5).set_mode(\"regression\")\n",
    "\n",
    "# Model 3: XGBoost\n",
    "spec_xgb = boost_tree(trees=100, tree_depth=4, learn_rate=0.1).set_engine(\"xgboost\")\n",
    "\n",
    "print(\"\u2713 3 model specifications defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Create WorkflowSet from Cross Product\n",
    "\n",
    "Combine all preprocessing strategies with all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 12 workflows:\n",
      "  - minimal_linear_reg_1\n",
      "  - minimal_rand_forest_2\n",
      "  - minimal_boost_tree_3\n",
      "  - two_pred_linear_reg_1\n",
      "  - two_pred_rand_forest_2\n",
      "  - two_pred_boost_tree_3\n",
      "  - all_pred_linear_reg_1\n",
      "  - all_pred_rand_forest_2\n",
      "  - all_pred_boost_tree_3\n",
      "  - normalized_linear_reg_1\n",
      "  - normalized_rand_forest_2\n",
      "  - normalized_boost_tree_3\n"
     ]
    }
   ],
   "source": [
    "# Create WorkflowSet\n",
    "wf_set = WorkflowSet.from_cross(\n",
    "    preproc=[\n",
    "        formula_minimal,\n",
    "        formula_two,\n",
    "        formula_all,\n",
    "        rec_normalized\n",
    "    ],\n",
    "    models=[\n",
    "        spec_lr,\n",
    "        spec_rf,\n",
    "        spec_xgb\n",
    "    ],\n",
    "    ids=[\"minimal\", \"two_pred\", \"all_pred\", \"normalized\"]\n",
    ")\n",
    "\n",
    "print(f\"Created {len(wf_set.workflows)} workflows:\")\n",
    "for wf_id in wf_set.workflows.keys():\n",
    "    print(f\"  - {wf_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit All Workflows Across All Groups\n",
    "\n",
    "**NEW**: Use `fit_nested()` to fit all workflows on all groups, then use rank_results() for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all workflows across ALL groups using NEW fit_nested() method\n",
    "print(f\"Fitting {len(wf_set.workflows)} workflows across {train_data['country'].nunique()} groups...\")\n",
    "print(f\"Total models: {len(wf_set.workflows) * train_data['country'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Use NEW WorkflowSet.fit_nested() method\n",
    "results = wf_set.fit_nested(train_data, group_col='country')\n",
    "\n",
    "print(\"\\n\u2713 All workflows fitted across all groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Collect and Rank Results\n",
    "\n",
    "**NEW**: Use group-aware methods to analyze performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metrics averaged across groups\n",
    "metrics_avg = results.collect_metrics(by_group=False, split='train')\n",
    "\n",
    "print(\"Average metrics across all groups:\")\n",
    "display(metrics_avg.head(12))\n",
    "\n",
    "# Rank workflows by average RMSE\n",
    "ranked_overall = results.rank_results('rmse', split='train', by_group=False, n=10)\n",
    "\n",
    "print(\"\\nTop 10 workflows (average RMSE across all groups):\")\n",
    "display(ranked_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank workflows within each group\n",
    "ranked_by_group = results.rank_results('rmse', split='train', by_group=True, n=3)\n",
    "\n",
    "print(\"Top 3 workflows per group:\")\n",
    "display(ranked_by_group.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Workflow Comparison\n",
    "\n",
    "**NEW**: Use autoplot() for group-aware visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average performance with error bars\n",
    "fig = results.autoplot('rmse', split='train', by_group=False, top_n=10)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nShows average RMSE \u00b1 std across all groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per-group performance\n",
    "fig = results.autoplot('rmse', split='train', by_group=True, top_n=5)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nShows top 5 workflows for each group separately\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract and Evaluate Best Workflow\n",
    "\n",
    "Select best workflow and evaluate on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best workflow overall\n",
    "best_wf_id = results.extract_best_workflow('rmse', split='train', by_group=False)\n",
    "\n",
    "print(f\"Best workflow (average across groups): {best_wf_id}\")\n",
    "\n",
    "# Also check per-group preferences\n",
    "best_by_group = results.extract_best_workflow('rmse', split='train', by_group=True)\n",
    "\n",
    "print(\"\\nBest workflow per group:\")\n",
    "display(best_by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best workflow and evaluate on test\n",
    "best_wf = wf_set.workflows[best_wf_id]\n",
    "\n",
    "fit_nested = best_wf.fit_nested(train_data, group_col='country')\n",
    "fit_nested = fit_nested.evaluate(test_data)\n",
    "\n",
    "# Extract test stats\n",
    "outputs, coefs, stats = fit_nested.extract_outputs()\n",
    "test_stats = stats[stats['split'] == 'test']\n",
    "\n",
    "# Pivot for display\n",
    "test_stats_pivot = test_stats.pivot_table(\n",
    "    index='group',\n",
    "    columns='metric',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nTest performance by country:\")\n",
    "display(test_stats_pivot[['group', 'rmse', 'mae', 'r_squared']].sort_values('rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated **WorkflowSet grouped modeling with robust evaluation**:\n",
    "\n",
    "### Key Features:\n",
    "1. **`fit_nested()`** - Fit all workflows across all groups simultaneously\n",
    "2. **`collect_metrics(by_group=False)`** - Average metrics across groups for ranking\n",
    "3. **`rank_results()`** - Rank workflows overall and per-group\n",
    "4. **`autoplot()`** - Visualize comparison with error bars\n",
    "5. **`extract_best_workflow()`** - Select winning workflow\n",
    "\n",
    "### Advantages Over Old Approach:\n",
    "\n",
    "**Before:**\n",
    "- Filter to ONE group (Germany)\n",
    "- Run CV manually for each workflow\n",
    "- Aggregate metrics manually\n",
    "- Apply best to all groups separately\n",
    "\n",
    "**After (NEW):**\n",
    "- Fit ALL workflows on ALL groups\n",
    "- Automatic metric aggregation\n",
    "- Built-in ranking and visualization\n",
    "- Single method call for complete evaluation\n",
    "\n",
    "### Benefits:\n",
    "- **More representative**: Uses all groups for selection, not just one\n",
    "- **Detects heterogeneity**: Can identify if different groups need different workflows\n",
    "- **Efficient**: Single API call vs manual loops\n",
    "- **Robust**: Averages across groups reduce overfitting to single group\n",
    "\n",
    "### Next Steps:\n",
    "- Add hyperparameter tuning to best workflow\n",
    "- Try `per_group_prep=True` for group-specific preprocessing\n",
    "- Experiment with `fit_global()` for comparison\n",
    "- Add time series CV within each group for even more robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}