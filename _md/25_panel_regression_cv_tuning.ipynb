{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel Regression: Evaluation, Diagnostics, and Best Practices\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook focuses on the practical aspects of panel regression:\n",
    "\n",
    "1. **Train/test evaluation**: Assessing out-of-sample performance\n",
    "2. **Residual diagnostics**: Checking model assumptions\n",
    "3. **Practical recommendations**: Guidelines for real-world applications\n",
    "4. **Common pitfalls**: What to avoid and how to handle edge cases\n",
    "\n",
    "### Why Evaluation Matters\n",
    "\n",
    "Panel models can overfit to group structure if:\n",
    "- Groups have very few observations\n",
    "- Too many random effects are estimated\n",
    "- Data contains outliers or influential observations\n",
    "\n",
    "Proper evaluation helps identify these issues before deployment.\n",
    "\n",
    "### Residual Diagnostics for Panel Data\n",
    "\n",
    "Standard residual checks:\n",
    "- **Normality**: Q-Q plots, Shapiro-Wilk test\n",
    "- **Heteroskedasticity**: Residuals vs fitted, Breusch-Pagan test\n",
    "- **Autocorrelation**: Durbin-Watson, Ljung-Box test\n",
    "- **Outliers**: Residuals by group, Cook's distance\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Generate multi-factory production data\n",
    "2. Perform time-based train/test splits\n",
    "3. Evaluate panel models on held-out data\n",
    "4. Conduct comprehensive residual diagnostics\n",
    "5. Identify outliers and influential groups\n",
    "6. Learn practical recommendations for panel modeling\n",
    "7. Understand when to use panel_reg() vs alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest\n",
    "import statsmodels.stats.diagnostic as sm_diag\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_parsnip import panel_reg, linear_reg\n",
    "from py_workflows import workflow\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Multi-Factory Production Data\n",
    "\n",
    "We'll create a dataset with:\n",
    "- **8 factories**: Each with different baseline production levels\n",
    "- **104 weeks** of weekly data per factory = 832 total observations\n",
    "- **Time series structure**: Observations within factories are correlated\n",
    "- **Variables**:\n",
    "  - `output`: Production output (outcome)\n",
    "  - `temperature`: Operating temperature (predictor)\n",
    "  - `pressure`: Operating pressure (predictor)\n",
    "  - `humidity`: Environmental humidity (predictor)\n",
    "  - `week`: Week number (time variable)\n",
    "  - `factory_id`: Factory identifier (group)\n",
    "\n",
    "**Data Generating Process**:\n",
    "- Random intercepts: Factories have different baseline outputs (80-120)\n",
    "- Temperature effect: +2.0 (positive effect on output)\n",
    "- Pressure effect: +1.5 (positive effect on output)\n",
    "- Humidity effect: -0.5 (negative effect on output)\n",
    "- Autocorrelation: AR(1) structure within each factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_factories = 8\n",
    "n_weeks = 104\n",
    "n_total = n_factories * n_weeks\n",
    "\n",
    "# Factory IDs\n",
    "factory_ids = [f'Factory_{i+1}' for i in range(n_factories)]\n",
    "\n",
    "# Random intercepts (baseline production levels)\n",
    "random_intercepts = np.random.uniform(80, 120, n_factories)\n",
    "\n",
    "# Fixed effects\n",
    "beta_temperature = 2.0\n",
    "beta_pressure = 1.5\n",
    "beta_humidity = -0.5\n",
    "\n",
    "# Autocorrelation parameter\n",
    "rho = 0.6  # AR(1) coefficient\n",
    "\n",
    "# Generate data\n",
    "data_list = []\n",
    "\n",
    "for i, factory_id in enumerate(factory_ids):\n",
    "    # Predictors\n",
    "    week = np.arange(1, n_weeks + 1)\n",
    "    temperature = np.random.uniform(60, 80, n_weeks)\n",
    "    pressure = np.random.uniform(20, 30, n_weeks)\n",
    "    humidity = np.random.uniform(30, 70, n_weeks)\n",
    "    \n",
    "    # Generate AR(1) errors\n",
    "    errors = np.zeros(n_weeks)\n",
    "    errors[0] = np.random.normal(0, 5)\n",
    "    for t in range(1, n_weeks):\n",
    "        errors[t] = rho * errors[t-1] + np.random.normal(0, 5)\n",
    "    \n",
    "    # Output = intercept + predictors*betas + AR(1) errors\n",
    "    output = (\n",
    "        random_intercepts[i] + \n",
    "        beta_temperature * temperature + \n",
    "        beta_pressure * pressure + \n",
    "        beta_humidity * humidity + \n",
    "        errors\n",
    "    )\n",
    "    \n",
    "    factory_data = pd.DataFrame({\n",
    "        'factory_id': factory_id,\n",
    "        'week': week,\n",
    "        'temperature': temperature,\n",
    "        'pressure': pressure,\n",
    "        'humidity': humidity,\n",
    "        'output': output\n",
    "    })\n",
    "    \n",
    "    data_list.append(factory_data)\n",
    "\n",
    "# Combine all factories\n",
    "production_data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Dataset shape: {production_data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(production_data.head(10))\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(production_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize factory production over time\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for factory_id in factory_ids:\n",
    "    factory_data = production_data[production_data['factory_id'] == factory_id]\n",
    "    ax.plot(factory_data['week'], factory_data['output'], alpha=0.7, linewidth=1.5, label=factory_id)\n",
    "\n",
    "ax.set_xlabel('Week', fontsize=12)\n",
    "ax.set_ylabel('Production Output', fontsize=12)\n",
    "ax.set_title('Factory Production Over Time', fontsize=14, weight='bold')\n",
    "ax.legend(loc='upper left', fontsize=9, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Each factory has a different baseline production level (random intercepts).\")\n",
    "print(\"   Production shows autocorrelation over time within each factory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split (Time-Based)\n",
    "\n",
    "For time series data, we use a **chronological split** to avoid data leakage:\n",
    "- **Training**: First 80 weeks per factory\n",
    "- **Test**: Last 24 weeks per factory\n",
    "\n",
    "This simulates forecasting future production based on historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "split_week = 80\n",
    "\n",
    "train_data = production_data[production_data['week'] <= split_week].copy()\n",
    "test_data = production_data[production_data['week'] > split_week].copy()\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"\\nTraining weeks: 1-{split_week}\")\n",
    "print(f\"Test weeks: {split_week+1}-{n_weeks}\")\n",
    "print(f\"\\nFactories in train: {train_data['factory_id'].nunique()}\")\n",
    "print(f\"Factories in test: {test_data['factory_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit and Evaluate Panel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit panel regression on training data\n",
    "spec = panel_reg(random_effects=\"intercept\")\n",
    "wf = workflow().add_formula(\"output ~ temperature + pressure + humidity\").add_model(spec)\n",
    "fit = wf.fit_global(train_data, group_col='factory_id')\n",
    "\n",
    "print(\"‚úÖ Panel regression model fitted on training data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "evaluated = fit.evaluate(test_data)\n",
    "\n",
    "# Extract outputs\n",
    "outputs, coefficients, stats = evaluated.extract_outputs()\n",
    "\n",
    "# Compare train vs test metrics\n",
    "train_stats = stats[stats['split'] == 'train']\n",
    "test_stats = stats[stats['split'] == 'test']\n",
    "\n",
    "train_rmse = train_stats[train_stats['metric'] == 'rmse']['value'].values[0]\n",
    "test_rmse = test_stats[test_stats['metric'] == 'rmse']['value'].values[0]\n",
    "train_r2 = train_stats[train_stats['metric'] == 'r_squared']['value'].values[0]\n",
    "test_r2 = test_stats[test_stats['metric'] == 'r_squared']['value'].values[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN VS TEST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"\\nTraining R¬≤: {train_r2:.4f}\")\n",
    "print(f\"Test R¬≤: {test_r2:.4f}\")\n",
    "\n",
    "# Calculate degradation\n",
    "rmse_degradation = ((test_rmse - train_rmse) / train_rmse) * 100\n",
    "r2_degradation = ((train_r2 - test_r2) / train_r2) * 100\n",
    "\n",
    "print(f\"\\nüìä Performance Degradation:\")\n",
    "print(f\"   RMSE increased by {rmse_degradation:.1f}%\")\n",
    "print(f\"   R¬≤ decreased by {r2_degradation:.1f}%\")\n",
    "\n",
    "if rmse_degradation < 10:\n",
    "    print(f\"\\n‚úÖ Good generalization: Model performs well on held-out data.\")\n",
    "elif rmse_degradation < 20:\n",
    "    print(f\"\\n‚ö†Ô∏è Moderate degradation: Some overfitting may be present.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Poor generalization: Model is overfitting to training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train vs test performance by factory\n",
    "train_outputs = outputs[outputs['split'] == 'train']\n",
    "test_outputs = outputs[outputs['split'] == 'test']\n",
    "\n",
    "# Calculate per-factory RMSE\n",
    "train_rmse_by_factory = train_outputs.groupby('group').apply(\n",
    "    lambda df: np.sqrt(np.mean((df['actuals'] - df['fitted'])**2))\n",
    ").reset_index()\n",
    "train_rmse_by_factory.columns = ['factory_id', 'train_rmse']\n",
    "\n",
    "test_rmse_by_factory = test_outputs.groupby('group').apply(\n",
    "    lambda df: np.sqrt(np.mean((df['actuals'] - df['fitted'])**2))\n",
    ").reset_index()\n",
    "test_rmse_by_factory.columns = ['factory_id', 'test_rmse']\n",
    "\n",
    "# Merge\n",
    "rmse_comparison = train_rmse_by_factory.merge(test_rmse_by_factory, on='factory_id')\n",
    "rmse_comparison['degradation_%'] = ((rmse_comparison['test_rmse'] - rmse_comparison['train_rmse']) / rmse_comparison['train_rmse']) * 100\n",
    "\n",
    "print(\"\\nPer-Factory Performance:\")\n",
    "print(rmse_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train vs test RMSE\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(rmse_comparison))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, rmse_comparison['train_rmse'], width, label='Train', color='steelblue')\n",
    "ax.bar(x + width/2, rmse_comparison['test_rmse'], width, label='Test', color='coral')\n",
    "\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_xlabel('Factory', fontsize=12)\n",
    "ax.set_title('Train vs Test RMSE by Factory', fontsize=14, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(rmse_comparison['factory_id'], rotation=45)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Most factories show similar train/test performance, indicating good generalization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Residual Diagnostics\n",
    "\n",
    "Let's check model assumptions using residual plots and statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract residuals and fitted values\n",
    "train_residuals = train_outputs['residuals'].values\n",
    "train_fitted = train_outputs['fitted'].values\n",
    "train_actuals = train_outputs['actuals'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESIDUAL DIAGNOSTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Normality (Shapiro-Wilk test)\n",
    "shapiro_stat, shapiro_p = shapiro(train_residuals)\n",
    "print(f\"\\n1. Normality Test (Shapiro-Wilk):\")\n",
    "print(f\"   Statistic: {shapiro_stat:.4f}\")\n",
    "print(f\"   p-value: {shapiro_p:.4f}\")\n",
    "if shapiro_p > 0.05:\n",
    "    print(f\"   ‚úÖ Residuals are approximately normal (p > 0.05)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Residuals deviate from normality (p < 0.05)\")\n",
    "\n",
    "# Test 2: Durbin-Watson (autocorrelation)\n",
    "dw_stats = stats[stats['metric'] == 'durbin_watson']\n",
    "if not dw_stats.empty:\n",
    "    dw_stat = dw_stats['value'].values[0]\n",
    "    print(f\"\\n2. Autocorrelation Test (Durbin-Watson):\")\n",
    "    print(f\"   Statistic: {dw_stat:.4f}\")\n",
    "    print(f\"   Interpretation: 2 = no autocorrelation, 0 = positive, 4 = negative\")\n",
    "    if 1.5 < dw_stat < 2.5:\n",
    "        print(f\"   ‚úÖ No significant autocorrelation\")\n",
    "    elif dw_stat < 1.5:\n",
    "        print(f\"   ‚ö†Ô∏è Positive autocorrelation detected (common in time series)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Negative autocorrelation detected\")\n",
    "\n",
    "# Test 3: Ljung-Box (autocorrelation in residuals)\n",
    "ljung_box_stats = stats[stats['metric'] == 'ljung_box_p']\n",
    "if not ljung_box_stats.empty:\n",
    "    ljung_box_p = ljung_box_stats['value'].values[0]\n",
    "    print(f\"\\n3. Ljung-Box Test (autocorrelation):\")\n",
    "    print(f\"   p-value: {ljung_box_p:.4f}\")\n",
    "    if ljung_box_p > 0.05:\n",
    "        print(f\"   ‚úÖ No significant autocorrelation in residuals (p > 0.05)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Autocorrelation present in residuals (p < 0.05)\")\n",
    "        print(f\"   Consider: (1) Adding lagged predictors, (2) AR error structure\")\n",
    "\n",
    "# Test 4: Breusch-Pagan (heteroskedasticity)\n",
    "bp_stats = stats[stats['metric'] == 'breusch_pagan_p']\n",
    "if not bp_stats.empty:\n",
    "    bp_p = bp_stats['value'].values[0]\n",
    "    print(f\"\\n4. Breusch-Pagan Test (heteroskedasticity):\")\n",
    "    print(f\"   p-value: {bp_p:.4f}\")\n",
    "    if bp_p > 0.05:\n",
    "        print(f\"   ‚úÖ Homoskedastic residuals (p > 0.05)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Heteroskedasticity present (p < 0.05)\")\n",
    "        print(f\"   Consider: (1) Log transformation, (2) Robust standard errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive residual plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Residuals vs Fitted\n",
    "axes[0, 0].scatter(train_fitted, train_residuals, alpha=0.5, s=20)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Fitted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Residuals vs Fitted')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Q-Q Plot\n",
    "stats.probplot(train_residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('Normal Q-Q Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Histogram of residuals\n",
    "axes[0, 2].hist(train_residuals, bins=40, edgecolor='black', alpha=0.7)\n",
    "axes[0, 2].set_xlabel('Residuals')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('Distribution of Residuals')\n",
    "axes[0, 2].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Scale-Location (sqrt(|residuals|) vs fitted)\n",
    "sqrt_abs_resid = np.sqrt(np.abs(train_residuals))\n",
    "axes[1, 0].scatter(train_fitted, sqrt_abs_resid, alpha=0.5, s=20)\n",
    "axes[1, 0].set_xlabel('Fitted Values')\n",
    "axes[1, 0].set_ylabel('‚àö|Residuals|')\n",
    "axes[1, 0].set_title('Scale-Location Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add lowess smoothing\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "lowess_result = lowess(sqrt_abs_resid, train_fitted, frac=0.3)\n",
    "axes[1, 0].plot(lowess_result[:, 0], lowess_result[:, 1], color='red', linewidth=2)\n",
    "\n",
    "# Plot 5: Residuals by factory (boxplot)\n",
    "train_outputs.boxplot(column='residuals', by='group', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Factory ID')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Residuals by Factory')\n",
    "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)\n",
    "plt.suptitle('')  # Remove auto title\n",
    "\n",
    "# Plot 6: ACF plot (autocorrelation function)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(train_residuals, lags=20, ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Autocorrelation Function')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Residual Diagnostic Interpretation:\")\n",
    "print(\"   - Residuals vs Fitted: Should show no clear pattern (random scatter)\")\n",
    "print(\"   - Q-Q Plot: Points should follow diagonal line (normal distribution)\")\n",
    "print(\"   - Histogram: Should be roughly bell-shaped and centered at zero\")\n",
    "print(\"   - Scale-Location: Red line should be roughly horizontal (homoskedasticity)\")\n",
    "print(\"   - By Factory: Similar distributions across factories (no outlier factories)\")\n",
    "print(\"   - ACF: Bars should stay within blue confidence bands (no autocorrelation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identify Outliers and Influential Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standardized residuals\n",
    "train_outputs['std_residuals'] = (train_outputs['residuals'] - train_outputs['residuals'].mean()) / train_outputs['residuals'].std()\n",
    "\n",
    "# Identify outlier observations (|std_resid| > 2.5)\n",
    "outliers = train_outputs[np.abs(train_outputs['std_residuals']) > 2.5]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUTLIER DETECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal observations: {len(train_outputs)}\")\n",
    "print(f\"Outliers (|std_resid| > 2.5): {len(outliers)}\")\n",
    "print(f\"Outlier percentage: {(len(outliers) / len(train_outputs)) * 100:.2f}%\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(f\"\\nOutliers by factory:\")\n",
    "    outlier_counts = outliers.groupby('group').size().reset_index(name='n_outliers')\n",
    "    outlier_counts = outlier_counts.sort_values('n_outliers', ascending=False)\n",
    "    print(outlier_counts.to_string(index=False))\n",
    "    \n",
    "    if outlier_counts['n_outliers'].max() > 5:\n",
    "        worst_factory = outlier_counts.iloc[0]['group']\n",
    "        print(f\"\\n‚ö†Ô∏è Factory '{worst_factory}' has unusually many outliers.\")\n",
    "        print(f\"   Consider investigating this factory for data quality issues.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No significant outliers detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Standardized residuals over time\n",
    "for factory_id in factory_ids:\n",
    "    factory_train = train_outputs[train_outputs['group'] == factory_id]\n",
    "    axes[0].plot(range(len(factory_train)), factory_train['std_residuals'].values, alpha=0.6, linewidth=1)\n",
    "\n",
    "axes[0].axhline(y=2.5, color='red', linestyle='--', linewidth=2, label='Outlier Threshold')\n",
    "axes[0].axhline(y=-2.5, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "axes[0].set_xlabel('Observation Index (within factory)', fontsize=12)\n",
    "axes[0].set_ylabel('Standardized Residuals', fontsize=12)\n",
    "axes[0].set_title('Standardized Residuals Over Time', fontsize=13, weight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of standardized residuals by factory\n",
    "train_outputs.boxplot(column='std_residuals', by='group', ax=axes[1])\n",
    "axes[1].axhline(y=2.5, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].axhline(y=-2.5, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Factory ID', fontsize=12)\n",
    "axes[1].set_ylabel('Standardized Residuals', fontsize=12)\n",
    "axes[1].set_title('Standardized Residuals by Factory', fontsize=13, weight='bold')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "plt.suptitle('')  # Remove auto title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Recommendations\n",
    "\n",
    "Based on our analysis and industry best practices, here are key recommendations for using panel regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Minimum Data Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check group sizes\n",
    "group_sizes = train_data.groupby('factory_id').size().reset_index(name='n_obs')\n",
    "group_sizes = group_sizes.sort_values('n_obs')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MINIMUM DATA REQUIREMENTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nObservations per group:\")\n",
    "print(group_sizes.to_string(index=False))\n",
    "\n",
    "min_obs = group_sizes['n_obs'].min()\n",
    "max_obs = group_sizes['n_obs'].max()\n",
    "mean_obs = group_sizes['n_obs'].mean()\n",
    "\n",
    "print(f\"\\nMin observations per group: {min_obs}\")\n",
    "print(f\"Max observations per group: {max_obs}\")\n",
    "print(f\"Mean observations per group: {mean_obs:.1f}\")\n",
    "\n",
    "print(\"\\nüí° GUIDELINES:\")\n",
    "print(\"   Minimum for random intercepts: 5-10 observations per group\")\n",
    "print(\"   Minimum for random slopes: 20+ observations per group\")\n",
    "print(\"   Number of groups: At least 5-10 groups for reliable variance estimation\")\n",
    "\n",
    "if min_obs >= 20:\n",
    "    print(\"\\n‚úÖ Your data meets requirements for random slopes models.\")\n",
    "elif min_obs >= 5:\n",
    "    print(\"\\n‚úÖ Your data meets requirements for random intercepts models.\")\n",
    "    print(\"   ‚ö†Ô∏è Insufficient data for random slopes (need 20+ per group).\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Insufficient data per group. Consider:\")\n",
    "    print(\"   1. Removing small groups\")\n",
    "    print(\"   2. Using linear_reg() with fixed effects\")\n",
    "    print(\"   3. Collecting more data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 When to Use Random Slopes vs Intercepts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM SLOPES DECISION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ USE RANDOM SLOPES WHEN:\")\n",
    "print(\"   1. Sufficient data per group (20+ observations)\")\n",
    "print(\"   2. Visual inspection shows varying slopes across groups\")\n",
    "print(\"   3. Theory suggests heterogeneity in effects\")\n",
    "print(\"   4. AIC/BIC improve by 10+ points\")\n",
    "print(\"   5. Variance of random slopes is substantial\")\n",
    "\n",
    "print(\"\\n‚ùå USE RANDOM INTERCEPTS ONLY WHEN:\")\n",
    "print(\"   1. Limited data per group (5-20 observations)\")\n",
    "print(\"   2. Visual inspection shows parallel slopes\")\n",
    "print(\"   3. Slopes model fails to converge\")\n",
    "print(\"   4. AIC/BIC do not improve or worsen\")\n",
    "print(\"   5. Primary interest is in group-level differences\")\n",
    "\n",
    "print(\"\\nüí° PRACTICAL TIP:\")\n",
    "print(\"   Always start with random intercepts.\")\n",
    "print(\"   Add random slopes only if there's clear evidence they improve the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Handling Unbalanced Panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UNBALANCED PANELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nUnbalanced panels occur when groups have different numbers of observations.\")\n",
    "print(\"\\n‚úÖ PANEL_REG HANDLES UNBALANCED DATA:\")\n",
    "print(\"   - MixedLM (statsmodels) naturally handles unbalanced panels\")\n",
    "print(\"   - No need for imputation or dropping groups\")\n",
    "print(\"   - Groups with more data get more weight in estimation\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è CONSIDERATIONS:\")\n",
    "print(\"   1. Groups with very few observations (<5) may have unreliable random effects\")\n",
    "print(\"   2. Extreme imbalance (e.g., 5 obs vs 500 obs) can affect convergence\")\n",
    "print(\"   3. Consider removing groups with <5 observations\")\n",
    "\n",
    "# Check balance\n",
    "balance_ratio = max_obs / min_obs if min_obs > 0 else np.inf\n",
    "print(f\"\\nYour data balance ratio: {balance_ratio:.2f}\")\n",
    "if balance_ratio < 3:\n",
    "    print(\"‚úÖ Well-balanced panel (max/min < 3)\")\n",
    "elif balance_ratio < 10:\n",
    "    print(\"‚ö†Ô∏è Moderately unbalanced (max/min < 10)\")\n",
    "else:\n",
    "    print(\"‚ùå Severely unbalanced (max/min ‚â• 10) - consider filtering small groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Convergence Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONVERGENCE TROUBLESHOOTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüîß IF MODEL FAILS TO CONVERGE:\")\n",
    "print(\"\\n1. Data Issues:\")\n",
    "print(\"   - Scale predictors using step_normalize()\")\n",
    "print(\"   - Remove highly correlated predictors (VIF > 10)\")\n",
    "print(\"   - Check for extreme outliers\")\n",
    "\n",
    "print(\"\\n2. Model Specification:\")\n",
    "print(\"   - Simplify: Use random intercepts only (not slopes)\")\n",
    "print(\"   - Remove interaction terms\")\n",
    "print(\"   - Reduce number of random effects\")\n",
    "\n",
    "print(\"\\n3. Data Structure:\")\n",
    "print(\"   - Remove groups with <5 observations\")\n",
    "print(\"   - Check for singleton groups\")\n",
    "print(\"   - Ensure sufficient between-group variation\")\n",
    "\n",
    "print(\"\\n4. Estimation:\")\n",
    "print(\"   - MixedLM uses LBFGS optimization (default)\")\n",
    "print(\"   - Convergence warnings are common but often harmless\")\n",
    "print(\"   - Check if results are reasonable despite warning\")\n",
    "\n",
    "print(\"\\nüí° PREVENTION:\")\n",
    "print(\"   - Always normalize/scale predictors\")\n",
    "print(\"   - Start simple (intercepts only)\")\n",
    "print(\"   - Add complexity incrementally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Missing Data Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING DATA STRATEGIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. MISSING PREDICTORS:\")\n",
    "print(\"   - Use recipe steps for imputation:\")\n",
    "print(\"     ‚Ä¢ step_impute_median() for numeric\")\n",
    "print(\"     ‚Ä¢ step_impute_mode() for categorical\")\n",
    "print(\"     ‚Ä¢ step_impute_knn() for complex patterns\")\n",
    "\n",
    "print(\"\\n2. MISSING OUTCOMES:\")\n",
    "print(\"   - MixedLM uses listwise deletion (drops rows with missing outcome)\")\n",
    "print(\"   - This is appropriate for panel data\")\n",
    "print(\"   - Groups with all missing outcomes are automatically excluded\")\n",
    "\n",
    "print(\"\\n3. MISSING GROUPS (NEW GROUPS IN TEST):\")\n",
    "print(\"   - Panel regression handles this automatically\")\n",
    "print(\"   - New groups get population average prediction (fixed effects only)\")\n",
    "print(\"   - No group-specific adjustment without training data\")\n",
    "\n",
    "print(\"\\nüí° BEST PRACTICE:\")\n",
    "print(\"   Handle missing data BEFORE modeling:\")\n",
    "print(\"   - Use recipe imputation steps\")\n",
    "print(\"   - Document imputation strategy\")\n",
    "print(\"   - Check sensitivity to imputation method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Future: Cross-Validation for Panel Data (Conceptual)\n",
    "\n",
    "Cross-validation for panel data is more complex than standard CV because we must respect:\n",
    "1. **Time ordering**: Don't train on future to predict past\n",
    "2. **Group structure**: Decide whether to evaluate on seen vs unseen groups\n",
    "\n",
    "Here's a conceptual outline (implementation in future release):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROSS-VALIDATION STRATEGIES (FUTURE FEATURE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. TIME SERIES CV (WITHIN GROUPS):\")\n",
    "print(\"   - Create per-group rolling/expanding windows\")\n",
    "print(\"   - Evaluate on future time periods within each group\")\n",
    "print(\"   - Tests: Can we forecast future for existing groups?\")\n",
    "print(\"\\n   Example:\")\n",
    "print(\"   for group in groups:\")\n",
    "print(\"       cv_folds = time_series_cv(group_data, initial='60 weeks', assess='10 weeks')\")\n",
    "print(\"       metrics = evaluate_on_folds(cv_folds)\")\n",
    "\n",
    "print(\"\\n2. GROUP-BASED CV (LEAVE-ONE-GROUP-OUT):\")\n",
    "print(\"   - Train on K-1 groups, test on 1 held-out group\")\n",
    "print(\"   - Repeat for each group\")\n",
    "print(\"   - Tests: Can we predict new groups?\")\n",
    "print(\"\\n   Example:\")\n",
    "print(\"   for test_group in groups:\")\n",
    "print(\"       train = data[data.group != test_group]\")\n",
    "print(\"       test = data[data.group == test_group]\")\n",
    "print(\"       fit_and_evaluate(train, test)\")\n",
    "\n",
    "print(\"\\n3. BLOCKED CV (COMBINATIONS):\")\n",
    "print(\"   - Combine time-based and group-based splits\")\n",
    "print(\"   - More complex but more realistic\")\n",
    "print(\"   - Tests both temporal and group generalization\")\n",
    "\n",
    "print(\"\\nüí° CURRENT WORKAROUND:\")\n",
    "print(\"   Use manual train/test splits as shown in this notebook.\")\n",
    "print(\"   Evaluate on chronologically later data for time series.\")\n",
    "print(\"   Evaluate on held-out groups for new group prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Train/Test Evaluation**:\n",
    "   - Use time-based splits for time series data\n",
    "   - Monitor train vs test performance to detect overfitting\n",
    "   - Expect some degradation (5-15% is normal)\n",
    "\n",
    "2. **Residual Diagnostics**:\n",
    "   - Check normality (Q-Q plot, Shapiro-Wilk)\n",
    "   - Check homoskedasticity (scale-location plot, Breusch-Pagan)\n",
    "   - Check autocorrelation (ACF plot, Durbin-Watson, Ljung-Box)\n",
    "   - Inspect per-group residuals for outlier factories\n",
    "\n",
    "3. **Outlier Detection**:\n",
    "   - Standardized residuals > 2.5 are potential outliers\n",
    "   - Some outliers are expected (‚âà1% if normal)\n",
    "   - Investigate groups with excessive outliers\n",
    "\n",
    "4. **Data Requirements**:\n",
    "   - Minimum 5-10 observations per group for random intercepts\n",
    "   - Minimum 20+ observations per group for random slopes\n",
    "   - At least 5-10 groups for reliable variance estimation\n",
    "   - Unbalanced panels are OK (MixedLM handles them)\n",
    "\n",
    "5. **Model Selection Guidelines**:\n",
    "   - Start simple (random intercepts only)\n",
    "   - Add random slopes only if justified\n",
    "   - Use AIC/BIC for comparison (improvement > 10 points is meaningful)\n",
    "   - Prioritize interpretability over complexity\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "‚ùå **Don't**:\n",
    "- Use panel_reg() with <5 observations per group\n",
    "- Add random slopes without sufficient data (20+ per group)\n",
    "- Ignore convergence warnings (check results still make sense)\n",
    "- Use unscaled predictors (always normalize)\n",
    "- Forget to check residual diagnostics\n",
    "\n",
    "‚úÖ **Do**:\n",
    "- Normalize/scale predictors with step_normalize()\n",
    "- Check ICC to justify panel model (ICC > 0.1)\n",
    "- Inspect per-group fits for outliers\n",
    "- Start simple and add complexity incrementally\n",
    "- Validate on held-out data\n",
    "\n",
    "### Decision Tree: panel_reg() vs Alternatives\n",
    "\n",
    "```\n",
    "Do you have grouped/panel data?\n",
    "‚îú‚îÄ No ‚Üí Use linear_reg() or other standard models\n",
    "‚îî‚îÄ Yes\n",
    "   ‚îú‚îÄ ICC < 0.1 (low group effect)\n",
    "   ‚îÇ  ‚îî‚îÄ Use linear_reg() with group as dummy variable\n",
    "   ‚îî‚îÄ ICC > 0.1 (moderate to high group effect)\n",
    "      ‚îú‚îÄ < 5 observations per group\n",
    "      ‚îÇ  ‚îî‚îÄ Use linear_reg() with fixed effects (dummies)\n",
    "      ‚îî‚îÄ ‚â• 5 observations per group\n",
    "         ‚îú‚îÄ 5-20 observations per group\n",
    "         ‚îÇ  ‚îî‚îÄ Use panel_reg() with random intercepts only\n",
    "         ‚îî‚îÄ > 20 observations per group\n",
    "            ‚îú‚îÄ Theory/visuals suggest parallel slopes\n",
    "            ‚îÇ  ‚îî‚îÄ Use panel_reg() with random intercepts only\n",
    "            ‚îî‚îÄ Theory/visuals suggest varying slopes\n",
    "               ‚îî‚îÄ Use panel_reg() with random intercepts + slopes\n",
    "```\n",
    "\n",
    "### Next Steps for Real-World Applications\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Clean and preprocess data\n",
    "   - Handle missing values\n",
    "   - Create recipe with normalization\n",
    "\n",
    "2. **Model Development**:\n",
    "   - Fit random intercepts model first\n",
    "   - Check ICC and residual diagnostics\n",
    "   - Consider random slopes if justified\n",
    "\n",
    "3. **Model Validation**:\n",
    "   - Evaluate on held-out data\n",
    "   - Check per-group performance\n",
    "   - Identify outliers and influential groups\n",
    "\n",
    "4. **Deployment**:\n",
    "   - Document model assumptions\n",
    "   - Monitor performance over time\n",
    "   - Retrain periodically with new data\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- **Books**:\n",
    "  - Gelman & Hill (2006): Data Analysis Using Regression and Multilevel/Hierarchical Models\n",
    "  - Snijders & Bosker (2011): Multilevel Analysis\n",
    "\n",
    "- **Online**:\n",
    "  - statsmodels MixedLM documentation\n",
    "  - Panel data analysis tutorials\n",
    "  - Mixed effects model interpretation guides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
