{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing Demo 2: Grouped/Panel Modeling\n",
    "\n",
    "This notebook demonstrates parallel execution for grouped/panel data modeling:\n",
    "- `Workflow.fit_nested()` - Fit separate models per group in parallel\n",
    "- Per-group preprocessing with `per_group_prep=True`\n",
    "- Progress tracking with `verbose=True`\n",
    "- Per-group results analysis\n",
    "- Performance comparisons (sequential vs parallel)\n",
    "\n",
    "**Key Features Demonstrated:**\n",
    "- ‚úÖ `n_jobs` parameter for grouped modeling\n",
    "- ‚úÖ CPU warning system for panel data\n",
    "- ‚úÖ Per-group preprocessing strategies\n",
    "- ‚úÖ Speedup measurements for nested models\n",
    "- ‚úÖ Per-group metrics and coefficient comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_workflows import workflow\n",
    "from py_parsnip import linear_reg\n",
    "from py_recipes import recipe, all_numeric_predictors\n",
    "from py_yardstick import metric_set, rmse, mae, r_squared\n",
    "from py_tune.parallel_utils import get_cpu_count\n",
    "\n",
    "# Seaborn styling\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv('_md/__data/preem.csv')\n",
    "df = raw_data.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Grouped Data\n",
    "\n",
    "We'll create 4 groups by assigning regions to simulate panel/grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create groups by splitting data into regions\n",
    "# Assign regions cyclically to create balanced groups\n",
    "n_groups = 4\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "df['region'] = [regions[i % n_groups] for i in range(len(df))]\n",
    "\n",
    "# Check group sizes\n",
    "group_counts = df['region'].value_counts().sort_index()\n",
    "print(\"Group sizes:\")\n",
    "print(group_counts)\n",
    "\n",
    "# Show sample\n",
    "display(df[['date', 'target', 'region']].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "FORMULA = \"target ~ .\"\n",
    "\n",
    "print(f\"Formula: {FORMULA}\")\n",
    "print(f\"Groups: {df['region'].nunique()}\")\n",
    "print(f\"Total observations: {len(df)}\")\n",
    "print(f\"Observations per group: ~{len(df) // df['region'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "cpu_count = get_cpu_count()\n",
    "print(f\"‚úì Detected {cpu_count} CPU cores\")\n",
    "print(f\"‚úì Joblib backend: loky (multiprocessing)\")\n",
    "print(f\"\\nThis system can efficiently run up to {cpu_count} parallel jobs.\")\n",
    "print(f\"With {n_groups} groups, parallel execution should provide speedup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Nested Modeling (Sequential vs Parallel)\n",
    "\n",
    "First, we'll compare sequential vs parallel execution for basic grouped modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple workflow\n",
    "wf = workflow().add_formula(FORMULA).add_model(linear_reg())\n",
    "\n",
    "print(f\"Workflow: Linear Regression\")\n",
    "print(f\"Groups: {n_groups} regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Execution (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential nested fitting\n",
    "print(\"Running SEQUENTIAL fit_nested()...\")\n",
    "start = time.time()\n",
    "nested_fit_seq = wf.fit_nested(\n",
    "    df,\n",
    "    group_col='region',\n",
    "    n_jobs=1,  # Sequential\n",
    "    verbose=True\n",
    ")\n",
    "seq_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚úì Sequential execution completed in {seq_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sequential results\n",
    "outputs_seq, coeffs_seq, stats_seq = nested_fit_seq.extract_outputs()\n",
    "\n",
    "print(\"\\nPer-group statistics (sequential):\")\n",
    "display(stats_seq[['group', 'n', 'split', 'rmse_mean', 'mae_mean', 'r_squared']].sort_values('group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution with All Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel nested fitting\n",
    "print(f\"Running PARALLEL fit_nested() (n_jobs=-1, using all {cpu_count} cores)...\")\n",
    "start = time.time()\n",
    "nested_fit_par = wf.fit_nested(\n",
    "    df,\n",
    "    group_col='region',\n",
    "    n_jobs=-1,  # Use all cores\n",
    "    verbose=True\n",
    ")\n",
    "par_time = time.time() - start\n",
    "\n",
    "speedup = seq_time / par_time\n",
    "efficiency = (speedup / cpu_count) * 100\n",
    "\n",
    "print(f\"\\n‚úì Parallel execution completed in {par_time:.2f} seconds\")\n",
    "print(f\"‚úì Speedup: {speedup:.2f}x\")\n",
    "print(f\"‚úì Efficiency: {efficiency:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results are identical\n",
    "outputs_par, coeffs_par, stats_par = nested_fit_par.extract_outputs()\n",
    "\n",
    "print(\"Consistency Check (per group):\")\n",
    "for group in sorted(df['region'].unique()):\n",
    "    stats_seq_group = stats_seq[stats_seq['group'] == group]\n",
    "    stats_par_group = stats_par[stats_par['group'] == group]\n",
    "    \n",
    "    rmse_seq = stats_seq_group[stats_seq_group['split'] == 'train']['rmse'].values[0]\n",
    "    rmse_par = stats_par_group[stats_par_group['split'] == 'train']['rmse'].values[0]\n",
    "    \n",
    "    match = np.isclose(rmse_seq, rmse_par, rtol=1e-10)\n",
    "    status = \"‚úì IDENTICAL\" if match else \"‚úó DIFFERENT\"\n",
    "    print(f\"  {group}: {status} (RMSE: {rmse_seq:.4f})\")\n",
    "\n",
    "print(\"\\n‚úì All parallel executions produce identical results to sequential!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison\n",
    "perf_df = pd.DataFrame({\n",
    "    'Configuration': ['Sequential', f'Parallel ({cpu_count} cores)'],\n",
    "    'n_jobs': [1, -1],\n",
    "    'Time (s)': [seq_time, par_time],\n",
    "    'Speedup': [1.0, speedup],\n",
    "    'Efficiency (%)': [100.0, efficiency]\n",
    "})\n",
    "\n",
    "display(perf_df)\n",
    "\n",
    "# Plot speedup\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Time comparison\n",
    "ax1.bar(perf_df['Configuration'], perf_df['Time (s)'], color=['gray', 'green'])\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_title('fit_nested() Execution Time')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speedup\n",
    "ax2.bar(perf_df['Configuration'], perf_df['Speedup'], color=['gray', 'green'])\n",
    "ax2.set_ylabel('Speedup (x)')\n",
    "ax2.set_title('fit_nested() Speedup vs Sequential')\n",
    "ax2.axhline(y=1, color='r', linestyle='--', label='Baseline')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Per-Group Preprocessing\n",
    "\n",
    "Demonstrate parallel execution with per-group preprocessing using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflow with PCA preprocessing\n",
    "rec_pca = (\n",
    "    recipe(df, FORMULA)\n",
    "    .step_normalize(all_numeric_predictors())\n",
    "    .step_pca(all_numeric_predictors(), num_comp=3)\n",
    ")\n",
    "\n",
    "wf_pca = workflow().add_recipe(rec_pca).add_model(linear_reg())\n",
    "\n",
    "print(\"Workflow with PCA:\")\n",
    "print(\"  - Normalize numeric predictors\")\n",
    "print(\"  - PCA: Reduce to 3 components\")\n",
    "print(\"  - Linear regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Preprocessing (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global preprocessing: Same PCA transformation for all groups\n",
    "print(\"Running fit_nested() with GLOBAL preprocessing...\")\n",
    "start = time.time()\n",
    "nested_fit_global = wf_pca.fit_nested(\n",
    "    df,\n",
    "    group_col='region',\n",
    "    per_group_prep=False,  # Global preprocessing\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "global_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚úì Global preprocessing completed in {global_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View global preprocessing results\n",
    "_, _, stats_global = nested_fit_global.extract_outputs()\n",
    "\n",
    "print(\"\\nPer-group statistics (global preprocessing):\")\n",
    "display(stats_global[['group', 'split', 'rmse_mean', 'mae_mean', 'r_squared']].sort_values('group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Group Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-group preprocessing: Each group gets its own PCA transformation\n",
    "print(\"Running fit_nested() with PER-GROUP preprocessing...\")\n",
    "start = time.time()\n",
    "nested_fit_pergroup = wf_pca.fit_nested(\n",
    "    df,\n",
    "    group_col='region',\n",
    "    per_group_prep=True,  # Per-group preprocessing\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "pergroup_time = time.time() - start\n",
    "\n",
    "print(f\"\\n‚úì Per-group preprocessing completed in {pergroup_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View per-group preprocessing results\n",
    "_, _, stats_pergroup = nested_fit_pergroup.extract_outputs()\n",
    "\n",
    "print(\"\\nPer-group statistics (per-group preprocessing):\")\n",
    "display(stats_pergroup[['group', 'split', 'rmse_mean', 'mae_mean', 'r_squared']].sort_values('group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature differences\n",
    "feature_comparison = nested_fit_pergroup.get_feature_comparison()\n",
    "\n",
    "print(\"\\nFeature comparison across groups:\")\n",
    "display(feature_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare global vs per-group preprocessing performance\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Strategy': ['Global Preprocessing', 'Per-Group Preprocessing'],\n",
    "    'Time (s)': [global_time, pergroup_time],\n",
    "    'Avg RMSE': [\n",
    "        stats_global[stats_global['split'] == 'train']['rmse'].mean(),\n",
    "        stats_pergroup[stats_pergroup['split'] == 'train']['rmse'].mean()\n",
    "    ],\n",
    "    'Avg MAE': [\n",
    "        stats_global[stats_global['split'] == 'train']['mae'].mean(),\n",
    "        stats_pergroup[stats_pergroup['split'] == 'train']['mae'].mean()\n",
    "    ],\n",
    "    'Avg R¬≤': [\n",
    "        stats_global[stats_global['split'] == 'train']['r_squared'].mean(),\n",
    "        stats_pergroup[stats_pergroup['split'] == 'train']['r_squared'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R¬≤']\n",
    "colors = ['blue', 'orange']\n",
    "\n",
    "for i, (metric, col) in enumerate(zip(metrics, ['Avg RMSE', 'Avg MAE', 'Avg R¬≤'])):\n",
    "    axes[i].bar(comparison_df['Strategy'], comparison_df[col], color=colors)\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].set_title(f'Average {metric} by Strategy')\n",
    "    axes[i].tick_params(axis='x', rotation=15)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Per-Group Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and compare coefficients across groups\n",
    "_, coeffs, _ = nested_fit_seq.extract_outputs()\n",
    "\n",
    "# Pivot to compare coefficients\n",
    "coeff_pivot = coeffs[coeffs['term'] != 'Intercept'].pivot(\n",
    "    index='term',\n",
    "    columns='group',\n",
    "    values='estimate'\n",
    ")\n",
    "\n",
    "print(\"\\nCoefficient comparison across groups:\")\n",
    "display(coeff_pivot.head(10))\n",
    "\n",
    "# Calculate coefficient variance across groups\n",
    "coeff_variance = coeff_pivot.var(axis=1).sort_values(ascending=False)\n",
    "print(\"\\nTop 5 most variable coefficients across groups:\")\n",
    "print(coeff_variance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient heterogeneity\n",
    "top_vars = coeff_variance.head(6).index\n",
    "coeff_subset = coeff_pivot.loc[top_vars]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "coeff_subset.T.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Coefficient Variation Across Groups (Top 6 Most Variable)')\n",
    "ax.set_xlabel('Region')\n",
    "ax.set_ylabel('Coefficient Estimate')\n",
    "ax.legend(title='Feature', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Coefficient variation suggests heterogeneity - nested modeling is appropriate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-group performance comparison\n",
    "stats_train = stats_seq[stats_seq['split'] == 'train'].sort_values('group')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# RMSE by group\n",
    "axes[0].bar(stats_train['group'], stats_train['rmse'], color='steelblue')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('RMSE by Group')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# MAE by group\n",
    "axes[1].bar(stats_train['group'], stats_train['mae'], color='coral')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('MAE by Group')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# R¬≤ by group\n",
    "axes[2].bar(stats_train['group'], stats_train['r_squared'], color='mediumseagreen')\n",
    "axes[2].set_ylabel('R¬≤')\n",
    "axes[2].set_title('R¬≤ by Group')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: CPU Warning Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: n_jobs > Number of Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger inefficiency warning\n",
    "print(f\"Data has {n_groups} groups. Requesting {cpu_count * 2} workers...\\n\")\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    nested_fit_ineff = wf.fit_nested(\n",
    "        df,\n",
    "        group_col='region',\n",
    "        n_jobs=cpu_count * 2,  # More workers than groups\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if w:\n",
    "        print(\"‚ö†Ô∏è  WARNING TRIGGERED:\")\n",
    "        print(f\"    {w[0].message}\")\n",
    "        print(f\"\\nüí° Recommendation: Use n_jobs={n_groups} (number of groups) instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PARALLEL GROUPED MODELING PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSystem: {cpu_count} CPU cores\")\n",
    "print(f\"Data: {len(df)} observations, {n_groups} groups\")\n",
    "\n",
    "print(f\"\\n1. Basic Nested Modeling\")\n",
    "print(f\"   Sequential: {seq_time:.2f}s\")\n",
    "print(f\"   Parallel (all cores): {par_time:.2f}s (speedup: {speedup:.2f}x)\")\n",
    "\n",
    "print(f\"\\n2. With PCA Preprocessing\")\n",
    "print(f\"   Global preprocessing: {global_time:.2f}s\")\n",
    "print(f\"   Per-group preprocessing: {pergroup_time:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Use parallel nested modeling (n_jobs=-1) when:\")\n",
    "print(f\"   - You have multiple groups (>{cpu_count-1})\")\n",
    "print(f\"   - Per-group models are computationally expensive\")\n",
    "print(f\"   - Groups exhibit heterogeneous patterns (different coefficients)\")\n",
    "print(f\"   - You need per-group predictions\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Consider sequential execution (n_jobs=1) when:\")\n",
    "print(f\"   - Few groups (< {cpu_count})\")\n",
    "print(f\"   - Simple/fast models\")\n",
    "print(f\"   - Debugging (easier error tracing)\")\n",
    "\n",
    "print(f\"\\nüí° Preprocessing Tips:\")\n",
    "print(f\"   - Use per_group_prep=True when groups have different feature distributions\")\n",
    "print(f\"   - Use per_group_prep=False (default) for consistency across groups\")\n",
    "print(f\"   - PCA, feature selection benefit from per-group preprocessing\")\n",
    "print(f\"   - Check feature_comparison() to see preprocessing differences\")\n",
    "\n",
    "print(f\"\\nüí° Performance Tips:\")\n",
    "print(f\"   - Set n_jobs to min(n_groups, cpu_count) for optimal efficiency\")\n",
    "print(f\"   - Use verbose=True to monitor progress\")\n",
    "print(f\"   - Watch for CPU warnings to avoid inefficiencies\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-tidymodels2",
   "language": "python",
   "name": "py-tidymodels2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
