{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel Regression Basics: Random Intercepts and ICC\n",
    "\n",
    "## Introduction to Panel Regression\n",
    "\n",
    "**Panel regression** (also known as **mixed effects models**, **multilevel models**, or **hierarchical linear models**) is designed for data with a grouped/hierarchical structure where observations within groups are correlated.\n",
    "\n",
    "### When to Use Panel Regression\n",
    "\n",
    "Use `panel_reg()` instead of `linear_reg()` when:\n",
    "- Your data has multiple groups/entities (stores, patients, countries, etc.)\n",
    "- Observations within groups are likely correlated\n",
    "- Groups have different baseline levels but similar slopes\n",
    "- You want to borrow strength across groups (partial pooling)\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Random Intercepts**: Each group has its own baseline level\n",
    "- Premium stores might have higher baseline sales than budget stores\n",
    "- But price sensitivity (slope) is similar across stores\n",
    "- More efficient than creating dummy variables for each group\n",
    "\n",
    "**Intraclass Correlation Coefficient (ICC)**: Proportion of total variance due to group differences\n",
    "- ICC < 0.3: Low (most variance within groups) - consider linear_reg()\n",
    "- ICC 0.3-0.7: Medium (mixed) - panel_reg() beneficial\n",
    "- ICC > 0.7: High (most variance between groups) - panel_reg() highly beneficial\n",
    "\n",
    "**Variance Components**: Panel regression partitions variance into:\n",
    "- **Between-group variance**: How much groups differ in their baselines\n",
    "- **Within-group variance**: How much observations vary within each group\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Generate realistic multi-store sales data with group structure\n",
    "2. Fit a basic panel regression model with random intercepts\n",
    "3. Extract and interpret the three-DataFrame outputs\n",
    "4. Calculate and interpret the ICC\n",
    "5. Compare panel_reg() with linear_reg()\n",
    "6. Make predictions for training stores and new stores\n",
    "7. Visualize group-specific effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# py-tidymodels imports\n",
    "from py_parsnip import panel_reg, linear_reg\n",
    "from py_workflows import workflow\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Multi-Store Sales Data\n",
    "\n",
    "We'll create a realistic dataset with:\n",
    "- **10 stores**: 5 premium stores (higher baseline sales) + 5 budget stores (lower baseline)\n",
    "- **52 weeks** of data per store = 520 total observations\n",
    "- **Variables**:\n",
    "  - `sales`: Weekly sales (outcome)\n",
    "  - `price`: Product price (predictor)\n",
    "  - `advertising`: Advertising spend (predictor)\n",
    "  - `store_id`: Store identifier (group)\n",
    "\n",
    "**Data Generating Process**:\n",
    "- Premium stores: Baseline ~150 units/week\n",
    "- Budget stores: Baseline ~100 units/week\n",
    "- Price effect: -2.5 (same for all stores)\n",
    "- Advertising effect: +1.5 (same for all stores)\n",
    "- Within-store noise: œÉ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_stores = 10\n",
    "n_weeks = 52\n",
    "n_total = n_stores * n_weeks\n",
    "\n",
    "# Store types\n",
    "store_types = ['Premium'] * 5 + ['Budget'] * 5\n",
    "store_ids = [f'Store_{i+1:02d}' for i in range(n_stores)]\n",
    "\n",
    "# Random intercepts (baseline sales by store)\n",
    "# Premium stores: mean 150, Budget stores: mean 100\n",
    "random_intercepts = np.array(\n",
    "    [np.random.normal(150, 15) for _ in range(5)] +  # Premium\n",
    "    [np.random.normal(100, 15) for _ in range(5)]    # Budget\n",
    ")\n",
    "\n",
    "# Fixed effects\n",
    "beta_price = -2.5\n",
    "beta_advertising = 1.5\n",
    "\n",
    "# Generate data\n",
    "data_list = []\n",
    "\n",
    "for i, store_id in enumerate(store_ids):\n",
    "    # Predictors\n",
    "    price = np.random.uniform(15, 25, n_weeks)\n",
    "    advertising = np.random.uniform(5, 15, n_weeks)\n",
    "    week = np.arange(1, n_weeks + 1)\n",
    "    \n",
    "    # Sales = intercept + price*beta + advertising*beta + noise\n",
    "    sales = (\n",
    "        random_intercepts[i] + \n",
    "        beta_price * price + \n",
    "        beta_advertising * advertising + \n",
    "        np.random.normal(0, 10, n_weeks)\n",
    "    )\n",
    "    \n",
    "    store_data = pd.DataFrame({\n",
    "        'store_id': store_id,\n",
    "        'store_type': store_types[i],\n",
    "        'week': week,\n",
    "        'price': price,\n",
    "        'advertising': advertising,\n",
    "        'sales': sales\n",
    "    })\n",
    "    \n",
    "    data_list.append(store_data)\n",
    "\n",
    "# Combine all stores\n",
    "sales_data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Dataset shape: {sales_data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(sales_data.head(10))\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(sales_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize store-level variation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Mean sales by store\n",
    "mean_sales_by_store = sales_data.groupby(['store_id', 'store_type'])['sales'].mean().reset_index()\n",
    "colors = ['steelblue' if t == 'Premium' else 'coral' for t in mean_sales_by_store['store_type']]\n",
    "\n",
    "axes[0].bar(range(len(mean_sales_by_store)), mean_sales_by_store['sales'], color=colors)\n",
    "axes[0].set_xlabel('Store ID')\n",
    "axes[0].set_ylabel('Mean Sales')\n",
    "axes[0].set_title('Mean Sales by Store (Premium vs Budget)')\n",
    "axes[0].set_xticks(range(len(mean_sales_by_store)))\n",
    "axes[0].set_xticklabels(mean_sales_by_store['store_id'], rotation=45)\n",
    "axes[0].axhline(y=mean_sales_by_store['sales'].mean(), color='black', linestyle='--', label='Overall Mean')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Distribution by store type\n",
    "sales_data.boxplot(column='sales', by='store_type', ax=axes[1])\n",
    "axes[1].set_xlabel('Store Type')\n",
    "axes[1].set_ylabel('Sales')\n",
    "axes[1].set_title('Sales Distribution by Store Type')\n",
    "plt.suptitle('')  # Remove auto title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Observation: Premium stores have consistently higher sales than budget stores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit Basic Panel Model - Random Intercepts\n",
    "\n",
    "We'll fit a panel regression model with:\n",
    "- **Random intercepts**: Each store has its own baseline sales level\n",
    "- **Fixed effects**: Price and advertising effects are the same across all stores\n",
    "\n",
    "The model is: `sales ~ price + advertising` with random intercepts for `store_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create panel regression specification\n",
    "spec = panel_reg(random_effects=\"intercept\")  # Random intercepts only (default)\n",
    "\n",
    "# Create workflow\n",
    "wf = workflow().add_formula(\"sales ~ price + advertising\").add_model(spec)\n",
    "\n",
    "# Fit using fit_global() to specify group column\n",
    "fit = wf.fit_global(sales_data, group_col='store_id')\n",
    "\n",
    "print(\"‚úÖ Panel regression model fitted successfully!\")\n",
    "print(f\"\\nModel type: {fit.spec.model_type}\")\n",
    "print(f\"Random effects: {fit.spec.args['random_effects']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract and Interpret Three-DataFrame Outputs\n",
    "\n",
    "Panel regression returns the standard three DataFrames:\n",
    "1. **Outputs**: Observation-level predictions, actuals, residuals (with `group` column)\n",
    "2. **Coefficients**: Fixed effects + variance components for random effects\n",
    "3. **Stats**: Model-level metrics including ICC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Outputs DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, coefficients, stats = fit.extract_outputs()\n",
    "\n",
    "print(\"Outputs DataFrame (first 10 rows):\")\n",
    "print(outputs.head(10))\n",
    "print(f\"\\nShape: {outputs.shape}\")\n",
    "print(f\"Columns: {list(outputs.columns)}\")\n",
    "print(f\"\\nNote: 'group' column shows which store each observation belongs to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fitted values by store\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, store_id in enumerate(sorted(outputs['group'].unique())):\n",
    "    store_data = outputs[outputs['group'] == store_id]\n",
    "    \n",
    "    axes[i].scatter(store_data['actuals'], store_data['fitted'], alpha=0.6, s=30)\n",
    "    axes[i].plot([store_data['actuals'].min(), store_data['actuals'].max()],\n",
    "                 [store_data['actuals'].min(), store_data['actuals'].max()],\n",
    "                 'r--', lw=1)\n",
    "    axes[i].set_title(store_id, fontsize=10)\n",
    "    axes[i].set_xlabel('Actual Sales')\n",
    "    axes[i].set_ylabel('Fitted Sales')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Actual vs Fitted Sales by Store', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Each store's predictions follow the 45¬∞ line closely, indicating good fit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Coefficients DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients DataFrame:\")\n",
    "print(coefficients)\n",
    "print(f\"\\nFixed effects (type='fixed'):\")\n",
    "print(coefficients[coefficients['type'] == 'fixed'][['variable', 'coefficient', 'std_error', 'p_value']])\n",
    "print(f\"\\nRandom effects variance components (type='random'):\")\n",
    "print(coefficients[coefficients['type'] == 'random'][['variable', 'coefficient', 'type']])\n",
    "print(f\"\\nResidual variance (type='residual'):\")\n",
    "print(coefficients[coefficients['type'] == 'residual'][['variable', 'coefficient', 'type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret fixed effects\n",
    "fixed_effects = coefficients[coefficients['type'] == 'fixed']\n",
    "price_coef = fixed_effects[fixed_effects['variable'] == 'price']['coefficient'].values[0]\n",
    "price_pval = fixed_effects[fixed_effects['variable'] == 'price']['p_value'].values[0]\n",
    "ad_coef = fixed_effects[fixed_effects['variable'] == 'advertising']['coefficient'].values[0]\n",
    "ad_pval = fixed_effects[fixed_effects['variable'] == 'advertising']['p_value'].values[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIXED EFFECTS INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüí∞ Price Effect: {price_coef:.3f}\")\n",
    "print(f\"   ‚Üí For every $1 increase in price, sales decrease by {abs(price_coef):.2f} units\")\n",
    "print(f\"   ‚Üí p-value: {price_pval:.4f} {'(significant)' if price_pval < 0.05 else '(not significant)'}\")\n",
    "print(f\"\\nüì¢ Advertising Effect: {ad_coef:.3f}\")\n",
    "print(f\"   ‚Üí For every $1 increase in advertising, sales increase by {ad_coef:.2f} units\")\n",
    "print(f\"   ‚Üí p-value: {ad_pval:.4f} {'(significant)' if ad_pval < 0.05 else '(not significant)'}\")\n",
    "\n",
    "# Interpret variance components\n",
    "re_intercept_var = coefficients[coefficients['variable'] == 'RE: Intercept Variance']['coefficient'].values[0]\n",
    "residual_var = coefficients[coefficients['variable'] == 'Residual Variance']['coefficient'].values[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VARIANCE COMPONENTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüè™ Between-Store Variance (Random Intercept): {re_intercept_var:.3f}\")\n",
    "print(f\"   ‚Üí Variance in baseline sales levels across stores\")\n",
    "print(f\"\\nüìä Within-Store Variance (Residual): {residual_var:.3f}\")\n",
    "print(f\"   ‚Üí Variance in sales within each store (unexplained by model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Stats DataFrame and ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats DataFrame (key metrics):\")\n",
    "key_metrics = ['rmse', 'mae', 'r_squared', 'adj_r_squared', 'icc', 'n_groups', 'aic', 'bic']\n",
    "stats_subset = stats[stats['metric'].isin(key_metrics)][['metric', 'value', 'split']]\n",
    "print(stats_subset.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and interpret ICC\n",
    "icc = stats[stats['metric'] == 'icc']['value'].values[0]\n",
    "rmse = stats[stats['metric'] == 'rmse']['value'].values[0]\n",
    "r_squared = stats[stats['metric'] == 'r_squared']['value'].values[0]\n",
    "n_groups = int(stats[stats['metric'] == 'n_groups']['value'].values[0])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTRACLASS CORRELATION COEFFICIENT (ICC)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nICC = {icc:.4f} ({icc*100:.2f}%)\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  ‚Üí {icc*100:.1f}% of total variance is due to differences BETWEEN stores\")\n",
    "print(f\"  ‚Üí {(1-icc)*100:.1f}% of total variance is due to variation WITHIN stores\")\n",
    "\n",
    "if icc < 0.3:\n",
    "    print(f\"\\nüìä ICC < 0.3: LOW group effect\")\n",
    "    print(f\"   Most variance is within stores. linear_reg() might be sufficient.\")\n",
    "elif icc < 0.7:\n",
    "    print(f\"\\nüìä ICC 0.3-0.7: MEDIUM group effect\")\n",
    "    print(f\"   Substantial between-store variation. panel_reg() is beneficial.\")\n",
    "else:\n",
    "    print(f\"\\nüìä ICC > 0.7: HIGH group effect\")\n",
    "    print(f\"   Most variance is between stores. panel_reg() is highly beneficial.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRMSE: {rmse:.3f} units\")\n",
    "print(f\"R¬≤: {r_squared:.4f}\")\n",
    "print(f\"Number of stores: {n_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ICC\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create pie chart\n",
    "sizes = [icc, 1-icc]\n",
    "labels = [f'Between-Store\\nVariance\\n({icc*100:.1f}%)', \n",
    "          f'Within-Store\\nVariance\\n({(1-icc)*100:.1f}%)']\n",
    "colors = ['steelblue', 'lightcoral']\n",
    "explode = (0.05, 0)\n",
    "\n",
    "ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='',\n",
    "       shadow=True, startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "ax.set_title(f'Variance Decomposition (ICC = {icc:.4f})', fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüîë Key Takeaway: The ICC of {icc:.4f} indicates that {icc*100:.1f}% of sales variance\")\n",
    "print(f\"   is explained by which store the observation comes from, justifying the use of panel_reg().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare with Linear Regression\n",
    "\n",
    "Let's compare panel_reg() with linear_reg() to see the differences:\n",
    "- **Linear regression**: Would need 10 dummy variables (one per store) to capture store effects\n",
    "- **Panel regression**: Uses 1 variance component to capture store effects\n",
    "\n",
    "This is called **partial pooling** - panel_reg() borrows strength across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression with store dummies\n",
    "spec_linear = linear_reg()\n",
    "wf_linear = workflow().add_formula(\"sales ~ price + advertising + C(store_id)\").add_model(spec_linear)\n",
    "fit_linear = wf_linear.fit(sales_data)\n",
    "\n",
    "print(\"‚úÖ Linear regression model fitted successfully!\")\n",
    "\n",
    "# Extract outputs\n",
    "outputs_linear, coefficients_linear, stats_linear = fit_linear.extract_outputs()\n",
    "\n",
    "# Compare number of parameters\n",
    "n_params_panel = len(coefficients[coefficients['type'] == 'fixed'])\n",
    "n_params_linear = len(coefficients_linear[coefficients_linear['type'] == 'fixed'])\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPanel Regression (Random Intercepts):\")\n",
    "print(f\"  ‚Üí Fixed effects: {n_params_panel} parameters (Intercept, price, advertising)\")\n",
    "print(f\"  ‚Üí Random effects: 1 variance component (store-level variation)\")\n",
    "print(f\"  ‚Üí Total parameters: {n_params_panel + 1}\")\n",
    "\n",
    "print(f\"\\nLinear Regression (Fixed Effects):\")\n",
    "print(f\"  ‚Üí Fixed effects: {n_params_linear} parameters (including 9 store dummies)\")\n",
    "print(f\"  ‚Üí No random effects\")\n",
    "print(f\"  ‚Üí Total parameters: {n_params_linear}\")\n",
    "\n",
    "print(f\"\\nüí° Efficiency Gain: Panel regression uses {n_params_linear - (n_params_panel + 1)} fewer parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance metrics\n",
    "rmse_panel = stats[stats['metric'] == 'rmse']['value'].values[0]\n",
    "rmse_linear = stats_linear[stats_linear['metric'] == 'rmse']['value'].values[0]\n",
    "r2_panel = stats[stats['metric'] == 'r_squared']['value'].values[0]\n",
    "r2_linear = stats_linear[stats_linear['metric'] == 'r_squared']['value'].values[0]\n",
    "aic_panel = stats[stats['metric'] == 'aic']['value'].values[0]\n",
    "aic_linear = stats_linear[stats_linear['metric'] == 'aic']['value'].values[0]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'R¬≤', 'AIC', 'Parameters'],\n",
    "    'Panel Regression': [f\"{rmse_panel:.3f}\", f\"{r2_panel:.4f}\", f\"{aic_panel:.1f}\", n_params_panel + 1],\n",
    "    'Linear Regression': [f\"{rmse_linear:.3f}\", f\"{r2_linear:.4f}\", f\"{aic_linear:.1f}\", n_params_linear]\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüéØ Both models have similar predictive performance, but panel_reg() is more\")\n",
    "print(f\"   parsimonious (fewer parameters) and provides interpretable variance components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel regression coefficients\n",
    "fixed_coefs = coefficients[coefficients['type'] == 'fixed'].copy()\n",
    "fixed_coefs = fixed_coefs[fixed_coefs['variable'] != 'Intercept']  # Exclude intercept for clarity\n",
    "axes[0].barh(fixed_coefs['variable'], fixed_coefs['coefficient'], color='steelblue')\n",
    "axes[0].set_xlabel('Coefficient')\n",
    "axes[0].set_title('Panel Regression: Fixed Effects')\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Linear regression coefficients (exclude store dummies for clarity)\n",
    "linear_main_coefs = coefficients_linear[\n",
    "    (~coefficients_linear['variable'].str.contains('store_id', case=False, na=False)) &\n",
    "    (coefficients_linear['variable'] != 'Intercept')\n",
    "].copy()\n",
    "axes[1].barh(linear_main_coefs['variable'], linear_main_coefs['coefficient'], color='coral')\n",
    "axes[1].set_xlabel('Coefficient')\n",
    "axes[1].set_title('Linear Regression: Main Effects')\n",
    "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Both models estimate similar price and advertising effects.\")\n",
    "print(\"   Panel regression captures store effects via variance components instead of dummies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions: Training Stores vs New Stores\n",
    "\n",
    "Panel regression handles predictions differently depending on whether the store was in the training data:\n",
    "\n",
    "- **Training stores**: Uses fixed effects + store-specific random effect\n",
    "- **New stores**: Uses fixed effects only (population average)\n",
    "\n",
    "This is called **shrinkage** or **partial pooling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data for Store_01 (training store)\n",
    "test_store_01 = pd.DataFrame({\n",
    "    'store_id': ['Store_01'] * 10,\n",
    "    'price': np.linspace(15, 25, 10),\n",
    "    'advertising': [10.0] * 10\n",
    "})\n",
    "\n",
    "# Create test data for Store_NEW (new store)\n",
    "test_store_new = pd.DataFrame({\n",
    "    'store_id': ['Store_NEW'] * 10,\n",
    "    'price': np.linspace(15, 25, 10),\n",
    "    'advertising': [10.0] * 10\n",
    "})\n",
    "\n",
    "# Make predictions\n",
    "preds_store_01 = fit.predict(test_store_01)\n",
    "preds_store_new = fit.predict(test_store_new)\n",
    "\n",
    "print(\"Predictions for Store_01 (training store):\")\n",
    "print(preds_store_01.head())\n",
    "print(f\"\\nPredictions for Store_NEW (new store):\")\n",
    "print(preds_store_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction differences\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "prices = test_store_01['price'].values\n",
    "ax.plot(prices, preds_store_01['.pred'].values, 'o-', label='Store_01 (training)', linewidth=2, markersize=8)\n",
    "ax.plot(prices, preds_store_new['.pred'].values, 's-', label='Store_NEW (new)', linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xlabel('Price ($)', fontsize=12)\n",
    "ax.set_ylabel('Predicted Sales', fontsize=12)\n",
    "ax.set_title('Predictions: Training Store vs New Store', fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mean_diff = (preds_store_01['.pred'].values - preds_store_new['.pred'].values).mean()\n",
    "print(f\"\\nüìç Prediction Difference:\")\n",
    "print(f\"   Training store (Store_01) predictions are {mean_diff:.2f} units higher on average.\")\n",
    "print(f\"   This reflects Store_01's positive random intercept (above-average baseline).\")\n",
    "print(f\"\\n   New stores get the 'population average' prediction (no store-specific adjustment).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Group-Specific Effects\n",
    "\n",
    "Let's extract and visualize the random effects (group-specific intercepts) for each store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract random effects from the fitted model\n",
    "random_effects_dict = fit.fit_data['random_effects']\n",
    "group_col = fit.fit_data['group_col']\n",
    "\n",
    "# Convert to DataFrame\n",
    "random_effects_df = pd.DataFrame([\n",
    "    {'store_id': group, 'random_intercept': effects['Group']}\n",
    "    for group, effects in random_effects_dict.items()\n",
    "]).sort_values('random_intercept', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Add store type\n",
    "random_effects_df = random_effects_df.merge(\n",
    "    sales_data[['store_id', 'store_type']].drop_duplicates(),\n",
    "    on='store_id'\n",
    ")\n",
    "\n",
    "print(\"Random Effects (Store-Specific Intercepts):\")\n",
    "print(random_effects_df.to_string(index=False))\n",
    "print(f\"\\nPositive values: Store has higher baseline sales than average\")\n",
    "print(f\"Negative values: Store has lower baseline sales than average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random effects\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['steelblue' if t == 'Premium' else 'coral' for t in random_effects_df['store_type']]\n",
    "bars = ax.barh(random_effects_df['store_id'], random_effects_df['random_intercept'], color=colors)\n",
    "\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=2, label='Population Average')\n",
    "ax.set_xlabel('Random Intercept (Deviation from Mean)', fontsize=12)\n",
    "ax.set_ylabel('Store ID', fontsize=12)\n",
    "ax.set_title('Store-Specific Random Intercepts (Panel Regression)', fontsize=14, weight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add custom legend for store types\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='steelblue', label='Premium'),\n",
    "    Patch(facecolor='coral', label='Budget')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèÜ Premium stores (blue) have positive random intercepts (higher baseline sales).\")\n",
    "print(\"üìâ Budget stores (coral) have negative random intercepts (lower baseline sales).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive residual diagnostic plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "residuals = outputs['residuals'].values\n",
    "fitted = outputs['fitted'].values\n",
    "\n",
    "# Plot 1: Residuals vs Fitted\n",
    "axes[0, 0].scatter(fitted, residuals, alpha=0.5, s=20)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Fitted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Residuals vs Fitted')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Q-Q Plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('Normal Q-Q Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Histogram of residuals\n",
    "axes[1, 0].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Residuals')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Distribution of Residuals')\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Residuals by group (boxplot)\n",
    "outputs.boxplot(column='residuals', by='group', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Store ID')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Residuals by Store')\n",
    "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)\n",
    "plt.suptitle('')  # Remove auto title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Residual diagnostics look good:\")\n",
    "print(\"   - Residuals vs Fitted: No clear patterns (homoskedasticity)\")\n",
    "print(\"   - Q-Q Plot: Residuals approximately normal\")\n",
    "print(\"   - Histogram: Centered at zero, roughly symmetric\")\n",
    "print(\"   - By Store: Similar residual distributions across stores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Panel regression** is designed for grouped/hierarchical data where observations within groups are correlated.\n",
    "\n",
    "2. **Random intercepts** allow each group to have its own baseline level while sharing common slopes.\n",
    "\n",
    "3. **ICC (Intraclass Correlation Coefficient)** quantifies the proportion of variance due to group differences:\n",
    "   - ICC < 0.3: Consider linear_reg()\n",
    "   - ICC 0.3-0.7: panel_reg() beneficial\n",
    "   - ICC > 0.7: panel_reg() highly beneficial\n",
    "\n",
    "4. **Variance components** partition total variance into:\n",
    "   - Between-group variance (random intercept variance)\n",
    "   - Within-group variance (residual variance)\n",
    "\n",
    "5. **Partial pooling**: Panel regression borrows strength across groups, using fewer parameters than fixed effects models.\n",
    "\n",
    "6. **Predictions** differ for training vs new groups:\n",
    "   - Training groups: Fixed + random effects\n",
    "   - New groups: Fixed effects only (population average)\n",
    "\n",
    "### When to Use panel_reg()\n",
    "\n",
    "‚úÖ **Use panel_reg() when:**\n",
    "- Data has multiple groups/entities\n",
    "- Observations within groups are correlated\n",
    "- Groups have different baselines but similar slopes\n",
    "- You want to estimate group-level variation\n",
    "- You need predictions for new groups\n",
    "\n",
    "‚ùå **Don't use panel_reg() when:**\n",
    "- No clear group structure\n",
    "- Very few groups (< 5)\n",
    "- Groups are too small (< 3 observations per group)\n",
    "- ICC is very low (< 0.1)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll explore:\n",
    "- **Random slopes**: Allowing groups to have different slopes (not just intercepts)\n",
    "- **Variance components**: Interpreting covariances between random effects\n",
    "- **Model comparison**: When to use random slopes vs intercepts only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
