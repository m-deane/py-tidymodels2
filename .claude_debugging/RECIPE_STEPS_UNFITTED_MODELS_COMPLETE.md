# Recipe Steps Unfitted Model Support - COMPLETE

**Date:** 2025-11-10
**Status:** ✅ ALL ISSUES RESOLVED

## User Issues Addressed

### Issue a) Pre-fitted Model Requirement
**Problem:** Users had to fit models before passing to recipe steps, violating recipe philosophy.

**Solution:** ✅ **FIXED**
- `step_select_permutation()` now accepts unfitted models
- `step_select_shap()` now accepts unfitted models
- `step_safe_v2()` now accepts unfitted models (NEW step)
- Models automatically fitted during `prep()` using recipe data

### Issue b) Same Pattern for Other Steps
**Problem:** step_select_permutation(), step_eix(), step_select_shap() had same pre-fitting requirement.

**Solution:** ✅ **FIXED**
- Fixed `step_select_permutation()` and `step_select_shap()`
- `step_eix()` intentionally requires pre-fitted model (analyzes tree structure, not just predictions)

### Issue c) Threshold Control
**Problem:** No way to control number of thresholds generated by step_safe().

**Solution:** ✅ **FIXED**
- Added `max_thresholds` parameter to `step_safe_v2()` (default=5)
- Selects most important changepoints based on PDP jump magnitude

### Issue d) LightGBM Special Characters
**Problem:** `[LightGBM] [Fatal] Do not support special JSON characters in feature name`

**Solution:** ✅ **FIXED**
- Implemented robust feature name sanitization: `re.sub(r'[^a-zA-Z0-9_]', '_', name)`
- Removes all special characters, consecutive underscores
- Fully compatible with LightGBM strict naming requirements

### Issue e) Importance on Original Features
**Problem:** Feature importances based on original features, not transformed conditional features.

**Solution:** ✅ **FIXED**
- `step_safe_v2()` recalculates importance on TRANSFORMED feature set
- Uses LightGBM after transformation is complete
- More accurate importance ranking

## Implementation Summary

### 1. step_safe_v2() - NEW Implementation

**File:** `py_recipes/steps/feature_extraction.py`

**Key Features:**
```python
.step_safe_v2(
    surrogate_model=GradientBoostingRegressor(n_estimators=100),  # UNFITTED
    outcome='target',
    penalty=10.0,
    max_thresholds=5,          # NEW: Control threshold count
    top_n=30,
    keep_original_cols=True,
    grid_resolution=100
)
```

**What It Does:**
1. Accepts UNFITTED surrogate model
2. Fits model during `prep()` using recipe data
3. Detects changepoints using PDP (Partial Dependence Plots)
4. Limits thresholds per feature to `max_thresholds`
5. Sanitizes feature names for LightGBM
6. Recalculates importance on TRANSFORMED features

**Inspection Methods:**
- `get_transformations()` - Returns dict of transformation metadata for each variable
  - Numeric: `changepoints`, `thresholds`, `intervals`, `new_names`
  - Categorical: `levels`, `merged_levels`, `new_names`
- `get_feature_importances()` - Returns DataFrame of feature importances on transformed features

**Tests:** 21/21 passing

### 2. step_select_permutation() - FIXED

**File:** `py_recipes/steps/filter_supervised.py:1366`

**Changes:**
- Added `_fitted_model` attribute
- Added `_is_model_fitted()` helper method
- Modified `prep()` to fit model if unfitted
- Updated `_compute_permutation_importance()` to use `_fitted_model`

**New Usage:**
```python
# OLD (pre-fitted required)
model = RandomForestRegressor()
model.fit(X_train, y_train)
rec = recipe().step_select_permutation(outcome='y', model=model, top_n=10)

# NEW (unfitted accepted)
rec = recipe().step_select_permutation(
    outcome='y',
    model=RandomForestRegressor(),  # UNFITTED
    top_n=10
)
```

**Tests:** 38/38 passing (includes existing tests)

### 3. step_select_shap() - FIXED

**File:** `py_recipes/steps/filter_supervised.py:1073`

**Changes:**
- Same modifications as step_select_permutation
- Handles both TreeExplainer and KernelExplainer
- Automatic model fitting during prep()

**New Usage:**
```python
# OLD
model = XGBRegressor()
model.fit(X_train, y_train)
rec = recipe().step_select_shap(outcome='y', model=model, top_n=10)

# NEW
rec = recipe().step_select_shap(
    outcome='y',
    model=XGBRegressor(),  # UNFITTED
    top_n=10
)
```

**Tests:** 38/38 passing

### 4. step_eix() - NO CHANGES (By Design)

**File:** `py_recipes/steps/interaction_detection.py`

**Reason:** Requires pre-fitted tree model by design because it:
- Analyzes tree structure (nodes, gains, paths)
- Does not just use `.predict()` method
- Validates fitted state in `__post_init__()`

This is fundamentally different from SHAP/permutation which only need predictions.

## Migration Guide

### For step_safe_v2()

**Before:**
```python
from sklearn.ensemble import GradientBoostingRegressor

# Manual fitting required
surrogate = GradientBoostingRegressor(n_estimators=100)
surrogate.fit(X_train, y_train)

# Pass fitted model
rec = recipe().step_safe(
    surrogate_model=surrogate,
    outcome='target',
    penalty=10,
    top_n=30
)
```

**After:**
```python
from sklearn.ensemble import GradientBoostingRegressor

# Pass UNFITTED model
rec = recipe().step_safe_v2(
    surrogate_model=GradientBoostingRegressor(n_estimators=100),  # UNFITTED
    outcome='target',
    penalty=10.0,
    max_thresholds=5,     # NEW: Control thresholds
    top_n=30
)

# Model fitted automatically during prep()
rec_prepped = rec.prep(train_data)
```

### For step_select_permutation() / step_select_shap()

**Before:**
```python
from sklearn.ensemble import RandomForestRegressor

# Manual fitting required
model = RandomForestRegressor(n_estimators=100)
model.fit(X_train, y_train)

# Pass fitted model
rec = recipe().step_select_permutation(
    outcome='target',
    model=model,
    top_n=10
)
```

**After:**
```python
from sklearn.ensemble import RandomForestRegressor

# Pass UNFITTED model
rec = recipe().step_select_permutation(
    outcome='target',
    model=RandomForestRegressor(n_estimators=100),  # UNFITTED
    top_n=10
)

# Model fitted automatically during prep()
rec_prepped = rec.prep(train_data)
```

## Technical Details

### Model Fitting Logic

All fixed steps use this pattern:

```python
def _is_model_fitted(self, model: Any) -> bool:
    """Check if model is already fitted."""
    fitted_attrs = ['n_features_in_', 'feature_names_in_', 'coef_', 'estimators_']
    return any(hasattr(model, attr) for attr in fitted_attrs)

def prep(self, data: pd.DataFrame, training: bool = True):
    # ... data preparation ...

    # Fit model if not already fitted
    if not self._is_model_fitted(self.model):
        if isinstance(self.model, type):
            # Model class - instantiate and fit
            self._fitted_model = self.model().fit(X_clean, y_clean)
        else:
            # Model instance - clone and fit
            from sklearn.base import clone
            self._fitted_model = clone(self.model).fit(X_clean, y_clean)
    else:
        # Already fitted - use as is
        self._fitted_model = self.model

    # Use self._fitted_model for importance calculation
    self._scores = self._compute_importance(X_clean, y_clean)
```

### Feature Name Sanitization

Used in `step_safe_v2()`:

```python
def _sanitize_feature_name(self, name: str) -> str:
    """Remove special characters for LightGBM compatibility."""
    import re
    # Remove all non-alphanumeric except underscore
    sanitized = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    # Remove consecutive underscores
    sanitized = re.sub(r'_+', '_', sanitized)
    # Remove leading/trailing underscores
    sanitized = sanitized.strip('_')
    return sanitized
```

### Threshold Limiting

Used in `step_safe_v2()`:

```python
def _limit_thresholds(self, changepoints: List[float], max_thresholds: int) -> List[float]:
    """Select top N most important changepoints."""
    if len(changepoints) <= max_thresholds:
        return changepoints

    # Calculate PDP jump magnitude at each changepoint
    jumps = [abs(pdp_after - pdp_before) for pdp_before, pdp_after in ...]

    # Select changepoints with largest jumps
    top_indices = np.argsort(jumps)[-max_thresholds:]
    return [changepoints[i] for i in sorted(top_indices)]
```

## Files Modified

1. **`py_recipes/steps/filter_supervised.py`**
   - Lines 1073-1330: `StepSelectShap` - Added unfitted model support
   - Lines 1366-1600: `StepSelectPermutation` - Added unfitted model support

2. **`py_recipes/steps/feature_extraction.py`** (NEW)
   - Added complete `StepSafeV2` class (~800 lines)
   - Added `step_safe_v2()` helper function

3. **`py_recipes/steps/__init__.py`**
   - Exported `step_safe_v2`

4. **`py_recipes/recipe.py`**
   - Added `step_safe_v2()` method

5. **`_md/forecasting_recipes.ipynb`**
   - Updated cells 78-79 to use new pattern

## Test Results

### step_safe_v2()
```bash
$ pytest tests/test_recipes/test_safe_v2.py -v
======================= 21 passed in 2.14s =======================
```

### step_select_permutation() / step_select_shap()
```bash
$ pytest tests/test_recipes/test_filter_supervised.py -v
======================= 38 passed, 153 warnings in 1.23s =======================
```

## Performance Benchmark

From `examples/step_safe_v2_demo.py`:

| Model | Test RMSE | Test R² | Notes |
|-------|-----------|---------|-------|
| Linear (original) | 7.9677 | 0.3840 | Baseline |
| Linear + SAFE v2 | 4.1355 | 0.8340 | **48.1% improvement** |

## Backward Compatibility

All changes are **backward compatible**:
- Existing code using pre-fitted models continues to work
- New code can use unfitted models
- Detection is automatic via `_is_model_fitted()`

## Conclusion

**All 5 user issues resolved:**
- ✅ a) Models fitted during prep()
- ✅ b) Fixed step_select_permutation and step_select_shap
- ✅ c) Added max_thresholds parameter
- ✅ d) Feature name sanitization for LightGBM
- ✅ e) Importance on transformed features

**Status:** PRODUCTION READY

The implementation follows recipe design philosophy where all fitting occurs during `prep()`, providing a cleaner, more reproducible API while maintaining full backward compatibility.
